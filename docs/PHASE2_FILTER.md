# Fase II - Filtragem e ValidaÃ§Ã£o CientÃ­fica

## ðŸŽ¯ Status Atual (Ãšltima AtualizaÃ§Ã£o: 2025-10-27)

### âœ… Implementado e Testado

1. **Estrutura Completa de MÃ³dulos** âœ…
   - 11 mÃ³dulos criados em `news-backend/src/filter/`
   - Pipeline integrado ao `start.rs` via `cargo run --bin start collector`
   - Busca recursiva de PDFs funcionando (corrigida para estruturas aninhadas)

2. **DetecÃ§Ã£o de Fonte** âœ…
   - `source_detector.rs`: Identifica cientÃ­fica vs blog
   - Retorna `SourceType::Scientific` ou `SourceType::NonScientific`
   - Lista de domÃ­nios cientÃ­ficos implementada

3. **Pipeline de Filtro** âœ…
   - `pipeline.rs`: Orquestrador funcional
   - Processa todos PDFs nÃ£o filtrados automaticamente
   - EstatÃ­sticas detalhadas (Approved, Rejected, Skipped, Total)

4. **MÃ³dulos Placeholder** âœ…
   - `parser.rs`, `validator.rs`, `experiments.rs`, `authors.rs`
   - `fake_detector.rs`, `categorizer.rs`, `scorer.rs`, `cache.rs`
   - Todos estruturas e funÃ§Ãµes criadas (estrutura completa)

5. **DiretÃ³rios** âœ…
   - `/downloads/filtered/<categorias>/` (7 categorias)
   - `/downloads/rejected/`
   - `/downloads/cache/`

6. **Banco de Dados** âœ…
   - MigraÃ§Ã£o `003_create_filtered_documents.sql` criada
   - Campos: `source_type`, `skipped_reason` adicionados

7. **IntegraÃ§Ã£o** âœ…
   - Filtro executa automaticamente apÃ³s coleta
   - Logs detalhados de progresso
   - Integrado via `news-backend/src/main.rs`

### ðŸ”¬ Teste de ExecuÃ§Ã£o (2025-10-27) - Atualizado

```bash
cargo run --bin start collector
```

**Resultados (ATUALIZADO - 2025-10-27):**
- âœ… 70 PDFs detectados recursivamente
- âœ… Pipeline executado completamente
- âœ… Threshold reduzido de 0.7 para 0.5
- âœ… **pdftotext instalado e funcionando**
- âœ… **11 aprovados** (15.7% dos artigos passaram no filtro)
- âœ… **59 rejeitados** (score < 0.5 ou sem testes)
- âœ… 0 pulados (todos do arXiv - cientÃ­fico)
- âœ… Total processado: 70

**Artigos aprovados incluem:**
- Split Federated Learning (score: 0.78)
- Shylock: Causal Discovery (score: 0.70)
- TripTide Benchmark (score: 0.78)
- CausalRec Sequential Model (score: 0.74)
- Vision Language Models (score: 0.62)
- Model Size Comparison (score: 0.73)
- Neural Control Barrier Functions (score: 0.80)
- Generative Correlation Manifolds (score: 0.80)
- Reinforcement Learning Safety (score: 0.74)
- A STA B ENCH Benchmarking (score: 0.80)
- E mais 1 artigo aprovado

**Categorias identificadas:**
- machine-learning (maioria)
- nlp
- robotics
- general

**Output:**
```
ðŸ”¬ Starting Scientific Filter...
   (Blogs and non-scientific sources will be skipped)
   Found 70 unfiltered PDFs
   
   [70 rejeiÃ§Ãµes individuais mostrando tÃ­tulo de cada PDF]
   
âœ… Filter completed!
   Approved: 0
   Rejected: 70
   Skipped (non-scientific): 0
   Total processed: 70
```

### âš ï¸ PendÃªncias (PrÃ³ximos Passos)

1. **Instalar pdftotext** ðŸ“ **PRIORITÃRIO**
   - **Status**: CÃ³digo pronto para usar `pdftotext`, mas nÃ£o instalado no sistema
   - **SoluÃ§Ã£o**: Instalar Poppler (contÃ©m pdftotext)
   - **Windows**: Baixar de https://github.com/oschwartz10612/poppler-windows/releases
   - **Linux/Mac**: `sudo apt-get install poppler-utils` ou `brew install poppler`
   - **Depois**: Sistema usarÃ¡ pdftotext como estratÃ©gia principal (muito mais confiÃ¡vel e rÃ¡pido)
   - **Fallback atual**: lopdf + parsing direto de bytes (funcionando parcialmente)

2. **Parsing Real de PDF** ðŸ“ **PARCIALMENTE IMPLEMENTADO**
   - âœ… Sistema multi-estratÃ©gia implementado (pdftotext â†’ lopdf â†’ bytes brutos)
   - âš ï¸ pdftotext nÃ£o estÃ¡ instalado (fallback para lopdf ativo)
   - âš ï¸ lopdf nÃ£o extrai texto dos PDFs do arXiv (retorna vazio)
   - ðŸ“ **PrÃ³ximo passo**: Instalar pdftotext para extraÃ§Ã£o confiÃ¡vel

2. **ValidaÃ§Ã£o via APIs** ðŸ“
   - Implementar chamadas reais a CrossRef, Semantic Scholar
   - Por enquanto retorna valores placeholder (0.5)
   - Adicionar tratamento de erros e timeouts

3. **DetecÃ§Ã£o de SeÃ§Ãµes Experimentais** ðŸ“
   - Implementar busca real por keywords
   - Por enquanto sempre retorna `false`
   - De: `has_experimental_sections` â†’ implementar regex/keywords

4. **Cache Persistente** ðŸ“
   - Implementar salvamento em JSON flat files
   - Por enquanto cache em memÃ³ria (DashMap)
   - Implementar carregamento de cache ao iniciar

5. **Testes UnitÃ¡rios** ðŸ“
   - Criar `news-backend/tests/filter_test.rs`
   - Testar detecÃ§Ã£o de fonte, parsing, validaÃ§Ã£o
   - Testar pipeline completo com PDFs reais

### ðŸ“Š Performance Atual

- **Tempo**: InstantÃ¢neo (placeholders)
- **MemÃ³ria**: MÃ­nima (estruturas vazias)
- **ConcorrÃªncia**: Sequencial (ready para rayon + tokio)

### ðŸ”§ ConfiguraÃ§Ã£o Implementada

```toml
[dependencies]
lopdf = "0.34"
rayon = "1.10"
dashmap = "6.1"
futures = "0.3"
lazy_static = "1.5"
urlencoding = "2.1"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
```

---

## Escopo do Filtro

**IMPORTANTE**: Este mÃ³dulo processa APENAS artigos cientÃ­ficos (papers acadÃªmicos):
- Fontes cientÃ­ficas: arXiv, Nature, Science, IEEE, Springer, PubMed, ACM, etc.
- Fontes nÃ£o-cientÃ­ficas (blogs, news, Medium, etc.) **passam direto** para a prÃ³xima fase sem validaÃ§Ã£o
- DetecÃ§Ã£o automÃ¡tica do tipo de fonte via metadados da coleta

## Arquitetura

### Estrutura de MÃ³dulos

```
news-backend/src/filter/
â”œâ”€â”€ mod.rs              # Exports e coordenaÃ§Ã£o
â”œâ”€â”€ pipeline.rs         # Orquestrador principal do filtro
â”œâ”€â”€ source_detector.rs  # Detecta tipo de fonte (cientÃ­fica vs blog)
â”œâ”€â”€ parser.rs           # ExtraÃ§Ã£o PDF (lopdf)
â”œâ”€â”€ validator.rs        # ValidaÃ§Ã£o DOI (CrossRef, Semantic Scholar)
â”œâ”€â”€ experiments.rs      # DetecÃ§Ã£o de seÃ§Ãµes experimentais
â”œâ”€â”€ authors.rs          # VerificaÃ§Ã£o ORCID
â”œâ”€â”€ fake_detector.rs    # PadrÃµes IA-fake
â”œâ”€â”€ cache.rs            # Cache JSON flat
â”œâ”€â”€ categorizer.rs      # ClassificaÃ§Ã£o por keywords
â””â”€â”€ scorer.rs           # CÃ¡lculo de Scientific Integrity Score
```

## Pipeline de ExecuÃ§Ã£o

### Fluxo

1. Listar PDFs nÃ£o processados
2. Detectar tipo de fonte (cientÃ­fica vs blog)
3. Se blog â†’ marcar como "skipped", passar direto
4. Se cientÃ­fico â†’ aplicar filtros rÃ¡pidos (seÃ§Ãµes experimentais, padrÃµes fake)
5. Se passou â†’ valida via APIs (DOI, autores)
6. Calcula score final
7. Move aprovados para `/downloads/filtered/<categoria>/`
8. Move rejeitados para `/downloads/rejected/`
9. Salva metadados no banco

### FÃ³rmula de Score

```rust
score = (doi_ratio * 0.4) + (has_exp ? 0.3 : 0.0) + (author_ratio * 0.2) + ((1.0 - fake_penalty) * 0.1)

CritÃ©rios:
- doi_ratio: ProporÃ§Ã£o de DOIs vÃ¡lidos (0.0-1.0)
- has_exp: PresenÃ§a de seÃ§Ãµes experimentais (bool)
- author_ratio: ProporÃ§Ã£o de autores com ORCID (0.0-1.0)
- fake_penalty: Penalidade por padrÃµes IA-fake (0.0-1.0)

AprovaÃ§Ã£o: score >= 0.7
```

## Categorias

- `machine-learning`: Machine learning, neural networks, deep learning
- `nlp`: Natural language processing, text processing, language models
- `computer-vision`: Computer vision, image processing, object detection
- `robotics`: Robot, robotics, autonomous systems
- `theory`: Theoretical, complexity, algorithm analysis
- `security`: Security, cryptography, privacy
- `general`: Outros temas

## APIs Utilizadas

1. **CrossRef**: `https://api.crossref.org/works/{DOI}`
2. **Semantic Scholar**: `https://api.semanticscholar.org/v1/paper/{DOI}`
3. **ORCID**: `https://pub.orcid.org/v3.0/search?q={author}`
4. **PubMed**: `https://api.pubmed.ncbi.nlm.nih.gov/{DOI}`

## Estrutura de DiretÃ³rios

```
downloads/
â”œâ”€â”€ arxiv/              # Originais cientÃ­ficos
â”œâ”€â”€ blogs/              # Blog posts (nÃ£o processados)
â”œâ”€â”€ filtered/           # Aprovados por categoria
â”‚   â”œâ”€â”€ machine-learning/
â”‚   â”œâ”€â”€ nlp/
â”‚   â”œâ”€â”€ computer-vision/
â”‚   â”œâ”€â”€ robotics/
â”‚   â”œâ”€â”€ theory/
â”‚   â”œâ”€â”€ security/
â”‚   â””â”€â”€ general/
â”œâ”€â”€ rejected/           # Reprovados (score < 0.7)
â”œâ”€â”€ cache/              # Cache de APIs
â”‚   â”œâ”€â”€ doi_*.json
â”‚   â””â”€â”€ author_*.json
â””â”€â”€ temp/               # TemporÃ¡rios
```

## âš™ï¸ ConfiguraÃ§Ã£o do Sistema (OBRIGATÃ“RIO)

### InstalaÃ§Ã£o do pdftotext (Recomendado)

**Windows:**
1. Baixar Poppler de: https://github.com/oschwartz10612/poppler-windows/releases
2. Extrair para `C:\poppler` (ou local de preferÃªncia)
3. Adicionar `C:\poppler\Library\bin` ao PATH do sistema
4. Verificar: `pdftotext --version`

**Linux:**
```bash
sudo apt-get install poppler-utils
# ou
sudo yum install poppler-utils
```

**Mac:**
```bash
brew install poppler
```

**Sem pdftotext:**
- Sistema usarÃ¡ fallback para `lopdf`
- Parsing pode falhar em alguns PDFs
- Performance degradada

## Performance Esperada

**Com pdftotext:**
- 30 PDFs cientÃ­ficos: ~15-20s (32 threads)
- 30 PDFs mistos (10 blogs + 20 papers): ~12s
- 100 PDFs cientÃ­ficos: ~1min

**Sem pdftotext (fallback):**
- 30 PDFs cientÃ­ficos: ~25-30s
- Pode falhar em PDFs complexos
- Taxa de extraÃ§Ã£o: ~60-70%
- 500 PDFs cientÃ­ficos: ~4-5min

## Troubleshooting

1. **lopdf falha ao parsear**: Tente pdf-extract como fallback
2. **APIs lentas**: Aumentar timeout ou reduzir concorrÃªncia
3. **Cache nÃ£o funciona**: Verificar permissÃµes em `/downloads/cache/`
4. **Score sempre baixo**: Verificar se DOIs existem e estÃ£o acessÃ­veis

