{
  "id": "11777072891412353027",
  "title": "Introducing Aardvark: OpenAI’s agentic security researcher",
  "url": "https://openai.com/index/introducing-aardvark",
  "published_date": "2025-10-30T11:00:00Z",
  "author": null,
  "summary": null,
  "original_title": "Introducing Aardvark: OpenAI’s agentic security researcher",
  "source_type": "rss",
  "content_html": "Now in private beta: an AI agent that thinks like a security researcher and scales to meet the demands of modern software. Today, were announcing Aardvark, an agentic security researcher powered by GPT5. Software security is one of the most criticaland challengingfrontiers in technology. Each year, tens of thousands of new vulnerabilities are discovered across enterprise and open-source codebases. Defenders face the daunting tasks of finding and patching vulnerabilities before their adversaries do. At OpenAI, we are working to tip that balance in favor of defenders. Aardvark represents a breakthrough in AI and security research: an autonomous agent that can help developers and security teams discover and fix security vulnerabilities at scale. Aardvark is now available in private beta to validate and refine its capabilities in the field. Aardvark continuously analyzes source code repositories to identify vulnerabilities, assess exploitability, prioritize severity, and propose targeted patches. Aardvark works by monitoring commits and changes to codebases, identifying vulnerabilities, how they might be exploited, and proposing fixes. Aardvark does not rely on traditional program analysis techniques like fuzzing or software composition analysis. Instead, it uses LLM-powered reasoning and tool-use to understand code behavior and identify vulnerabilities. Aardvark looks for bugs as a human security researcher might: by reading code, analyzing it, writing and running tests, using tools, and more. Aardvark relies on a multi-stage pipeline to identify, explain, and fix vulnerabilities: Aardvark works alongside engineers, integrating with GitHub, Codex, and existing workflows to deliver clear, actionable insights without slowing development. While Aardvark is built for security, in our testing weve found that it can also uncover bugs such as logic flaws, incomplete fixes, and privacy issues. Aardvark has been in service for several months, running continuously across OpenAIs internal codebases and those of external alpha partners. Within OpenAI, it has surfaced meaningful vulnerabilities and contributed to OpenAIs defensive posture. Partners have highlighted the depth of its analysis, with Aardvark finding issues that occur only under complex conditions. In benchmark testing on golden repositories, Aardvark identified 92 of known and synthetically-introduced vulnerabilities, demonstrating high recall and real-world effectiveness. Aardvark has also been applied to open-source projects, where it has discovered and we have responsibly disclosed numerous vulnerabilitiesten of which have received Common Vulnerabilities and Exposures (CVE) identifiers. As beneficiaries of decades of open research and responsible disclosure, were committed to giving backcontributing tools and findings that make the digital ecosystem safer for everyone. We plan to offer pro-bono scanning to select non-commercial open source repositories to contribute to the security of the open source software ecosystem and supply chain. We recently updated our outbound coordinated disclosure policy which takes a developer-friendly stance, focused on collaboration and scalable impact, rather than rigid disclosure timelines that can pressure developers. We anticipate tools like Aardvark will result in the discovery of increasing numbers of bugs, and want to sustainably collaborate to achieve long-term resilience. Software is now the backbone of every industrywhich means software vulnerabilities are a systemic risk to businesses, infrastructure, and society. Over 40,000 CVEs were reported in 2024 alone. Our testing shows that around 1.2 of commits introduce bugssmall changes that can have outsized consequences. Aardvark represents a new defender-first model: an agentic security researcher that partners with teams by delivering continuous protection as code evolves. By catching vulnerabilities early, validating real-world exploitability, and offering clear fixes, Aardvark can strengthen security without slowing innovation. We believe in expanding access to security expertise. We're beginning with a private beta and will broaden availability as we learn. Were inviting select partners to join the Aardvark private beta. Participants will gain early access and work directly with our team to refine detection accuracy, validation workflows, and reporting experience. Were looking to validate performance across a variety of environments. If your organization or open source project is interested in joining, you can apply here. Akshay Bhat, Andy Nguyen, Dave Aitel, Harold Nguyen, Ian Brelinsky, Tiffany Citra, Xin Hu, Matt Knight",
  "content_text": "Now in private beta: an AI agent that thinks like a security researcher and scales to meet the demands of modern software. Today, were announcing Aardvark, an agentic security researcher powered by GPT5. Software security is one of the most criticaland challengingfrontiers in technology. Each year, tens of thousands of new vulnerabilities are discovered across enterprise and open-source codebases. Defenders face the daunting tasks of finding and patching vulnerabilities before their adversaries do. At OpenAI, we are working to tip that balance in favor of defenders. Aardvark represents a breakthrough in AI and security research: an autonomous agent that can help developers and security teams discover and fix security vulnerabilities at scale. Aardvark is now available in private beta to validate and refine its capabilities in the field. Aardvark continuously analyzes source code repositories to identify vulnerabilities, assess exploitability, prioritize severity, and propose targeted patches. Aardvark works by monitoring commits and changes to codebases, identifying vulnerabilities, how they might be exploited, and proposing fixes. Aardvark does not rely on traditional program analysis techniques like fuzzing or software composition analysis. Instead, it uses LLM-powered reasoning and tool-use to understand code behavior and identify vulnerabilities. Aardvark looks for bugs as a human security researcher might: by reading code, analyzing it, writing and running tests, using tools, and more. Aardvark relies on a multi-stage pipeline to identify, explain, and fix vulnerabilities: Aardvark works alongside engineers, integrating with GitHub, Codex, and existing workflows to deliver clear, actionable insights without slowing development. While Aardvark is built for security, in our testing weve found that it can also uncover bugs such as logic flaws, incomplete fixes, and privacy issues. Aardvark has been in service for several months, running continuously across OpenAIs internal codebases and those of external alpha partners. Within OpenAI, it has surfaced meaningful vulnerabilities and contributed to OpenAIs defensive posture. Partners have highlighted the depth of its analysis, with Aardvark finding issues that occur only under complex conditions. In benchmark testing on golden repositories, Aardvark identified 92 of known and synthetically-introduced vulnerabilities, demonstrating high recall and real-world effectiveness. Aardvark has also been applied to open-source projects, where it has discovered and we have responsibly disclosed numerous vulnerabilitiesten of which have received Common Vulnerabilities and Exposures (CVE) identifiers. As beneficiaries of decades of open research and responsible disclosure, were committed to giving backcontributing tools and findings that make the digital ecosystem safer for everyone. We plan to offer pro-bono scanning to select non-commercial open source repositories to contribute to the security of the open source software ecosystem and supply chain. We recently updated our outbound coordinated disclosure policy which takes a developer-friendly stance, focused on collaboration and scalable impact, rather than rigid disclosure timelines that can pressure developers. We anticipate tools like Aardvark will result in the discovery of increasing numbers of bugs, and want to sustainably collaborate to achieve long-term resilience. Software is now the backbone of every industrywhich means software vulnerabilities are a systemic risk to businesses, infrastructure, and society. Over 40,000 CVEs were reported in 2024 alone. Our testing shows that around 1.2 of commits introduce bugssmall changes that can have outsized consequences. Aardvark represents a new defender-first model: an agentic security researcher that partners with teams by delivering continuous protection as code evolves. By catching vulnerabilities early, validating real-world exploitability, and offering clear fixes, Aardvark can strengthen security without slowing innovation. We believe in expanding access to security expertise. We're beginning with a private beta and will broaden availability as we learn. Were inviting select partners to join the Aardvark private beta. Participants will gain early access and work directly with our team to refine detection accuracy, validation workflows, and reporting experience. Were looking to validate performance across a variety of environments. If your organization or open source project is interested in joining, you can apply here. Akshay Bhat, Andy Nguyen, Dave Aitel, Harold Nguyen, Ian Brelinsky, Tiffany Citra, Xin Hu, Matt Knight"
}