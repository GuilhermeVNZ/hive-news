{
  "id": "1416961349067221087",
  "title": "Fighting the New York Times’ invasion of user privacy",
  "url": "https://openai.com/index/fighting-nyt-user-privacy-invasion",
  "published_date": "2025-11-12T06:00:00Z",
  "author": null,
  "summary": null,
  "original_title": "Fighting the New York Times’ invasion of user privacy",
  "source_type": "rss",
  "content_html": "Trust, security, and privacy guide every product and decision we make. Each week, 800 million people use ChatGPT to think, learn, create, and handle some of the most personal parts of their lives. People entrust us with sensitive conversations, files, credentials, memories, searches, payment information, and AI agents that act on their behalf. We treat this data as among the most sensitive information in your digital lifeand were building our privacy and security protections to match that responsibility. The New York Times is demanding that we turn over 20 million of your private ChatGPT conversations. They claim they might find examples of you using ChatGPT to try to get around their paywall. This demand disregards long-standing privacy protections, breaks with common-sense security practices, and would force us to turn over tens of millions of highly personal conversations from people who have no connection to the Times baseless lawsuit against OpenAI. They have tried this before. Originally, the Times wanted you to lose the ability to delete your private chats. We fought that and restored your right to remove them. Then they demanded we turn over 1.4 billion of your private ChatGPT conversations. We pushed back, and were pushing back again now. Your private conversations are yoursand they should not become collateral in a dispute over online content access. We respect strong, independent journalism and partner with many publishers and newsrooms. Journalism has historically played a critical role in defending peoples right to privacy throughout the world. However, this demand from the New York Times does not live up to that legacy, and were asking the court to reject it. We will continue to explore every option available to protect our users privacy. We are accelerating our security and privacy roadmap to protect your data. OpenAI is one of the most targeted organizations in the world. We have invested significant time and resources building systems to prevent unauthorized access to your data by adversaries ranging from organized criminal groups to state-sponsored intelligence services. However, if the Times succeeds in its demand, we will be forced to hand over the very same data were protectingyour datato third parties, including the Times lawyers and paid consultants. Our long-term roadmap includes advanced security features designed to keep your data private, including client-side encryption for your messages with ChatGPT. We believe these features will help keep your private conversations private and inaccessible to anyone else, even OpenAI. We will build fully automated systems to detect safety issues in our products. Only serious misuse and critical riskssuch as threats to someones life, plans to harm others, or cybersecurity threatsmay ever be escalated to a small, highly vetted team of human reviewers. These security features are in active development and we will share more details about them, and other short-term mitigations, in the very near future. The privacy and security protections must become more powerful as AI becomes more deeply integrated into peoples lives. We are committed to a future where you can trust that your most personal AI conversations are safe, secure, and truly private. Dane Stuckey, Chief Information Security Officer, OpenAI Why are The New York Times and other plaintiffs demanding this? What are you doing to protect my personal information and privacy? Does this court order violate GDPR or my rights under European or other privacy laws?",
  "content_text": "Trust, security, and privacy guide every product and decision we make. Each week, 800 million people use ChatGPT to think, learn, create, and handle some of the most personal parts of their lives. People entrust us with sensitive conversations, files, credentials, memories, searches, payment information, and AI agents that act on their behalf. We treat this data as among the most sensitive information in your digital lifeand were building our privacy and security protections to match that responsibility. The New York Times is demanding that we turn over 20 million of your private ChatGPT conversations. They claim they might find examples of you using ChatGPT to try to get around their paywall. This demand disregards long-standing privacy protections, breaks with common-sense security practices, and would force us to turn over tens of millions of highly personal conversations from people who have no connection to the Times baseless lawsuit against OpenAI. They have tried this before. Originally, the Times wanted you to lose the ability to delete your private chats. We fought that and restored your right to remove them. Then they demanded we turn over 1.4 billion of your private ChatGPT conversations. We pushed back, and were pushing back again now. Your private conversations are yoursand they should not become collateral in a dispute over online content access. We respect strong, independent journalism and partner with many publishers and newsrooms. Journalism has historically played a critical role in defending peoples right to privacy throughout the world. However, this demand from the New York Times does not live up to that legacy, and were asking the court to reject it. We will continue to explore every option available to protect our users privacy. We are accelerating our security and privacy roadmap to protect your data. OpenAI is one of the most targeted organizations in the world. We have invested significant time and resources building systems to prevent unauthorized access to your data by adversaries ranging from organized criminal groups to state-sponsored intelligence services. However, if the Times succeeds in its demand, we will be forced to hand over the very same data were protectingyour datato third parties, including the Times lawyers and paid consultants. Our long-term roadmap includes advanced security features designed to keep your data private, including client-side encryption for your messages with ChatGPT. We believe these features will help keep your private conversations private and inaccessible to anyone else, even OpenAI. We will build fully automated systems to detect safety issues in our products. Only serious misuse and critical riskssuch as threats to someones life, plans to harm others, or cybersecurity threatsmay ever be escalated to a small, highly vetted team of human reviewers. These security features are in active development and we will share more details about them, and other short-term mitigations, in the very near future. The privacy and security protections must become more powerful as AI becomes more deeply integrated into peoples lives. We are committed to a future where you can trust that your most personal AI conversations are safe, secure, and truly private. Dane Stuckey, Chief Information Security Officer, OpenAI Why are The New York Times and other plaintiffs demanding this? What are you doing to protect my personal information and privacy? Does this court order violate GDPR or my rights under European or other privacy laws?"
}