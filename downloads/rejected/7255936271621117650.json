{
  "id": "7255936271621117650",
  "title": "AWS and OpenAI announce multi-year strategic partnership",
  "url": "https://openai.com/index/aws-and-openai-partnership",
  "published_date": "2025-11-03T06:00:00Z",
  "author": null,
  "summary": null,
  "source_type": "rss",
  "content_html": "Partnership will enable OpenAI to run its advanced AI workloads on AWSs world-class infrastructure starting immediately. Today, Amazon Web Services (AWS) and OpenAI announced a multi-year, strategic partnership that provides AWSs world-class infrastructure to run and scale OpenAIs core artificial intelligence (AI) workloads starting immediately. Under this new 38 billion agreement, which will have continued growth over the next seven years, OpenAI is accessing AWS compute comprising hundreds of thousands of state-of-the-art NVIDIA GPUs, with the ability to expand to tens of millions of CPUs to rapidly scale agentic workloads. AWS has unusual experience running large-scale AI infrastructure securely, reliably, and at scalewith clusters topping 500K chips. AWS's leadership in cloud infrastructure combined with OpenAI's pioneering advancements in generative AI will help millions of users continue to get value from ChatGPT. The rapid advancement of AI technology has created unprecedented demand for computing power. As frontier model providers seek to push their models to new heights of intelligence, they are increasingly turning to AWS due to the performance, scale, and security they can achieve. OpenAI will immediately start utilizing AWS compute as part of this partnership, with all capacity targeted to be deployed before the end of 2026, and the ability to expand further into 2027 and beyond. The infrastructure deployment that AWS is building for OpenAI features a sophisticated architectural design optimized for maximum AI processing efficiency and performance. Clustering the NVIDIA GPUsboth GB200s and GB300svia Amazon EC2 UltraServers on the same network enables low-latency performance across interconnected systems, allowing OpenAI to efficiently run workloads with optimal performance. The clusters are designed to support various workloads, from serving inference for ChatGPT to training next generation models, with the flexibility to adapt to OpenAI's evolving needs. Scaling frontier AI requires massive, reliable compute,\" said OpenAI co-founder and CEO Sam Altman. Our partnership with AWS strengthens the broad compute ecosystem that will power this next era and bring advanced AI to everyone. As OpenAI continues to push the boundaries of what's possible, AWS's best-in-class infrastructure will serve as a backbone for their AI ambitions, said Matt Garman, CEO of AWS. The breadth and immediate availability of optimized compute demonstrates why AWS is uniquely positioned to support OpenAI's vast AI workloads.\" This news continues the companies work together to provide cutting-edge AI technology to benefit organizations worldwide. Earlier this year, OpenAI open weight foundation models became available on Amazon Bedrock, bringing these additional model options to millions of customers on AWS. OpenAI has quickly become one of the most popular publicly available model providers in Amazon Bedrock with thousands of customersincluding Bystreet, Comscore, Peloton, Thomson Reuters, Triomics, and Verana Healthworking with their models for agentic workflows, coding, scientific analysis, mathematical problem-solving, and more. To get started with OpenAIs open weight models in Amazon Bedrock, visit: aws.amazon.com/bedrock/openai",
  "content_text": "Partnership will enable OpenAI to run its advanced AI workloads on AWSs world-class infrastructure starting immediately. Today, Amazon Web Services (AWS) and OpenAI announced a multi-year, strategic partnership that provides AWSs world-class infrastructure to run and scale OpenAIs core artificial intelligence (AI) workloads starting immediately. Under this new 38 billion agreement, which will have continued growth over the next seven years, OpenAI is accessing AWS compute comprising hundreds of thousands of state-of-the-art NVIDIA GPUs, with the ability to expand to tens of millions of CPUs to rapidly scale agentic workloads. AWS has unusual experience running large-scale AI infrastructure securely, reliably, and at scalewith clusters topping 500K chips. AWS's leadership in cloud infrastructure combined with OpenAI's pioneering advancements in generative AI will help millions of users continue to get value from ChatGPT. The rapid advancement of AI technology has created unprecedented demand for computing power. As frontier model providers seek to push their models to new heights of intelligence, they are increasingly turning to AWS due to the performance, scale, and security they can achieve. OpenAI will immediately start utilizing AWS compute as part of this partnership, with all capacity targeted to be deployed before the end of 2026, and the ability to expand further into 2027 and beyond. The infrastructure deployment that AWS is building for OpenAI features a sophisticated architectural design optimized for maximum AI processing efficiency and performance. Clustering the NVIDIA GPUsboth GB200s and GB300svia Amazon EC2 UltraServers on the same network enables low-latency performance across interconnected systems, allowing OpenAI to efficiently run workloads with optimal performance. The clusters are designed to support various workloads, from serving inference for ChatGPT to training next generation models, with the flexibility to adapt to OpenAI's evolving needs. Scaling frontier AI requires massive, reliable compute,\" said OpenAI co-founder and CEO Sam Altman. Our partnership with AWS strengthens the broad compute ecosystem that will power this next era and bring advanced AI to everyone. As OpenAI continues to push the boundaries of what's possible, AWS's best-in-class infrastructure will serve as a backbone for their AI ambitions, said Matt Garman, CEO of AWS. The breadth and immediate availability of optimized compute demonstrates why AWS is uniquely positioned to support OpenAI's vast AI workloads.\" This news continues the companies work together to provide cutting-edge AI technology to benefit organizations worldwide. Earlier this year, OpenAI open weight foundation models became available on Amazon Bedrock, bringing these additional model options to millions of customers on AWS. OpenAI has quickly become one of the most popular publicly available model providers in Amazon Bedrock with thousands of customersincluding Bystreet, Comscore, Peloton, Thomson Reuters, Triomics, and Verana Healthworking with their models for agentic workflows, coding, scientific analysis, mathematical problem-solving, and more. To get started with OpenAIs open weight models in Amazon Bedrock, visit: aws.amazon.com/bedrock/openai"
}