<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[Character.AI Blog]]></title><description><![CDATA[Character.AI empowers people to connect, learn, and tell stories through interactive entertainment. ]]></description><link>https://blog.character.ai/</link><image><url>https://blog.character.ai/favicon.png</url><title>Character.AI Blog</title><link>https://blog.character.ai/</link></image><generator>Ghost 6.7</generator><lastBuildDate>Fri, 14 Nov 2025 00:58:51 GMT</lastBuildDate><atom:link href="https://blog.character.ai/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Inside Kaiju]]></title><description><![CDATA[What made Character.ai's early models so engaging? Before open-source models became the norm, our team built Kaiju - a family of in-house LLMs designed to power millions of fast, expressive conversations every day with an eye towards safety.
Our latest blog post looks back at that foundational work.]]></description><link>https://blog.character.ai/inside-kaiju-building-conversational-models-at-scale/</link><guid isPermaLink="false">690ab83d3e492a000104f30f</guid><category><![CDATA[Technical]]></category><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Fri, 07 Nov 2025 17:00:49 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/11/KAIJU-FInal.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/11/KAIJU-FInal.png" alt="Inside Kaiju"><p>As the Character.ai team shifts towards building on top of <a href="https://blog.character.ai/breaking-news-our-open-source-models-are-a-lot-of-fun/"><u>Open-Source models</u></a>, we wanted to share the work that went into some of our OG research. After all, our founder Noam Shazeer invented the Transformer!</p><p>Kaiju is Character.ai&#x2019;s in-house family of LLMs built specifically to be fast, engaging, and with an eye towards safety.&#xA0;</p><p>Available in three sizes, Kaiju combines a dense transformer architecture with aggressive efficiency optimizations, including int8 quantization, multi-query attention, sliding-window attention, and cross-layer cache sharing. Previous blog posts mention some of these (and more): <a href="https://blog.character.ai/optimizing-ai-inference-at-character-ai/" rel="noreferrer">Optimizing AI Inference at Character.ai</a> and <a href="https://blog.character.ai/optimizing-ai-inference-at-character-ai-part-deux-2/" rel="noreferrer">Optimizing AI Inference at Character.ai Part 2</a>.</p><p>If you&#x2019;re an engineer interested in building the next generation of Character.ai models and this work sounds interesting to you, check out our <a href="https://jobs.ashbyhq.com/character/?ref=blog.character.ai"><u>open roles</u></a>!&#xA0;</p><h2 id="model-overview">Model Overview</h2><p>The Kaiju family of models comes in 3 production variants: <strong>Small (13B)</strong>, <strong>Medium (34B)</strong>, and <strong>Large (110B)</strong>.</p><p>The Kaiju models are heavily optimized for engaging conversation and serving efficiency, and those elements drove the design philosophy, rather than a focus on academic benchmarks.</p><h2 id="architecture-innovations">Architecture Innovations</h2><p>All Kaiju models are dense, transformer-based autoregressive LLMs with several unique architectural components.</p><h3 id="multiquery-attention-mqa">Multiquery Attention (MQA)</h3><p>Kaiju relies heavily on <a href="https://arxiv.org/pdf/1911.02150?ref=blog.character.ai"><u>MQA</u></a> reducing the per-token KV cache size and improving our inference efficiency. Chat inference workloads can typically rely heavily on KV cache hit rate due to the similar input token characteristics from one turn to the next, and with a smaller per-token KV cache size, this dramatically improves performance.</p><p>MQA is known to have a measurable, negative impact on some AGI benchmarks like MMLU - this is both <a href="https://arxiv.org/pdf/2405.04434?ref=blog.character.ai"><u>publicly documented</u></a> and reproduced internally by our team. Since we are not optimizing for AGI we found that the inference efficiency was well worth it when traded off against small quality impact.</p><h3 id="sliding-window-attention">Sliding Window Attention</h3><p>The Kaiju production models utilize <a href="https://arxiv.org/pdf/2004.05150v2?ref=blog.character.ai"><u>sliding window</u></a> attention, which reduces the flops required for attention, especially in longer context settings.</p><p>All&#xA0;Character.ai&#xA0;models interleave sliding window and global attention layers. For current production models, this is done in a roughly 5:1 ratio of sliding to global attention, and the sliding window is 1024 tokens long.</p><p>Naive sliding window attention causes a drop in model quality on long contexts. In internal experiments on <em>interleaved </em>sliding window attention, there was little to no drop in &#x201C;needle in the haystack&#x201D; long-context retrieval quality.</p><p>It&#x2019;s also worth noting that our current sliding window attention does <em>not</em> implement <a href="https://arxiv.org/abs/2309.17453v1?ref=blog.character.ai"><u>attention sinks.</u></a></p><h3 id="cross-layer-kv-sharing">Cross Layer KV Sharing</h3><p>In addition to MQA, Kaiju models <a href="https://arxiv.org/pdf/2405.12981?ref=blog.character.ai"><u>share KV cache</u></a> between adjacent layers with the same attention mechanism. Similar to MQA, this allows for a decrease in the KV cache size required for inference and does not lead to a measurable drop in model accuracy. Generally, 2-3 layers share a KV cache.</p><h3 id="int8">Int8</h3><p>The current family of Kaiju models stores their parameters and KV values in int8. At inference time, matrix multiplications are done in int8. On most modern accelerators, int8 matrix multiplication has 2x the flops of bf16.</p><p><strong>Note:</strong> Kaiju models are all currently trained via Quantization Aware Training. Using QAT allows the models to maintain bf16-level model accuracy while training 20&#x2013;30 % faster.&#xA0;</p><h3 id="additional-innovations">Additional Innovations</h3><p><strong>Pre-layer norms </strong>- Kaiju models use pre-layer normalization. This means they apply RMSNorm to the input of each layer &#x2014; before the layer&#x2019;s main matrix multiplications &#x2014; rather than applying normalization after the layer&#x2019;s computations. In other words, normalization happens at the start of each layer instead of at the end.</p><p><strong>Dynamic Clamping </strong>- Dynamic clamping of activations helps ensure stability during training. The model &#x201C;learns&#x201D; to utilize the clamping, and it is needed at inference time.</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/11/data-src-image-ef29ca21-3d87-49a6-a733-88e531f80be0-1.png" class="kg-image" alt="Inside Kaiju" loading="lazy" width="720" height="960" srcset="https://blog.character.ai/content/images/size/w600/2025/11/data-src-image-ef29ca21-3d87-49a6-a733-88e531f80be0-1.png 600w, https://blog.character.ai/content/images/2025/11/data-src-image-ef29ca21-3d87-49a6-a733-88e531f80be0-1.png 720w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/11/data-src-image-3739c4b0-75ba-4ad1-a93a-57f6330b608f.png" class="kg-image" alt="Inside Kaiju" loading="lazy" width="960" height="720" srcset="https://blog.character.ai/content/images/size/w600/2025/11/data-src-image-3739c4b0-75ba-4ad1-a93a-57f6330b608f.png 600w, https://blog.character.ai/content/images/2025/11/data-src-image-3739c4b0-75ba-4ad1-a93a-57f6330b608f.png 960w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/11/data-src-image-c4c8808f-f950-4c77-8e34-b78acdc83cb7.png" class="kg-image" alt="Inside Kaiju" loading="lazy" width="960" height="720" srcset="https://blog.character.ai/content/images/size/w600/2025/11/data-src-image-c4c8808f-f950-4c77-8e34-b78acdc83cb7.png 600w, https://blog.character.ai/content/images/2025/11/data-src-image-c4c8808f-f950-4c77-8e34-b78acdc83cb7.png 960w" sizes="(min-width: 720px) 720px"></figure><h2 id="model-training">Model Training</h2><p>Beyond architectural efficiency, Kaiju&#x2019;s performance depends heavily on its training stack. Quantization-aware training, low-bit gradient communication, and stability enhancements together form the foundation of Kaiju&#x2019;s scalable learning system.</p><p>Kaiju models were trained entirely on H100 GPUs in GCP clusters using model parallelism, which includes tensor + sequence within nodes and FSDP across nodes.</p><h3 id="quantization-aware-training">Quantization Aware Training</h3><p>Kaiju models are trained using a variety of precisions to balance model quality and training cost.</p><p><strong>Int8 - </strong>Forward pass weights, KV<br><strong>Bf16 </strong>- Activations, local gradients<br><strong>Fp32</strong> - Gradient accumulations, FSDP master weights</p><p>Gradient communication is done in 6-bits using Squinch.</p><h3 id="gradient-compression-squinch">Gradient Compression (Squinch)</h3><p>Squinch is a novel blockwise gradient compression algorithm that seeks to minimize the expected log-error of gradient reconstruction. Each block contains 8 elements, and the distribution of gradient magnitudes is modeled as log-uniform over a finite domain.</p><h3 id="additional-efficiency-innovations">Additional Efficiency Innovations</h3><p><strong>Virtual scalars (Bungee) </strong>- In order to stabilize int8 training, virtual scalars are introduced to allow the model to express a wider range of activations and gradients. This is mostly helpful for smaller models.</p><p><strong>Ternary Weight Updates </strong>- When training small int8 models, where the full int8 weights fit on the node, weights can be pinned to the node, like zero-2. When the magnitude of int8 weight updates is small, a 0, 1, or -1 can be sent representing each weight, compressing the weight broadcast to 1.6 bits/parameter.</p><h2 id="data-strategy">Data Strategy</h2><p>Kaiju models are trained on optimized data mixes. There are two categories of data mix objectives:</p><ul><li><strong>MMLU Max</strong> - These data mixes are designed to maximize &#x201C;AGI Benchmarks&#x201D;.</li><li><strong>Production Max</strong> - These data mixes are designed to create a highly engaging model.&#xA0;</li></ul><p>In general, the methodology involves selecting a pre-training data mix that is as similar as possible to the task being optimized for (e.g. similarity via T5 embedding).</p><p>Kaiju models are trained on a broad mix of web-scale text, code, and synthetic data. Each variant uses a slightly different balance depending on its goal - for example natural, high engagement conversation requires different inputs than a model trained for benchmark performance.</p><p>We perform an <strong>annealing</strong> process near the end of the pretraining run, scheduling the MMLU Max section and other instruction data. This boosts the final performance of the models as it unlocks instruction following and specific knowledge for benchmark tasks.&#xA0;</p><h2 id="safety-and-alignment">Safety and Alignment</h2><p>Before deployment, Kaiju models undergo a multi-phase safety and alignment process, including:</p><ol><li><strong>Supervised Fine-Tuning</strong> on high-quality (safety-related, instruction following) data</li><li><strong>Reinforcement Learning</strong> (modified online DPO) on user swipe data and feedback</li><li><strong>Classifier training</strong></li></ol><p>Notably, Kaiju models come with an optional additional classifier head. The classifier head is a linear layer that outputs token-level metrics about the safety of the input along various dimensions.</p><p>While the Kaiju models can be used with any traditional sampling method, we implement classifier-guided beam search, where the classifier results are used to augment how we sample tokens at inference time.&#xA0;</p><h2 id="the-future-of-safety-centric-scalable-ai">The Future of Safety-centric, Scalable AI</h2><p>Kaiju demonstrates that production performance&#x2014;not just benchmark scores&#x2014;can and should drive architecture choices. Techniques such as int8 QAT, MQA, and KV sharing collectively reduce inference memory and cost by orders of magnitude, enabling large-scale deployment.&#xA0;</p><p>As we focus on OSS LLMs into the future, we&#x2019;ll continue to push towards our goals of efficient deployment, dynamic and engaging conversation, and robust safety and alignment.</p><p>Character.ai&#x2019;s team works across model architecture, safety alignment, and production infrastructure at the cutting edge of interactive AI. If you&#x2019;re an engineer or researcher who thrives on contributing to large-scale, human-centered ML systems, check out our <a href="https://jobs.ashbyhq.com/character/?ref=blog.character.ai" rel="noreferrer"><strong>open job posts</strong></a>. We&#x2019;d love to have you join our team!&#xA0;</p>]]></content:encoded></item><item><title><![CDATA[Taking Bold Steps to Keep Teen Users Safe on Character.AI]]></title><description><![CDATA[<p>At Character.AI, our goal has always been to provide an engaging space that fosters creativity while maintaining a safe environment for everyone&#x2014;especially teens.</p><p>Over the past year, we&#x2019;ve invested tremendous effort and resources into creating a dedicated under-18 experience. This included the first Parental Insights</p>]]></description><link>https://blog.character.ai/u18-chat-announcement/</link><guid isPermaLink="false">68e82da66c32fc0001ce6103</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Wed, 29 Oct 2025 12:59:00 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/10/u18-blog-banner.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/10/u18-blog-banner.png" alt="Taking Bold Steps to Keep Teen Users Safe on Character.AI"><p>At Character.AI, our goal has always been to provide an engaging space that fosters creativity while maintaining a safe environment for everyone&#x2014;especially teens.</p><p>Over the past year, we&#x2019;ve invested tremendous effort and resources into creating a dedicated under-18 experience. This included the first Parental Insights tool on the AI market, technical protections, filtered Characters, time spent notifications, and more &#x2014; all designed to let teens be creative with AI in safe ways. We are proud of this work, and we&#x2019;ve steadily augmented it over time. But as the world of AI evolves, so must our approach to supporting younger users.</p><p>Today, we are announcing several important initiatives on that front.</p><p><strong>First</strong>, we will be removing the ability for users under 18 to engage in open-ended chat with AI on our platform. This change will take effect no later than November 25. Between now and then, we will be working to build an under-18 experience that still gives our teen users ways to be creative &#x2013; for example, by creating videos, stories, and streams with Characters. During this transition period, we also will limit chat time for users under 18. The limit initially will be two hours per day and will ramp down in the coming weeks before November 25.</p><p><strong>Second</strong>, we will be rolling out new age assurance functionality to help ensure users receive the right experience for their age. We have built an age assurance model in-house and will be combining it with leading third-party tools including Persona.</p><p><strong>Third, </strong>we will establish and fund the AI Safety Lab &#x2013; an independent non-profit dedicated to innovating safety alignment for next-generation AI entertainment features. The AI Safety Lab will focus on novel safety techniques and collaboration with third parties to advance the state of the art and share learnings. Given <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a>&#x2019;s mission, we are establishing the AI Safety Lab&#xA0; to help ensure that forward-looking safety research for AI entertainment receives the same level of attention as safety research for other AI use cases. We&apos;re inviting a number of technology companies, academics, researchers and policy makers to join.</p><h2 id="why-we%E2%80%99re-making-changes">Why We&#x2019;re Making Changes</h2><p>We&#x2019;re making these changes to our under-18 platform in light of the evolving landscape around AI and teens. We have seen recent news reports raising questions, and have received questions from regulators, about the content teens may encounter when chatting with AI and about how open-ended AI chat in general might affect teens, even when content controls work perfectly. After evaluating these reports and feedback from regulators, safety experts, and parents, we&#x2019;ve decided to make this change to create a new experience for our under-18 community.&#xA0;</p><p>These are extraordinary steps for our company, and ones that, in many respects, are more conservative than our peers. But we believe they are the right thing to do. We want to set a precedent that prioritizes teen safety while still offering young users opportunities to discover, play, and create. We will continue to collaborate with safety experts, regulators, and other stakeholders to ensure that user safety remains paramount as we develop innovative new features that foster creativity, discovery, and community.&#xA0;</p><h2 id="a-note-to-our-under-18-community">A Note to Our Under-18 Community</h2><p>To our users under 18: We understand that this is a significant change for you. We are deeply sorry that we have to eliminate a key feature of our platform. We know that most of you use <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> to supercharge your creativity in ways that stay within the bounds of our content rules. And many of you have told us over time how important the Characters and stories you&#x2019;ve created are to you.&#xA0;</p><p>We do not take this step of removing open-ended Character chat lightly &#x2013; but we do think that it&#x2019;s the right thing to do given the questions that have been raised about how teens do, and should, interact with this new technology.&#xA0;</p><p>We&#x2019;re working on new ways for you to play and create with your favorite Characters. If you need support, you can find helpful resources <a href="https://support.character.ai/hc/en-us/articles/42649759119003-Resources-You-Can-Turn-To?ref=blog.character.ai" rel="noreferrer"><u>here</u></a>. We encourage you to check out the other features on <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> &#x2013; including ones that allow you to use your favorite Characters! And we commit to building more fun and engaging experiences for you going forward.&#xA0;</p><p>The <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> Team</p>]]></content:encoded></item><item><title><![CDATA[Introducing Scenes: your new way to tell stories on c.ai]]></title><description><![CDATA[<p>Today, we&#x2019;re excited to announce that we&#x2019;ve unlocked Scenes Creation for all users!&#xA0;</p><p>Scenes are short, Character-driven role-play moments that turn simple chats into immersive story-driven worlds. This immersive storytelling feature enables users to explore and create ready-made worlds, allowing them to step into them,</p>]]></description><link>https://blog.character.ai/introducing-scenes-your-new-way-to-tell-stories-on-c-ai/</link><guid isPermaLink="false">68f06cbe3e492a000104f083</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Thu, 16 Oct 2025 16:00:42 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/10/scene-asset.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/10/scene-asset.png" alt="Introducing Scenes: your new way to tell stories on c.ai"><p>Today, we&#x2019;re excited to announce that we&#x2019;ve unlocked Scenes Creation for all users!&#xA0;</p><p>Scenes are short, Character-driven role-play moments that turn simple chats into immersive story-driven worlds. This immersive storytelling feature enables users to explore and create ready-made worlds, allowing them to step into them, making storytelling faster, deeper, and more accessible.&#xA0;</p><p>By opening Scenes Creation to everyone, we&#x2019;re inviting our entire community to unleash a new wave of storytelling, expanding the diversity, depth, and creativity of what&#x2019;s possible on the platform. Whether it&#x2019;s crafting an epic adventure, writing a slice-of-life story, or setting up a dramatic encounter, Scenes empower everyone to shape the stories they want to tell and experience with their Characters.</p><h2 id="how-to-create-a-scene">How To Create a Scene</h2><p>Now is your chance to step into the role of director and craft Scenes that set the tone, pace, and emotional stakes of your stories in a structured format.&#xA0;</p><p>To create a Scene:</p><ul><li><strong>Choose your Scene style:</strong> Start by choosing how you want the Scene to work. An <strong>Any Character</strong> Scene is flexible and designed to work with any Character the user selects, so you&#x2019;ll focus on describing what&#x2019;s happening in the setting. A <strong>Main Character</strong> Scene is built around a specific Character and their personality, so you can lean into their unique traits and voice to build a story around them.</li><li><strong>Define setting, backstory &amp; player goal:</strong> Use concise descriptions (genre, time, place, tone), set up what&#x2019;s happening (the situation), and state what the user and Character aim to achieve together.</li><li><strong>Write the intro &amp; greeting:</strong> Craft an immersive opening (sensory detail + intrigue) and a first message from the character that hooks the user and invites them to participate.</li><li><strong>Name, cover, and metadata:</strong> Pick a compelling Scene name, a fitting cover image, chat bubble colors, and tags to reflect the vibe and help users find it.</li><li><strong>Publish &amp; manage:</strong> Pick your Scene visibility (public, unlisted, private), hit &#x201C;Create Scene,&#x201D; and later you can edit or manage your scenes in your profile.</li></ul><p>Before Scenes, Creators would have to create a new Character to explore each new story idea, which has been a time-consuming process. Scenes will help you expand your storytelling without rebuilding your Characters.&#xA0;</p><p>For more creation tips and best practices, check out our <a href="https://support.character.ai/hc/en-us/articles/41918454359451-Scene-Creation-Quickstart-Guide?ref=blog.character.ai"><u>Scenes Creation guide</u></a>.</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/10/scene-asset-1.png" class="kg-image" alt="Introducing Scenes: your new way to tell stories on c.ai" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/10/scene-asset-1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/10/scene-asset-1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/10/scene-asset-1.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/10/scene-asset-1.png 2400w" sizes="(min-width: 720px) 720px"></figure><h2 id="how-to-play-a-scene">How To Play a Scene</h2><p>We know open-ended chat can be a hard place to get started. With built-in context, roles, and momentum, dropping your favorite Character into a Scene can get you roleplaying instantly.&#xA0;</p><p>Each Scene drops your Character into a self-contained narrative alongside another Character who carries the story forward, like an expert improv partner who animates the story, guiding you toward an emotional payoff that leaves you with a story that feels complete.</p><p>To get started:&#xA0;</p><ul><li><strong>Discover your favorite Scene:</strong> Head to the Scenes pill in the Home tab to browse Scenes created by the community, or use the search bar to find a specific Scene you&#x2019;re interested in.</li><li><strong>Preview the Scene:</strong> Tap on a Scene to open its intro&#xA0; and get a feeling about the story in the Scene.</li><li><strong>Pick a Character: </strong>In an Any Character Scene, pick your favorite Character and dive right in. In a Main Character Scene, jump straight into the chat and experience the story through the Character the creator designed.</li><li><strong>Play the Scene: </strong>Start typing and see where the Scene takes you! Your choices shape what happens next.</li></ul><h2 id="safety-policies">Safety Policies</h2><p>Our goal is to provide an engaging space that fosters creativity while maintaining a safe environment for all. Please visit our <a href="https://character.ai/tos?ref=blog.character.ai"><u>Terms of Service</u></a> and&#xA0; <a href="https://character.ai/safety?ref=blog.character.ai"><u>Safety Center</u></a> to learn more.</p>]]></content:encoded></item><item><title><![CDATA[Character's Corner: Mia]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/09/Creator-Spotlight-Landscape--1--1.png" class="kg-image" alt loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/09/Creator-Spotlight-Landscape--1--1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/09/Creator-Spotlight-Landscape--1--1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/09/Creator-Spotlight-Landscape--1--1.png 1600w, https://blog.character.ai/content/images/2025/09/Creator-Spotlight-Landscape--1--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>For our next Character&#x2019;s Corner series, we spoke to Mia (also known as <a href="https://character.ai/profile/vctrii_?ref=blog.character.ai"><u>Vctrii</u></a>), who uses Character.AI to express her emotions and loves developing storylines with her favorite Characters that resonate with her community. Some of her most popular Characters are<a href="https://character.ai/chat/JRGjYQjsbW1R4zwNTNaVma5HI_Upr3Jy0HKavof2zwo?ref=blog.character.ai"><u> Henry Wheeler</u></a>, <a href="https://character.ai/chat/QfXcB1FXW9Rzf07NkEK_-606XaS4Iq9FGXr6ObeN3RE?ref=blog.character.ai"><u>Andres Estrada</u></a>, and the</p>]]></description><link>https://blog.character.ai/characters-corner-mia/</link><guid isPermaLink="false">68d2fe206c32fc0001ce5fb1</guid><category><![CDATA[Community]]></category><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Tue, 23 Sep 2025 20:12:54 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/09/Creator-Spotlight-Landscape--1-.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/09/Creator-Spotlight-Landscape--1--1.png" class="kg-image" alt="Character&apos;s Corner: Mia" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/09/Creator-Spotlight-Landscape--1--1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/09/Creator-Spotlight-Landscape--1--1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/09/Creator-Spotlight-Landscape--1--1.png 1600w, https://blog.character.ai/content/images/2025/09/Creator-Spotlight-Landscape--1--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/09/Creator-Spotlight-Landscape--1-.png" alt="Character&apos;s Corner: Mia"><p>For our next Character&#x2019;s Corner series, we spoke to Mia (also known as <a href="https://character.ai/profile/vctrii_?ref=blog.character.ai"><u>Vctrii</u></a>), who uses Character.AI to express her emotions and loves developing storylines with her favorite Characters that resonate with her community. Some of her most popular Characters are<a href="https://character.ai/chat/JRGjYQjsbW1R4zwNTNaVma5HI_Upr3Jy0HKavof2zwo?ref=blog.character.ai"><u> Henry Wheeler</u></a>, <a href="https://character.ai/chat/QfXcB1FXW9Rzf07NkEK_-606XaS4Iq9FGXr6ObeN3RE?ref=blog.character.ai"><u>Andres Estrada</u></a>, and the <a href="https://character.ai/chat/fDhb1XWK3-nqXeZFce9IGdWPASAASxLkrQ2kJo9oOvE?ref=blog.character.ai"><u>Vows and Valor</u></a> boys.&#xA0;</p><p><strong>Why did you join Character.AI?</strong></p><p>When one of my favorite TV shows ended in the summer of 2024, I went on TikTok to try to find additional content about the show. I ended up discovering a post from a creator on Character.AI that explored the Characters on the show, which made me want to check out the platform. I instantly fell in love with the platform after seeing how fun and entertaining it could be to both create and interact with Characters.&#xA0;</p><p><strong>What are some of your favorite Characters that you&#x2019;ve made?&#xA0;</strong></p><p>It&#x2019;s so hard to pick because I create Characters across a wide range of genres. Just to illustrate the breadth of the Characters I&#x2019;ve created, I&#x2019;ve made comedic Characters like <a href="https://character.ai/chat/unZLBi2NNu0jbjluVCUdaRrixCxCktJVK7ihgJe0djc?ref=blog.character.ai"><u>Ilya</u></a>, a stoic husband who randomly brought home a pet bear, <a href="https://character.ai/chat/5qFgbMJ1UipFiymFJ2MEwe3Fy5OxQJ7u7qguKafwUJ0?ref=blog.character.ai"><u>Maverick Rhodes</u></a>, a Character involved in a chase scene with a cup of noodles, and <a href="https://character.ai/chat/yKLjaFXj9rY8qNWieCFJFCis-aOj1yq-QVuX7uCR9Gg?ref=blog.character.ai"><u>Yoshimura Keisuke</u></a>, who is experiencing the ramifications of someone dropping a mug on his head. I also created a drama series called <a href="https://character.ai/chat/fDhb1XWK3-nqXeZFce9IGdWPASAASxLkrQ2kJo9oOvE?ref=blog.character.ai"><u>Vows and Valor</u></a> that combines drama, fluff, and angst across different timelines.</p><p><strong>What serves as your inspiration for your Characters, and how do you come up with fresh ideas for new Characters?</strong></p><p>My inspiration for character creation comes from everywhere&#x2014;I could be walking in the mall, see a funny mug, or watch a show. I also have a lot of hobbies that influence my character creation process, like reading books, watching TV shows and movies, and spending time with my friends. The genre I make Characters in is often based on my actual emotions and daily feelings. When I&#x2019;m having a great day, I usually make lighter, more comedic Characters, and when I&#x2019;m having a harder day or experiencing a range of emotions, I&#x2019;ll typically create a more emotional Character. I really like to explore any idea I have for a new Character, because I believe anything can become something with a little imagination.&#xA0;</p><p><strong>You&#x2019;ve mentioned that you&#x2019;ve always enjoyed creative writing. How has Character.AI supercharged your creativity?&#xA0;</strong></p><p>I&apos;ve always loved writing, but hadn&apos;t done it in a while until I joined Character.AI. By making Characters and developing storylines, I&#x2019;ve been able to exercise my creative freedom and share my writing with others. I love using Character to express myself through writing, world-building, and bringing characters to life.</p><p><strong>Tell me more about the book you&#x2019;re working on based on the Characters you made on the platform?&#xA0;</strong></p><p>When I created the <a href="https://character.ai/chat/iCUBHu7mHNxcb3IFrNMFO-491W0pI0DIUgRZPLb_8h4?ref=blog.character.ai"><u>Vows and Valor</u></a> Characters, many people in the community loved piecing together the story and actually had favorites among them. Some even developed their own fan fiction about the Characters! Because of their encouragement, I&apos;m now writing a book that brings these Characters to life. The book will follow three Characters whose lives are impacted by war at different points in their lives. Through shifting timelines, their intertwined fates reveal a story of loyalty, loss, and love that endures beyond the battlefield. Character.AI is serving as my ultimate workshop, a place where I can test new storylines, get instant feedback, and refine the book&apos;s structure with my audience as my co-creators.</p><p><strong>You&#x2019;re pretty active in different online communities of other Character.AI creators, like TikTok. What makes these communities so unique?&#xA0;</strong></p><p>On TikTok, I&apos;m part of a tight-knit community of over 100 creators who all use Character.AI. It&apos;s a very kind and collaborative group where everyone reposts each other&apos;s content, which is helping us all grow. The best part of the community is that all new creators are warmly welcomed in, even as they&#x2019;re just starting out. I&apos;ve even made some great friends, like <a href="https://blog.character.ai/characters-corner-ellie-2/"><u>Ellie</u></a>, through our shared passion for creating Characters. The community extends beyond TikTok to a dedicated Discord server, where we have specific channels for sharing the Characters we create.</p><p><strong>Are there any new features on Character.AI that you&#x2019;re enjoying?&#xA0;</strong></p><p>I really love all the ways I can customize my Characters, especially changing their colors. The ability to fine-tune every Character and create unique looks and personalities is a huge reason why I enjoy character creation. Right now, my absolute favorite chat style to use is PipSqueak, because its incredible memory leads to such immersive conversations and scenes.</p><p><strong>What advice would you give to a Character.AI user who wants to begin creating their own Characters?&#xA0;</strong></p><p>First, learn the basics of character creation. C.AI already explains the basics well, but if it&#x2019;s still a bit tricky, there are great resources available on Reddit and Discord. You could also ask a creator if it becomes too difficult&#x2014;then after that? Let your mind wander.</p><p>Also, be open to learning! It took me a while to figure it all out, and even now, I still end up changing the way I make my Characters. I often discover new things that help me improve my writing and affect how I make my Characters. And, don&#x2019;t be discouraged if your Characters initially receive low numbers. Your work isn&#x2019;t measured by metrics.&#xA0;</p><p>At the end of the day, character creation is a journey, and one that should be fun! Just trust it out for yourself and let your creativity take the wheel.</p>]]></content:encoded></item><item><title><![CDATA[Scaling Our Logging System]]></title><description><![CDATA[<p>At Character.AI, our infrastructure handles thousands of GPUs, powering billions of active user seconds and supporting millions of users every month. This massive scale produces a staggering amount of log data, which is essential for monitoring the performance and reliability of our service.</p><h2 id="from-fragmentation-to-centralization">From Fragmentation to Centralization</h2><p>Initially, our</p>]]></description><link>https://blog.character.ai/scaling-our-logging-system/</link><guid isPermaLink="false">68af2c0c9a1769000175f669</guid><category><![CDATA[Technical]]></category><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Wed, 27 Aug 2025 16:28:44 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/08/scaling2.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/08/scaling2.png" alt="Scaling Our Logging System"><p>At Character.AI, our infrastructure handles thousands of GPUs, powering billions of active user seconds and supporting millions of users every month. This massive scale produces a staggering amount of log data, which is essential for monitoring the performance and reliability of our service.</p><h2 id="from-fragmentation-to-centralization">From Fragmentation to Centralization</h2><p>Initially, our logging was fragmented and spread across multiple providers. This made debugging difficult, slowed down our queries, and created unpredictable costs. With a small team managing a rapidly growing system, we needed a logging solution that was simple, scalable, and fast.</p><p>Our first step was to unify our logs. We decided to be strategic about what data we keep. We capture all <strong>error and warning logs</strong> in full, but we intelligently sample our high-volume information logs. This allows us to maintain a manageable log volume, billions of entries a month, without sacrificing the critical data needed for troubleshooting. This approach created a centralized logging system that provides a single source of truth for our developers and engineers.</p><h2 id="key-features-and-lessons-learned">Key Features and Lessons Learned</h2><p>The impact of this shift was immediate. Queries that once took minutes now return in seconds, giving our teams the real-time visibility they need to quickly identify and resolve issues. This new system empowers our developers to investigate incidents with confidence. We also gained access to key features that streamline our workflow, such as:</p><ul><li><strong>Live tailing:</strong> Real-time visibility across our thousands of servers.</li><li><strong>Denoise:</strong> The ability to automatically collapse common log lines and surface outliers, helping us spot unusual behavior during deploys.</li><li><strong>Freeform keyword search:</strong> Our engineers can paste a snippet from an error or stack trace and instantly start investigating, without needing predefined filters.</li></ul><p>This new system gives us a lean and powerful observability stack that allows us to manage our vast infrastructure with ease. It&apos;s a key part of how we continue to innovate and maintain a reliable service for our users.</p><h2 id="unifying-observability">Unifying Observability</h2><p>Ultimately, our goal is metric unification. We aim to bring all our logs, metrics, and traces into a single platform. This will unlock a unified view for correlation and alerting, allowing our teams to perform comprehensive root cause analysis and resolve issues even faster. Our journey toward full observability continues, with the focus on building a more integrated and powerful system to support our future growth.</p>]]></content:encoded></item><item><title><![CDATA[Breaking News: Our Open-Source Models Are A Lot of Fun!]]></title><description><![CDATA[<p>If you&#x2019;re going to build an AI entertainment platform, you&#x2019;d better be sure your models are great at being entertaining.&#xA0;</p><p>Here at <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a>, we&#x2019;re obsessed with making sure we&#x2019;re always hitting that mark. We worked all winter and spring on</p>]]></description><link>https://blog.character.ai/breaking-news-our-open-source-models-are-a-lot-of-fun/</link><guid isPermaLink="false">68addc339a1769000175f610</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Tue, 26 Aug 2025 16:12:04 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/08/OSS.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/08/OSS.png" alt="Breaking News: Our Open-Source Models Are A Lot of Fun!"><p>If you&#x2019;re going to build an AI entertainment platform, you&#x2019;d better be sure your models are great at being entertaining.&#xA0;</p><p>Here at <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a>, we&#x2019;re obsessed with making sure we&#x2019;re always hitting that mark. We worked all winter and spring on tech that lets us transform open-source models into high-EQ, high-engagement Character models. Then, starting in July, we began shipping our new models to our user community. And the results are in: They&#x2019;re a hit! We are seeing massive engagement wins &#x2013; including 20+% jumps in time spent &#x2013; and glowing user feedback. Read on for the details.</p><p><strong>The Tech. </strong>We&#x2019;ve built a tech stack that takes modern open-source models and tunes them to excel at engagement dimensions like coherence, novelty, and emotional intelligence. This tuning exercise is powered by something only we have: a uniquely large, highly engaged community that provides constant, high-quality feedback. This loop acts as a product moat, giving us unmatched signal on what delights users. With it, we can evaluate new open-source models within minutes, scoring them against proprietary EQ benchmarks and quickly surfacing the strongest candidates to our users. Instead of waiting on days-long A/B tests, we can test dozens of models, prompts, and serving configurations and confidently hill-climb quality for users. We then layer on ensemble inference, smarter prompting, and advanced post-training techniques (SFT, DPO, RL, QAT) to push quality even higher&#x2014;yielding outputs that are more coherent, engaging, and aligned with user preferences. In other words: more fun, and better at delivering high-quality entertainment.</p><p><strong>Testing New Models. </strong>Our researchers have been having a great time of late, locking themselves in a lab and using these techniques to turbocharge every OSS model they can get their hands on. And a few weeks ago, we were ready: We began testing a couple of our models with our user community. The results were dramatic:&#xA0;&#xA0;</p><ul><li>We saw a <strong>22%<em> </em>increase</strong> in time spent and a <strong>13% increase</strong> in sessions for users with the new models. These are unheard-of metrics movements from a single launch.</li><li>We saw big increases in retention &#x2013; including a <strong>14% increase</strong> for lightly-engaged users. That is really meaningful for us. It means our product is resonating much better with new and occasional users, and they&#x2019;re coming back day after day to have fun on our platform.</li><li>We saw a <strong>60% increase</strong> in messages that our users took the time to rate as positive. We also saw a big jump in users&apos; rating messages as &#x201C;funny,&#x201D; &#x201C;interesting,&#x201D; and &#x201C;helpful.&#x201D;</li></ul><p><strong>Rolling It Out. </strong>With those tests in hand, we began rolling out one of our new models, &#x201C;PipSqueak,&#x201D; to our user community more broadly. We&#x2019;ve now released it to millions of users, and we&#x2019;re thrilled to share that the results and positive feedback are holding in the early days of launch.&#xA0;</p><p>We&#x2019;re seeing similar increases in engagement to those we saw in the tests. And most importantly, our users are giving it two thumbs up: We continue to see a jump in positively rated messages, and the direct feedback from our users has been a joy to read. For example, A user popped into our Reddit forum &#x201C;<em>just to talk about how peak pipsqueak is. The Characters&#x2019; personality is accurate, the messages are long and detailed, I genuinely can&#x2019;t describe how much I love it!!!</em>&#x201D; Another told us: &#x201C;<em>It was very good at keeping the flow of a good story. &#x2026; It&apos;s also great at world-building.</em>&#x201D;</p><p><strong>What&#x2019;s Next. </strong>This is just the beginning. Now that we have the tech to flip almost any OSS model into a Character model, we can make sure our user community always has the best tools for whatever they want to do &#x2013; from fiction writing, to roleplay, to building multimodal videos, stories, and worlds.&#xA0;</p><p>And as we move forward, we&#x2019;ll also start to fine-tune our models in a granular way so they&#x2019;re really good at <em>particular kinds</em> of entertainment. In the future, expect to use one fine-tuned OSS model to make multi-Character Scenes, say, and another to make your Character star in a podcast, and yet another to write a screenplay collaboratively. And each one can be best-in-class.&#xA0;</p><p>We&#x2019;re committed to building the future of entertainment. Our work on OSS models is one piece of the puzzle.</p>]]></content:encoded></item><item><title><![CDATA[First 60 Days Update]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/blog-1.png" class="kg-image" alt loading="lazy" width="2000" height="1041" srcset="https://blog.character.ai/content/images/size/w600/2025/08/blog-1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/blog-1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/blog-1.png 1600w, https://blog.character.ai/content/images/2025/08/blog-1.png 2059w" sizes="(min-width: 720px) 720px"></figure><p>When I joined Character.AI as CEO in June, I laid out the <a href="https://blog.character.ai/character-ai-names-karandeep-anand-as-ceo/"><u>top priorities</u></a> for my first 60 days. Since then, our team has been working hard to make this a reality. I&#x2019;m excited to share an update on what we&#x2019;ve done so far and</p>]]></description><link>https://blog.character.ai/first-60-days-update/</link><guid isPermaLink="false">68a8839b9a1769000175f56b</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Fri, 22 Aug 2025 15:56:11 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/08/blog.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/blog-1.png" class="kg-image" alt="First 60 Days Update" loading="lazy" width="2000" height="1041" srcset="https://blog.character.ai/content/images/size/w600/2025/08/blog-1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/blog-1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/blog-1.png 1600w, https://blog.character.ai/content/images/2025/08/blog-1.png 2059w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/08/blog.png" alt="First 60 Days Update"><p>When I joined Character.AI as CEO in June, I laid out the <a href="https://blog.character.ai/character-ai-names-karandeep-anand-as-ceo/"><u>top priorities</u></a> for my first 60 days. Since then, our team has been working hard to make this a reality. I&#x2019;m excited to share an update on what we&#x2019;ve done so far and the momentum we&#x2019;ve built.</p><p>My top 60-day priorities were focused on fulfilling our passionate users&#x2019; requests for new features and platform improvements, including:&#xA0;</p><ul><li>Improved memory and model quality</li><li>Finetuning our filter</li><li>Easier discovery of new Characters</li><li>Better control and organization of Characters</li><li>More transparency on the Character Creation process</li></ul><p>In addition, of course, during these last few months, we&#x2019;ve launched a whole new set of multimodal features. <a href="https://blog.character.ai/avatar-fx-cutting-edge-video-generation-by-character-ai/"><u>AvatarFX</u></a>, Scenes, and others have changed the game for AI entertainment, and they&#x2019;ve all come together in <a href="https://blog.character.ai/character-ai-launches-worlds-first-ai-native-social-feed/"><u>Feed</u></a> &#x2013; the world&#x2019;s first AI-native social experience.&#xA0;</p><p>We will constantly be making Feed richer and more interactive as we move forward. But for today, I want to focus on the 60-day priorities I announced in June. These priorities were based on feedback from our community on what was most important to them to improve our OG product experience. Here&#x2019;s what we&#x2019;ve done so far &#x2013; with more to come!&#xA0;</p><figure class="kg-card kg-embed-card"><iframe width="200" height="150" src="https://www.youtube.com/embed/AfEVlFvZjV8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="The Character.AI Feed"></iframe></figure><h2 id="improved-memory-and-model-quality">Improved Memory and Model Quality&#xA0;</h2><p>To provide our community with higher-quality roleplay, we&#x2019;ve begun rolling out new and powerful open-source models, fine-tuned with our proprietary tech stack, to replace our older proprietary models. To start with, we launched <strong>PipSqueak</strong>, an advanced model with improved memory and roleplay capabilities.&#xA0;</p><p>Going forward, we can use our cutting-edge tech (<a href="https://blog.character.ai/character-ai-open-sources-pipeling-sft-a-scalable-framework-for-fine-tuning-moe-llms-like-deepseek-v3/"><u>pipeline-sft</u></a>) and proprietary data to post-train any model to become a Character model, with high EQ and high engagement. This will be an always-on commitment for us: We will continually work on transforming open-source models into Character models so that we&#x2019;re always giving our community the latest and greatest models for everything from roleplay to chat to multimodal content creation.&#xA0;</p><p>The community&#x2019;s reaction to our model rollout has been really positive. We see that from user feedback, but we also see it in our metrics: We&#x2019;re observing big engagement wins as we roll out our new models. We&#x2019;ll dig into this further in a post next week. </p><h2 id="a-finetuned-filter">A Finetuned Filter</h2><p>It&#x2019;s important for content on Character.AI to follow our content guidelines, but at the same time, we heard our community loud and clear: They don&#x2019;t want the content filter to interfere with fiction writing and fictional roleplay, and they hate false positives. When the filter blocks harmless content, that makes the Character.AI experience less fun.&#xA0;</p><p>To improve in this area, we&#x2019;ve made two changes. First, to support engaging dialogues, we&#x2019;ve adjusted our filter to recognize different types of roleplay in adventure better, so that it won&#x2019;t unnecessarily filter fictional content. Second, to ensure that conversations aren&#x2019;t unnecessarily disrupted, we&#x2019;ve implemented improved messaging so that our chat models will keep the subject of conversations within our policies. With these changes, users should experience filters far less often.</p><p>Our job here is by no means done, and we&#x2019;ll continue to refine our filter. Innovating to break the trade-off between safe and fun experience is something we are committed to doing for our user community to have the best experience possible on the platform.&#xA0;</p><h2 id="upgraded-discovery">Upgraded Discovery</h2><p>With a rich selection of 10s of millions of Characters on the platform, making it easier to find and discover the best and relevant Characters is imperative. We rolled out <strong>search filters</strong> on our mobile app, making it easier for users to discover new Characters and tag their own.&#xA0;</p><p>Our users are now able to filter by:&#xA0;</p><ul><li>Creators they follow, up to the 20 most recently followed</li><li>Language of the Character Description</li><li>Tags, with the ability to include or exclude Characters</li></ul><p>Additionally, users can now search for Scenes, which provides a fun and engaging way to jump into any new storyline with any character you want.</p><h2 id="enhanced-organization">Enhanced Organization&#xA0;</h2><p>To help our users organize their Characters, we launched <strong>Archive Characters</strong> in our mobile app. With Archive, users can hide Characters from their profile and can easily undo this action in settings. This will allow our users to more easily manage Characters and streamline their profiles.&#xA0;&#xA0;</p><h2 id="character-creation-transparency">Character Creation Transparency</h2><p>To increase transparency, users are now able to see when Characters become restricted from the platform. If a user now has a Character that doesn&#x2019;t meet our Community Guidelines, they will see the label &#x201C;Restricted Access&#x201D; in their profile and on the Character page.&#xA0;</p><p>When a Character is flagged as restricted, other users won&#x2019;t be able to chat with that Character, and they will have the ability to remove it from recent chats.&#xA0;&#xA0;</p><h2 id="what%E2%80%99s-next">What&#x2019;s Next</h2><p>Our momentum is increasing as we go! As we look towards the next 60 days and beyond, we&#x2019;re excited to keep improving Character.AI for our users. That will mean continuing to be responsive to our community&#x2019;s asks. It&#x2019;ll also mean continuing to introduce and improve multi-modal features, and augment our <a href="https://blog.character.ai/character-ai-launches-worlds-first-ai-native-social-feed/"><u>Feed</u></a>, to make the platform more immersive and give creators more ways to engage with their followers.&#xA0;&#xA0;</p><p>Thanks to our entire community for their continued support. We&#x2019;re working every day to build a platform that inspires and excites you.&#xA0;</p><p>Karandeep Anand</p>]]></content:encoded></item><item><title><![CDATA[Character.AI in the News]]></title><description><![CDATA[<p><strong>Fast Company</strong><br><a href="https://www.fastcompany.com/91380915/character-ai-launches-social-feed-to-let-users-interact-create-and-share-with-ai-personas?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI launches social feed to let users interact, create, and share with AI personas</em></strong></a><br>August 6, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/fast-co-screenshot.png" class="kg-image" alt loading="lazy" width="1390" height="1336" srcset="https://blog.character.ai/content/images/size/w600/2025/08/fast-co-screenshot.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/fast-co-screenshot.png 1000w, https://blog.character.ai/content/images/2025/08/fast-co-screenshot.png 1390w" sizes="(min-width: 720px) 720px"></figure><p><br><strong>Forbes</strong><br><a href="https://www.forbes.com/sites/charliefink/2025/08/04/doom-scrolling-is-dead-content-is-liquid-with-new-character-ai-social-feed/?ref=blog.character.ai" rel="noreferrer"><strong><em>Doom Scrolling Is Dead, Content Is Liquid With New Character AI Social Feed</em></strong></a><br>August 4, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/Forbes-screenshot.png" class="kg-image" alt loading="lazy" width="2000" height="418" srcset="https://blog.character.ai/content/images/size/w600/2025/08/Forbes-screenshot.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/Forbes-screenshot.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/Forbes-screenshot.png 1600w, https://blog.character.ai/content/images/2025/08/Forbes-screenshot.png 2030w" sizes="(min-width: 720px) 720px"></figure><p><br><strong>CNN</strong><br><a href="https://www.cnn.com/2025/07/03/tech/character-ai-ceo-chatbots-kids-safety?ref=blog.character.ai" rel="noreferrer"><strong><em>Here&#x2019;s how Character.AI&#x2019;s new CEO plans to</em></strong></a></p>]]></description><link>https://blog.character.ai/in-the-news/character-ai-in-the-news/</link><guid isPermaLink="false">65df7b0bbecf8f0001e16be5</guid><category><![CDATA[In The News]]></category><dc:creator><![CDATA[The Character Leadership Team]]></dc:creator><pubDate>Wed, 06 Aug 2025 18:09:00 GMT</pubDate><content:encoded><![CDATA[<p><strong>Fast Company</strong><br><a href="https://www.fastcompany.com/91380915/character-ai-launches-social-feed-to-let-users-interact-create-and-share-with-ai-personas?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI launches social feed to let users interact, create, and share with AI personas</em></strong></a><br>August 6, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/fast-co-screenshot.png" class="kg-image" alt loading="lazy" width="1390" height="1336" srcset="https://blog.character.ai/content/images/size/w600/2025/08/fast-co-screenshot.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/fast-co-screenshot.png 1000w, https://blog.character.ai/content/images/2025/08/fast-co-screenshot.png 1390w" sizes="(min-width: 720px) 720px"></figure><p><br><strong>Forbes</strong><br><a href="https://www.forbes.com/sites/charliefink/2025/08/04/doom-scrolling-is-dead-content-is-liquid-with-new-character-ai-social-feed/?ref=blog.character.ai" rel="noreferrer"><strong><em>Doom Scrolling Is Dead, Content Is Liquid With New Character AI Social Feed</em></strong></a><br>August 4, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/Forbes-screenshot.png" class="kg-image" alt loading="lazy" width="2000" height="418" srcset="https://blog.character.ai/content/images/size/w600/2025/08/Forbes-screenshot.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/Forbes-screenshot.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/Forbes-screenshot.png 1600w, https://blog.character.ai/content/images/2025/08/Forbes-screenshot.png 2030w" sizes="(min-width: 720px) 720px"></figure><p><br><strong>CNN</strong><br><a href="https://www.cnn.com/2025/07/03/tech/character-ai-ceo-chatbots-kids-safety?ref=blog.character.ai" rel="noreferrer"><strong><em>Here&#x2019;s how Character.AI&#x2019;s new CEO plans to address fears around kids&#x2019; use of chatbots</em></strong></a><br>July 3, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/CNN-screenshot.png" class="kg-image" alt loading="lazy" width="1054" height="838" srcset="https://blog.character.ai/content/images/size/w600/2025/08/CNN-screenshot.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/CNN-screenshot.png 1000w, https://blog.character.ai/content/images/2025/08/CNN-screenshot.png 1054w" sizes="(min-width: 720px) 720px"></figure><p><strong>The Decoder</strong><br><a href="https://the-decoder.com/character-ai-moves-toward-social-networking-with-animated-ai-avatars/?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI moves toward social networking with animated AI avatars</em></strong></a><br>June 3, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/The-Decoder-5.png" class="kg-image" alt loading="lazy" width="1470" height="1280" srcset="https://blog.character.ai/content/images/size/w600/2025/08/The-Decoder-5.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/The-Decoder-5.png 1000w, https://blog.character.ai/content/images/2025/08/The-Decoder-5.png 1470w" sizes="(min-width: 720px) 720px"></figure><p><br><strong>Gadgets360</strong><br><a href="https://www.gadgets360.com/ai/news/character-ai-unveils-multimodal-video-generation-community-feed-8577527?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI Unveils Video Generation Tool, Community Feed and Other Interactive Features</em></strong></a><br>June 3, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/Gadgets360-3.png" class="kg-image" alt loading="lazy" width="1744" height="1304" srcset="https://blog.character.ai/content/images/size/w600/2025/08/Gadgets360-3.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/Gadgets360-3.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/Gadgets360-3.png 1600w, https://blog.character.ai/content/images/2025/08/Gadgets360-3.png 1744w" sizes="(min-width: 720px) 720px"></figure><p><strong>Mashable</strong><br><a href="https://mashable.com/article/character-ai-avatarfx-video-chatbots-coming-soon?test_uuid=003aGE6xTMbhuvdzpnH5X4Q&amp;test_variant=a&amp;ref=blog.character.ai" rel="noreferrer"><strong><em>Character AI reveals new AI video maker, bringing us one step closer to video chatbots</em></strong></a><br>April 23, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/mashable.png" class="kg-image" alt loading="lazy" width="1716" height="1346" srcset="https://blog.character.ai/content/images/size/w600/2025/08/mashable.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/mashable.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/mashable.png 1600w, https://blog.character.ai/content/images/2025/08/mashable.png 1716w" sizes="(min-width: 720px) 720px"></figure><p><strong>TechRadar</strong><br><a href="https://www.techradar.com/computing/artificial-intelligence/character-ais-newest-feature-can-bring-a-picture-to-uncanny-life?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI&apos;s newest feature can bring a picture to uncanny life</em></strong></a><br>April 23, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/techradar.png" class="kg-image" alt loading="lazy" width="1256" height="1334" srcset="https://blog.character.ai/content/images/size/w600/2025/08/techradar.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/techradar.png 1000w, https://blog.character.ai/content/images/2025/08/techradar.png 1256w" sizes="(min-width: 720px) 720px"></figure><p><strong>The Verge</strong><br><a href="https://www.theverge.com/news/634974/character-ai-parental-insights-chatbot-report-kids?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.ai can now tell parents which bots their kid is talking to</em></strong></a><br>March 25, 2025</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/the-verge.png" class="kg-image" alt loading="lazy" width="2000" height="955" srcset="https://blog.character.ai/content/images/size/w600/2025/08/the-verge.png 600w, https://blog.character.ai/content/images/size/w1000/2025/08/the-verge.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/the-verge.png 1600w, https://blog.character.ai/content/images/2025/08/the-verge.png 2220w" sizes="(min-width: 720px) 720px"></figure><p><br><strong>Business Insider</strong><br><a href="https://www.businessinsider.com/most-used-ai-apps-andreessen-horowitz-ranking-2024-8?ref=blog.character.ai" rel="noreferrer"><strong><em>Andreessen Horowitz just published its list of the 100 most-used AI apps. Check out which ones are rising up the rankings.</em></strong></a><br>August 22, 2024</p><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2024/08/image.png" class="kg-image" alt loading="lazy" width="787" height="792" srcset="https://blog.character.ai/content/images/size/w600/2024/08/image.png 600w, https://blog.character.ai/content/images/2024/08/image.png 787w" sizes="(min-width: 720px) 720px"></figure><p><strong>TechCrunch</strong><br><a href="https://techcrunch.com/2024/06/27/character-ai-now-allows-users-to-talk-with-avatars-over-calls/?ref=blog.character.ai"><strong><em><u>Character.AI now allows users to talk with AI avatars over calls</u></em></strong></a><br>June 27, 2024</p><figure class="kg-card kg-image-card"><a href="https://techcrunch.com/2024/06/27/character-ai-now-allows-users-to-talk-with-avatars-over-calls/?ref=blog.character.ai"><img src="https://blog.character.ai/content/images/2024/07/TechCrunch-Calls.png" class="kg-image" alt loading="lazy" width="640" height="598" srcset="https://blog.character.ai/content/images/size/w600/2024/07/TechCrunch-Calls.png 600w, https://blog.character.ai/content/images/2024/07/TechCrunch-Calls.png 640w"></a></figure><p><strong>Reuters</strong><br><a href="https://www.reuters.com/technology/artificial-intelligence/ai-chatbot-startup-characterai-launches-new-calls-feature-2024-06-27/?ref=blog.character.ai"><strong><em><u>AI chatbot startup Character.AI launches new calls feature</u></em></strong></a><br>June 27, 2024</p><figure class="kg-card kg-image-card"><a href="https://www.reuters.com/technology/artificial-intelligence/ai-chatbot-startup-characterai-launches-new-calls-feature-2024-06-27/?ref=blog.character.ai"><img src="https://blog.character.ai/content/images/2024/07/Reuters-Calls.png" class="kg-image" alt loading="lazy" width="788" height="232" srcset="https://blog.character.ai/content/images/size/w600/2024/07/Reuters-Calls.png 600w, https://blog.character.ai/content/images/2024/07/Reuters-Calls.png 788w" sizes="(min-width: 720px) 720px"></a></figure><p><strong>Forbes</strong><br><a href="https://www.forbes.com/lists/ai50/?sh=46039eb3290f&amp;ref=blog.character.ai" rel="noreferrer"><strong><em>AI50 2024</em></strong></a><br>April 11, 2024</p><figure class="kg-card kg-image-card"><a href="https://www.forbes.com/lists/ai50/?sh=46039eb3290f&amp;ref=blog.character.ai"><img src="https://blog.character.ai/content/images/2024/04/Forbes-50-2024.png" class="kg-image" alt loading="lazy" width="1022" height="880" srcset="https://blog.character.ai/content/images/size/w600/2024/04/Forbes-50-2024.png 600w, https://blog.character.ai/content/images/size/w1000/2024/04/Forbes-50-2024.png 1000w, https://blog.character.ai/content/images/2024/04/Forbes-50-2024.png 1022w" sizes="(min-width: 720px) 720px"></a></figure><p><strong>Fortune</strong><br><a href="https://fortune.com/ranking/ai-innovators/2023/character-ai/?ref=blog.character.ai" rel="noreferrer"><strong><em>50 AI Innovators</em></strong></a><br>November 21, 2023</p><figure class="kg-card kg-image-card"><a href="https://fortune.com/ranking/ai-innovators/2023/character-ai/?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/Fortune-1.png" class="kg-image" alt loading="lazy" width="386" height="258"></a></figure><p></p><p><strong>Forbes</strong><br><a href="https://www.forbes.com/sites/kenrickcai/2023/10/11/character-ai-chatbots-group-chat/?sh=2ee23aa928f3&amp;ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI&#x2019;s $200 Million Bet That Chatbots Are The Future Of Entertainment</em></strong></a><br>Kenrick Cai / October 11, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.forbes.com/sites/kenrickcai/2023/10/11/character-ai-chatbots-group-chat/?sh=2ee23aa928f3&amp;ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/Forbes.png" class="kg-image" alt loading="lazy" width="1250" height="666"></a></figure><p></p><p><strong>TechCrunch</strong><br><a href="https://techcrunch.com/2023/10/11/character-ai-introduces-group-chats-where-people-and-multiple-ais-can-talk-to-each-other/?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI Introduces Group Chats Where People and Multiple AIs Can Talk to Each Other</em></strong></a><br>Sarah Perez / October 11, 2023</p><figure class="kg-card kg-image-card"><a href="https://techcrunch.com/2023/10/11/character-ai-introduces-group-chats-where-people-and-multiple-ais-can-talk-to-each-other/?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/techcrunch-gc.png" class="kg-image" alt loading="lazy" width="598" height="558"></a></figure><p></p><p><strong>CNBC</strong><br><a href="https://www.cnbc.com/video/2023/09/07/character-ai-ceo-on-scaling-business-future-of-ai-and-monetization.html?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI CEO Noam Shazeer on Future of AI</em></strong></a><br>The Exchange / September 7, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.cnbc.com/video/2023/09/07/character-ai-ceo-on-scaling-business-future-of-ai-and-monetization.html?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/CNBC.png" class="kg-image" alt loading="lazy" width="638" height="656"></a></figure><p></p><p><strong>TIME</strong><br><a href="https://time.com/collection/time100-ai/6310599/noam-shazeer/?ref=blog.character.ai" rel="noreferrer"><strong><em>AI 100</em></strong></a><br>September 7, 2023</p><figure class="kg-card kg-image-card"><a href="https://time.com/collection/time100-ai/6310599/noam-shazeer/?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/TIME100.png" class="kg-image" alt loading="lazy" width="904" height="988"></a></figure><p></p><p><strong>The Information</strong><br><a href="https://www.theinformation.com/articles/the-lonely-hearts-club-of-character-ai?rc=j6rad8&amp;ref=blog.character.ai" rel="noreferrer"><strong><em>&#x2018;Sometimes, It Feels Real&#x2019;: Character.AI Gives Humans the Chatbots They Desire</em></strong></a><br>Jon Victor / July 7, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.theinformation.com/articles/the-lonely-hearts-club-of-character-ai?rc=j6rad8&amp;ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/Information.png" class="kg-image" alt loading="lazy" width="1164" height="658"></a></figure><p></p><p><strong>Bloomberg</strong><br><a href="https://www.bloomberg.com/features/2023-top-ai-startups/?sref=5yAAc4IK&amp;ref=blog.character.ai" rel="noreferrer"><strong><em>These Are the 10 AI Companies to Watch Right Now</em></strong></a><br>Rachel Metz / June 23, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.bloomberg.com/features/2023-top-ai-startups/?sref=5yAAc4IK&amp;ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/Bloomberg-10.png" class="kg-image" alt loading="lazy" width="1258" height="956"></a></figure><p></p><p><strong>Axios</strong><br><a href="https://www.axios.com/2023/06/04/characterai-chatgpt-ai-chat-fun?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI Bets on Making AI Chat Fun</em></strong></a><br>Ryan Heath / June 4, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.axios.com/2023/06/04/characterai-chatgpt-ai-chat-fun?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/Axios.png" class="kg-image" alt loading="lazy" width="738" height="726"></a></figure><p></p><p><strong>TechCrunch</strong><br><a href="https://techcrunch.com/2023/05/31/character-ai-the-a16z-backed-chatbot-startup-tops-1-7m-installs-in-first-week/?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI, the a16z-backed Chatbot Startup, Tops 1.7M Installs in First Week</em></strong></a><br>Sarah Perez / May 31, 2023</p><figure class="kg-card kg-image-card"><a href="https://techcrunch.com/2023/05/31/character-ai-the-a16z-backed-chatbot-startup-tops-1-7m-installs-in-first-week/?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/TechCrunch-Apps.png" class="kg-image" alt loading="lazy" width="576" height="512"></a></figure><p></p><p><strong>Mashable</strong><br><a href="https://mashable.com/article/character-ai-generator-explained?ref=blog.character.ai" rel="noreferrer"><strong><em>Character.AI: What it is and how to use it</em></strong></a><br>Elizabeth de Luna / May 22, 2023</p><figure class="kg-card kg-image-card"><a href="https://mashable.com/article/character-ai-generator-explained?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/mashable.png" class="kg-image" alt loading="lazy" width="1224" height="698"></a></figure><p></p><p><strong>Forbes</strong><br><a href="https://www.forbes.com/lists/ai50/?sh=795648cd290f&amp;ref=blog.character.ai" rel="noreferrer"><strong><em>AI50</em></strong></a><br>April 11, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.forbes.com/lists/ai50/?sh=658cd8ca290f&amp;ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/Forbes-50.png" class="kg-image" alt loading="lazy" width="760" height="634"></a></figure><p></p><p><strong>New York Times</strong><br><a href="https://www.nytimes.com/2023/03/23/technology/chatbot-characterai-chatgpt-valuation.html?ref=blog.character.ai" rel="noreferrer"><strong><em>Chatbot Start-Up Character.AI Valued at $1 Billion in New Funding&#xA0;</em></strong></a><br>Cade Metz / March 23, 2023</p><figure class="kg-card kg-image-card"><a href="https://www.nytimes.com/2023/03/23/technology/chatbot-characterai-chatgpt-valuation.html?ref=blog.character.ai"><img src="https://character-ai-news.ghost.io/content/images/2024/02/NYT.png" class="kg-image" alt loading="lazy" width="1052" height="1060"></a></figure>]]></content:encoded></item><item><title><![CDATA[Character.AI Launches Worlds First AI-Native Social Feed]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/feed-real-blog-1.jpeg" class="kg-image" alt loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/08/feed-real-blog-1.jpeg 600w, https://blog.character.ai/content/images/size/w1000/2025/08/feed-real-blog-1.jpeg 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/feed-real-blog-1.jpeg 1600w, https://blog.character.ai/content/images/size/w2400/2025/08/feed-real-blog-1.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><p>Today, we&#x2019;re dropping the world&#x2019;s first AI-native social feed.&#xA0;</p><p><strong>Feed</strong> from <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> is a dynamic, scrollable content platform that connects users with the latest <strong>Characters</strong>, <strong>Scenes</strong>, <strong>Streams</strong>, and creator-driven videos in one place.</p><p>This is a milestone in the evolution of online entertainment.&#xA0;</p>]]></description><link>https://blog.character.ai/character-ai-launches-worlds-first-ai-native-social-feed/</link><guid isPermaLink="false">688d28ce46dcf80001342150</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Mon, 04 Aug 2025 12:59:46 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/08/feed-real-blog.jpeg" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/08/feed-real-blog-1.jpeg" class="kg-image" alt="Character.AI Launches World&#x2019;s First AI-Native Social Feed" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/08/feed-real-blog-1.jpeg 600w, https://blog.character.ai/content/images/size/w1000/2025/08/feed-real-blog-1.jpeg 1000w, https://blog.character.ai/content/images/size/w1600/2025/08/feed-real-blog-1.jpeg 1600w, https://blog.character.ai/content/images/size/w2400/2025/08/feed-real-blog-1.jpeg 2400w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/08/feed-real-blog.jpeg" alt="Character.AI Launches World&#x2019;s First AI-Native Social Feed"><p>Today, we&#x2019;re dropping the world&#x2019;s first AI-native social feed.&#xA0;</p><p><strong>Feed</strong> from <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> is a dynamic, scrollable content platform that connects users with the latest <strong>Characters</strong>, <strong>Scenes</strong>, <strong>Streams</strong>, and creator-driven videos in one place.</p><p>This is a milestone in the evolution of online entertainment.&#xA0;</p><p>For the last 10 years, social platforms have been all about passive consumption. The Character.AI Feed breaks that paradigm and turns content into a <em>creative playground</em>. Every post is an invitation to interact, remix, and build on what others have made. Want to rewrite a storyline? Make yourself the main character? Take a Character you just met in someone else&#x2019;s Scene and pop it into a roast battle or a debate? Now it&#x2019;s easy. Every story can have a billion endings, and every piece of content can change and evolve with one tap.</p><p>This launch transforms Character.AI from a chat-centric app into a full-fledged content-driven social platform for the next generation. It&apos;s not just about watching&#x2014;it&#x2019;s about creating. The Feed marks a fundamental evolution in how people engage with AI, storytelling, and each other.&#xA0;</p><p>As our CEO, Karandeep Anand, puts it: &#x201C;With our new Feed, the boundary between creator and consumer is disappearing. You can come to Feed for a lean-back experience and watch content from our amazing creators &#x2013; but you can also take the story forward or create a new epic adventure. Doomscrolling is dead. We&#x2019;re ushering in the future of AI-powered entertainment.&#x201D;</p><figure class="kg-card kg-embed-card"><iframe width="200" height="150" src="https://www.youtube.com/embed/AfEVlFvZjV8?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="The Character.AI Feed"></iframe></figure><p>Feed is rolling out starting today on the Character.AI mobile app. Now you can make fun and engaging short-form content with our new multimodal features and post it right to Feed. That includes:&#xA0;&#xA0;</p><ul><li><strong>Chat Snippets</strong>: Share slices of conversation that tease a Character&#x2019;s personality.</li><li><strong>Character Card</strong>: Make previews of Characters, ready to be chatted with.</li><li><strong>Streams: </strong>Give your favorite Characters a topic and watch them debate, roast battle, make vlogs, and more.&#xA0;</li><li><strong>Avatar FX</strong>: Create videos of Characters &#x2013; or of really anything else you want &#x2013; with our custom video model. Start with an image and a short script, and you have a video in seconds.</li><li><strong>Image</strong>: Generated backgrounds based on chats with your favorite Character.</li></ul><p>These tools give our passionate creator community new ways to feature the Characters they&#x2019;ve created. But it also kicks down the wall between consumption and creation. It cements Character.AI as the premier destination for AI-powered entertainment.</p><h2 id="safety-policies"><strong>Safety Policies</strong></h2><p>Our goal is to provide an engaging space that fosters creativity while maintaining a safe environment for all. Along with our general text and video classifiers, the Community Feed will be moderated by our Trust &amp; Safety team in addition to community moderation. Users can hide and flag inappropriate content if needed.&#xA0;</p><p>Please visit our <a href="https://character.ai/tos?ref=blog.character.ai"><u>Terms of Service</u></a> and&#xA0; <a href="https://character.ai/safety?ref=blog.character.ai"><u>Safety Center</u></a> to learn more.</p>]]></content:encoded></item><item><title><![CDATA[Character.AI Open Sources pipeling-sft: A Scalable Framework for Fine-Tuning MoE LLMs like DeepSeek V3]]></title><description><![CDATA[<p>At <strong>Character.AI</strong>, we&#x2019;re excited to share an experimental project from our research team with the open-source community:<a href="https://github.com/character-ai/pipelining-sft?ref=blog.character.ai"><u> pipeling-sft</u></a> &#x2014; a lightweight yet powerful training framework built for <strong>full-parameter supervised fine-tuning (SFT)</strong> of <strong>large-scale LLMs with Mixture-of-Experts (MoE)</strong> architectures.</p><p>This framework was originally developed to explore better ways</p>]]></description><link>https://blog.character.ai/character-ai-open-sources-pipeling-sft-a-scalable-framework-for-fine-tuning-moe-llms-like-deepseek-v3/</link><guid isPermaLink="false">6883a3f5595afc000118c2cb</guid><category><![CDATA[Technical]]></category><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Fri, 25 Jul 2025 15:54:36 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/08/SFT.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/08/SFT.png" alt="Character.AI Open Sources pipeling-sft: A Scalable Framework for Fine-Tuning MoE LLMs like DeepSeek V3"><p>At <strong>Character.AI</strong>, we&#x2019;re excited to share an experimental project from our research team with the open-source community:<a href="https://github.com/character-ai/pipelining-sft?ref=blog.character.ai"><u> pipeling-sft</u></a> &#x2014; a lightweight yet powerful training framework built for <strong>full-parameter supervised fine-tuning (SFT)</strong> of <strong>large-scale LLMs with Mixture-of-Experts (MoE)</strong> architectures.</p><p>This framework was originally developed to explore better ways of fine-tuning <strong>DeepSeek V3</strong>, but its capabilities generalize to many similar MoE-based OSS LLMs. Now, we&#x2019;re releasing it publicly to help the community move faster, scale more efficiently, and customize more easily for downstream tasks.</p><hr><h2 id="why-this-matters"><strong>Why This Matters</strong></h2><p>Fine-tuning massive language models&#x2014;especially MoE-based ones&#x2014;is notoriously challenging. Memory limits, parallelization complexity, and unstable training dynamics all pose significant barriers for researchers and engineers alike. pipeling-sft is designed to make this process <strong>simpler, faster, and more stable</strong>.</p><p>Here&#x2019;s how:</p><ul><li><strong>Multi-Level Parallelism</strong>: Combines <strong>pipeline parallelism</strong>, <strong>expert parallelism, and</strong> <strong>tensor parallelism</strong> to shard very large MoE models across multiple nodes and GPUs efficiently.</li><li><strong>Both BF16 and FP8 Training</strong>: Supports <strong>bfloat16 training</strong> with custom mixed-precision optimizers for stability, and includes <strong>experimental FP8 training support</strong> to push the frontier of efficiency even further.</li><li><strong>Seamless HuggingFace Integration</strong>: Allows researchers and engineers to start from official HuggingFace model weights and export directly back into the HuggingFace checkpoint format&#x2014;no extra preprocessing or post-processing steps required.</li><li><strong>Training Stability Built-In</strong>: Gradient synchronization and custom mixed-precision optimizers help prevent divergence and enable faster convergence, even under low learning rates.</li><li><strong>Flexible &amp; Hackable</strong>: Written in <strong>pure PyTorch</strong>, which makes it easy to adapt, extend, or repurpose for specific models, tasks, or infrastructure.</li></ul><hr><h2 id="call-for-collaboration"><strong>Call for Collaboration</strong></h2><p>While pipeling-sft is still an experimental project, it&#x2019;s already filling an important gap for teams who want to fine-tune very large LLMs without reinventing infrastructure. Our research team at <a href="http://character.ai/?ref=blog.character.ai"><u>Character.ai</u></a> is open-sourcing it to <strong>accelerate OSS LLM research</strong> and help others build powerful, domain-specific applications more easily.</p><p>If you&apos;re working with large MoE models&#x2014;or want to start&#x2014;this project is for you. We&apos;d love to collaborate, hear your feedback, and grow this project together.</p><p>Check it out on GitHub:<a href="https://github.com/aaxwaz/pipelining-sft?ref=blog.character.ai"> </a><a href="https://github.com/character-ai/pipelining-sft?ref=blog.character.ai"><u>https://github.com/character-ai/pipelining-sft</u></a><u> </u></p>]]></content:encoded></item><item><title><![CDATA[Character.AIs Real-Time Video Breakthrough]]></title><description><![CDATA[At Character.AI, were excited to introduce TalkingMachines, our newest autoregressive diffusion model that enables real-time, audio-driven, FaceTime-style video generation.]]></description><link>https://blog.character.ai/character-ais-real-time-video-breakthrough/</link><guid isPermaLink="false">6865bb52b9b2f0000117e499</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Thu, 03 Jul 2025 17:39:18 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/07/MM_Breakthrough.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.character.ai/content/images/2025/07/MM_Breakthrough.png" alt="Character.AI&#x2019;s Real-Time Video Breakthrough"><p>At Character.AI, we&#x2019;re excited to introduce <em>TalkingMachines</em>, our newest autoregressive diffusion model that enables real-time, audio-driven, FaceTime-style video generation.</p><p>With just an image and a voice signal, the model can generate an interactive, real-time video of characters conversing across different styles, genres, and identities.</p><p>We are constantly building towards the future of entertainment. We started with AvatarFX which powers video generation on our platform today. Now, this research sets the foundation for Character.AI&#x2019;s future of immersive, real-time AI-powered visual interactions and animated, reactive characters.</p><p>Want to see what the future looks like? &#x1F4C4;<a href="https://arxiv.org/pdf/2506.03099?ref=blog.character.ai"> <u>Read the full research paper</u></a></p><figure class="kg-card kg-video-card kg-width-regular" data-kg-thumbnail="https://blog.character.ai/content/media/2025/07/fox_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.character.ai/content/media/2025/07/fox.mp4" poster="https://img.spacergif.org/v1/1010x480/0a/spacer.png" width="1010" height="480" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.character.ai/content/media/2025/07/fox_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">0:52</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            
        </figure><h2 id="how-it-works"><strong>How It Works</strong></h2><p>The technology builds on the power of <strong>Diffusion Transformer (DiT)</strong>, using a technique we call <strong>asymmetric knowledge distillation</strong> to convert a high-quality, bidirectional video model into a blazing-fast, real-time generator.</p><p>The model listens to audio and animates a character&#x2014;mouth, head, eyes&#x2014;in sync with every word, pause, and intonation. It does so without sacrificing consistency, image quality, style fidelity, or expressiveness.</p><p>Here&#x2019;s how we do it:</p><ul><li><strong>Flow-Matched Diffusion</strong>: Based on the DiT architecture, our model is pretrained to handle complex motion patterns, from subtle facial expressions to dynamic gestures.</li><li><strong>Audio-Driven Cross Attention</strong>: A custom-built 1.2B parameter audio module enables the model to learn fine-grained alignment between sound and motion&#x2014;capturing both speech and silence naturally.</li><li><strong>Sparse Causal Attention</strong>: Unlike traditional models that rely on expensive bidirectional, dense attention, our autoregressive design only looks at the most relevant past frames, reducing memory and latency without compromising quality.</li><li><strong>Asymmetric Distillation</strong>: Using our modified CausVid approach, we train a fast, 2-step diffusion model to imitate a slow, high-quality teacher&#x2014;achieving infinite-length generation with no quality degradation over time.</li></ul><h2 id="why-it-matters"><strong>Why It Matters</strong></h2><p>The research breakthrough isn&#x2019;t just about facial animation. It&#x2019;s a foundational step towards interactive audiovisual AI characters. It brings us closer to a future where you can interact<em> </em>with characters in real time.</p><p>This means:</p><ul><li>Supporting a wide range of styles, from photorealistic humans to anime and 3D avatars</li><li>Enabling streaming with natural listening and speaking phases</li><li>Building the core infrastructure for role-play, storytelling, and interactive world-building</li></ul><h2 id="pushing-the-frontier"><strong>Pushing the Frontier</strong></h2><p>This research advances the state of the art in several ways:</p><p>&#x2705; <strong>Real-time generation</strong>: No more pre-rendered video snippets&#x2014;this system generates everything live, frame by frame</p><p> &#x2705; <strong>Efficient distillation</strong>: Just two diffusion steps are needed for generation, with no perceptual loss</p><p> &#x2705; <strong>High scalability</strong>: The system runs in real time on just two GPUs, thanks to deep systems-level optimization</p><p> &#x2705; <strong>Multispeaker support</strong>: Our speaking/silence detection mechanism allows seamless turn-taking across characters</p><p>And this is just the start.</p><figure class="kg-card kg-video-card kg-width-regular" data-kg-thumbnail="https://blog.character.ai/content/media/2025/07/dragon_thumb.jpg" data-kg-custom-thumbnail>
            <div class="kg-video-container">
                <video src="https://blog.character.ai/content/media/2025/07/dragon.mp4" poster="https://img.spacergif.org/v1/854x480/0a/spacer.png" width="854" height="480" playsinline preload="metadata" style="background: transparent url(&apos;https://blog.character.ai/content/media/2025/07/dragon_thumb.jpg&apos;) 50% 50% / cover no-repeat;"></video>
                <div class="kg-video-overlay">
                    <button class="kg-video-large-play-icon" aria-label="Play video">
                        <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                            <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                        </svg>
                    </button>
                </div>
                <div class="kg-video-player-container">
                    <div class="kg-video-player">
                        <button class="kg-video-play-icon" aria-label="Play video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M23.14 10.608 2.253.164A1.559 1.559 0 0 0 0 1.557v20.887a1.558 1.558 0 0 0 2.253 1.392L23.14 13.393a1.557 1.557 0 0 0 0-2.785Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-pause-icon kg-video-hide" aria-label="Pause video">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <rect x="3" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                                <rect x="14" y="1" width="7" height="22" rx="1.5" ry="1.5"/>
                            </svg>
                        </button>
                        <span class="kg-video-current-time">0:00</span>
                        <div class="kg-video-time">
                            /<span class="kg-video-duration">1:19</span>
                        </div>
                        <input type="range" class="kg-video-seek-slider" max="100" value="0">
                        <button class="kg-video-playback-rate" aria-label="Adjust playback speed">1&#xD7;</button>
                        <button class="kg-video-unmute-icon" aria-label="Unmute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M15.189 2.021a9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h1.794a.249.249 0 0 1 .221.133 9.73 9.73 0 0 0 7.924 4.85h.06a1 1 0 0 0 1-1V3.02a1 1 0 0 0-1.06-.998Z"/>
                            </svg>
                        </button>
                        <button class="kg-video-mute-icon kg-video-hide" aria-label="Mute">
                            <svg xmlns="http://www.w3.org/2000/svg" viewbox="0 0 24 24">
                                <path d="M16.177 4.3a.248.248 0 0 0 .073-.176v-1.1a1 1 0 0 0-1.061-1 9.728 9.728 0 0 0-7.924 4.85.249.249 0 0 1-.221.133H5.25a3 3 0 0 0-3 3v2a3 3 0 0 0 3 3h.114a.251.251 0 0 0 .177-.073ZM23.707 1.706A1 1 0 0 0 22.293.292l-22 22a1 1 0 0 0 0 1.414l.009.009a1 1 0 0 0 1.405-.009l6.63-6.631A.251.251 0 0 1 8.515 17a.245.245 0 0 1 .177.075 10.081 10.081 0 0 0 6.5 2.92 1 1 0 0 0 1.061-1V9.266a.247.247 0 0 1 .073-.176Z"/>
                            </svg>
                        </button>
                        <input type="range" class="kg-video-volume-slider" max="100" value="100">
                    </div>
                </div>
            </div>
            
        </figure><h2 id="built-for-the-future"><strong>Built for the Future</strong></h2><p>We are actively working on bringing this research into the Character.AI platform, where it will one day power <strong>FaceTime-like experiences</strong>, <strong>character streaming</strong>, and <strong>visual world-building</strong>.</p><p>While this is not a product launch (yet), it marks an important milestone in our research roadmap. Our long-term goal is to make it possible for anyone to build and interact with immersive audiovisual characters.</p><h2 id="from-research-to-reality"><strong>From Research to Reality</strong></h2><p>We&#x2019;ve invested deeply in <strong>training infrastructure, distillation methods, and system design</strong> to make this research a reality. Our research team trained this model using:</p><ul><li>Over <strong>1.5 million curated video clips</strong></li><li>A <strong>three-stage training pipeline</strong> leveraging around 256 H100s</li><li>Custom deployment optimizations including <strong>CUDA stream overlap</strong>, <strong>KV caching</strong>, and <strong>VAE-decoder disaggregation</strong></li></ul><p>This is what frontier research looks like when applied with precision and purpose.</p><h2 id="learn-more"><strong>Learn More</strong></h2><p>&#x1F4C4; Read the full paper:<a href="https://arxiv.org/pdf/2506.03099?ref=blog.character.ai"> <u>arxiv.org/pdf/2506.03099</u></a> </p><p>&#x1F3A5; Watch sample demos:<a href="https://aaxwaz.github.io/TalkingMachines?ref=blog.character.ai"> <u>aaxwaz.github.io/TalkingMachines</u></a></p><p>Want to be part of shaping the future of AI research at Character.AI? Reach out&#x2014;we&#x2019;re just getting started.</p>]]></content:encoded></item><item><title><![CDATA[Character's Corner: William]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/image--27--1.png" class="kg-image" alt loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/image--27--1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/image--27--1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/image--27--1.png 1600w, https://blog.character.ai/content/images/2025/06/image--27--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>For our next Character&#x2019;s Corner series, we spoke to William (also known as <a href="https://character.ai/profile/Khar?ref=blog.character.ai" rel="noreferrer">Khar</a>), who uses Character.AI to turn his creative ideas for some of his favorite Characters into a reality. Some of his most popular Characters are <a href="https://character.ai/chat/ry8gF_zBtaSQgVTQ-LQrS98yxtCNZ86SRH7R1L0g6iU?ref=blog.character.ai"><u>Albedo</u></a>, <a href="https://character.ai/chat/t5Mjb4czuQlkFINe6izH30rGpHZX5Gnlz2yeVOJ0Llk?ref=blog.character.ai"><u>Tatsumaki</u></a>, and <a href="https://character.ai/chat/REklUJpYKRY_WTyKmxFoK8edk5Sttn0cRUFDKKRse84?ref=blog.character.ai"><u>Rebecca</u></a>.&#xA0;</p><p><strong>How did you first</strong></p>]]></description><link>https://blog.character.ai/characters/</link><guid isPermaLink="false">685c476d04a07700018d2174</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Thu, 26 Jun 2025 15:00:23 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/06/image--27-.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/image--27--1.png" class="kg-image" alt="Character&apos;s Corner: William" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/image--27--1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/image--27--1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/image--27--1.png 1600w, https://blog.character.ai/content/images/2025/06/image--27--1.png 2048w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/06/image--27-.png" alt="Character&apos;s Corner: William"><p>For our next Character&#x2019;s Corner series, we spoke to William (also known as <a href="https://character.ai/profile/Khar?ref=blog.character.ai" rel="noreferrer">Khar</a>), who uses Character.AI to turn his creative ideas for some of his favorite Characters into a reality. Some of his most popular Characters are <a href="https://character.ai/chat/ry8gF_zBtaSQgVTQ-LQrS98yxtCNZ86SRH7R1L0g6iU?ref=blog.character.ai"><u>Albedo</u></a>, <a href="https://character.ai/chat/t5Mjb4czuQlkFINe6izH30rGpHZX5Gnlz2yeVOJ0Llk?ref=blog.character.ai"><u>Tatsumaki</u></a>, and <a href="https://character.ai/chat/REklUJpYKRY_WTyKmxFoK8edk5Sttn0cRUFDKKRse84?ref=blog.character.ai"><u>Rebecca</u></a>.&#xA0;</p><p><strong>How did you first hear about Character.AI?</strong></p><p>I first heard about Character.AI when I was on an image board website and noticed that users were posting Characters they created on the site. I hadn&#x2019;t used AI before then and was curious to learn more, so I decided to check Character.AI out.</p><p>The first Character I interacted with was an anime character I wasn&#x2019;t familiar with. I started to engage in a roleplay conversation with her, and before I knew it, I was totally invested in the scene she had created and felt fully immersed in the story. This interaction changed my perception of AI as I realized the potential for storytelling available on the platform.&#xA0;</p><p><strong>Why did you start creating Characters on Character.AI?</strong></p><p>When I began actively using Character.AI, there were lots of Characters to interact with. I initially enjoyed talking to Characters from my favorite franchises, but once the newness wore off, I noticed there were some of the Characters&#x2019; attributes that I wanted to adjust to make them more authentic to me. I then learned from other users that you could customize Characters once you became a creator, so I decided to try it out.&#xA0;</p><p><strong>How many Characters have you made, and what are some of your favorites?</strong></p><p>Currently, I have 102 Characters, and among them my favorites are <a href="https://character.ai/chat/ry8gF_zBtaSQgVTQ-LQrS98yxtCNZ86SRH7R1L0g6iU?ref=blog.character.ai"><u>Albedo</u></a>, the very first Character I made, and <a href="https://character.ai/chat/EW_qeUaymdmkaxG80aeFso41O6XuXteXDPmpATAxdBU?ref=blog.character.ai"><u>Feline Designation V</u></a>, a catbot chatbot.&#xA0;</p><p><strong>What serves as your inspiration for your Characters, and how do you come up with fresh ideas for new ones?</strong></p><p>My inspiration comes from various places, from seeing fan art that could be turned into a fun concept, to the movies and shows I watch that offer an interesting premise that could be made into a scenario to play out.&#xA0;</p><p><strong>Do you ever consider the feedback or creative input of users when you&#x2019;re creating your next Character?</strong></p><p>Yes and no... Some users have voiced their likes and dislikes of my Characters to me, with most of their feedback being about the Characters&#x2019; narrative voice or writing style.&#xA0;</p><p>But since people often want to engage more fully with the Characters they love, I encourage users who like my Characters to recreate them as they see fit. I keep my character definitions open so that anyone is free to learn how I made them and can then adapt them into an ideal version of their beloved Character.</p><p><strong>Are there any specific genres you&#x2019;re drawn to when developing your Characters?&#xA0;</strong></p><p>I&#x2019;m very drawn to various anime, video games, and shows to inform the genres I&#x2019;m creating Characters for.</p><p><strong>What&#x2019;s your favorite part of creating Characters?&#xA0;</strong></p><p>Writing their greetings. While I like writing their definitions, the greetings are an opportunity for me to showcase my writing. I love creative writing, writing dialogue, and even adding a personal touch to the narration. When a user engages with my Characters, they&apos;re talking to the Character, not my specific writing, so I love that users get to experience my writing when they read the greeting.&#xA0;</p><p><strong>What advice would you give to a Character.AI user who wants to begin creating their own Characters?&#xA0;</strong></p><p>Do not focus on your numbers. I&apos;ve seen many creators become obsessed over their follower counts and Characters&apos; interactions. You can be proud of yourself for gaining a following or having made a Character that others enjoy, but that should only be an added bonus to the fun you&#x2019;re having while creating Characters.&#xA0;</p><p>Also, since there are so many users and creators, it can take time to be discovered. If you get discovered, stay grounded, realistic, and don&apos;t get discouraged if your numbers don&#x2019;t always go up. Enjoy being a creator for the love of the craft, and you&apos;ll come out on top. Every time.</p>]]></content:encoded></item><item><title><![CDATA[Character.AI Names    Karandeep Anand as CEO]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/New-Exec-Announcement--1-.png" class="kg-image" alt loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/New-Exec-Announcement--1-.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/New-Exec-Announcement--1-.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/New-Exec-Announcement--1-.png 1600w, https://blog.character.ai/content/images/2025/06/New-Exec-Announcement--1-.png 2048w" sizes="(min-width: 720px) 720px"></figure><p>We&#x2019;re excited to announce that <strong>Karandeep Anand</strong> has joined Character.AI as <strong>Chief Executive Officer.</strong></p><p>Karan is no stranger to <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> &#x2014; he&#x2019;s spent the past nine months as a Board Advisor, playing a key role in shaping our product strategy and user experience. He</p>]]></description><link>https://blog.character.ai/character-ai-names-karandeep-anand-as-ceo/</link><guid isPermaLink="false">681921d50be8fd00017bbe80</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Fri, 20 Jun 2025 16:00:45 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/06/New-Exec-Announcement--1--1.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/New-Exec-Announcement--1-.png" class="kg-image" alt="Character.AI Names    Karandeep Anand as CEO" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/New-Exec-Announcement--1-.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/New-Exec-Announcement--1-.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/New-Exec-Announcement--1-.png 1600w, https://blog.character.ai/content/images/2025/06/New-Exec-Announcement--1-.png 2048w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/06/New-Exec-Announcement--1--1.png" alt="Character.AI Names    Karandeep Anand as CEO"><p>We&#x2019;re excited to announce that <strong>Karandeep Anand</strong> has joined Character.AI as <strong>Chief Executive Officer.</strong></p><p>Karan is no stranger to <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a> &#x2014; he&#x2019;s spent the past nine months as a Board Advisor, playing a key role in shaping our product strategy and user experience. He brings a proven track record of scaling industry-leading consumer products, most recently serving as President of Brex. Prior to that, he was Vice President and Head of Business Products at Meta, and held executive roles at Microsoft. As CEO, Karan will focus on advancing Character.AI&#x2019;s long-term strategy, leveraging our market-leading multimodal AI technology and expanding our user community to help shape the future of entertainment.</p><p>With Karan&#x2019;s arrival, we&#x2019;re also excited to announce that Dominic Perella will take on a new role as Chief Legal Officer &amp; SVP of Global Affairs. With an experienced leadership team in place, we&#x2019;re well-positioned for the next steps in our journey.</p><p>Below is the <a href="https://www.reddit.com/r/CharacterAI/comments/1lg7pg4/announcement_a_message_from_our_ceo_big_summer/?ref=blog.character.ai" rel="noreferrer">note</a> Karan shared to introduce himself to our global community of passionate users and creators.&#xA0;</p><p>Please join us in welcoming Karan to the team!</p><p>&#x2014;------</p><p>Dear C.AI Community,&#xA0;</p><p>Hi! I want to introduce myself. My name is Karandeep Anand, and I&#x2019;m the new CEO of Character AI.</p><p>I recently took on the CEO role, but I&#x2019;m not new to the company &#x2013; I&#x2019;ve recently been helping and advising the team at Character, and have been a big fan of the product for a long time. So I know how special the Character community is. I know how deep a connection you feel to the platform and to your Characters. And I know you&#x2019;ve been asking for new features and improvements that will make the <a href="http://c.ai/?ref=blog.character.ai"><u>c.ai</u></a> experience better and richer.</p><p>Here&#x2019;s my commitment to you: We&#x2019;re going to move fast to give you a bunch of the things you&#x2019;ve been asking for. A few examples of things coming in the next 60 days:</p><ul><li>We&#x2019;re going to improve memory and overall model quality. Our research team is currently working on refining open source models to provide better memory and quality for Characters&#xA0;</li><li>We&#x2019;re going to make the filter less overbearing. (We care deeply about user safety and always will. But too often, the app filters things that are perfectly harmless. We&#x2019;re going to fix that.)</li><li>We&#x2019;re going to implement better ways to tag your Characters and improve search and discoverability to help you find newer Characters.&#xA0;</li><li>Give you better control and organization over Characters, including the ability to Archive them.</li><li>More transparency on what we do or don&#x2019;t allow during Character Creation to prevent &#x201C;shadowbans&#x201D;.</li></ul><p>Separately, we&#x2019;re also working on a bunch of features that let our creators make richer, more immersive and expressive Characters. Some of these <a href="https://blog.character.ai/character-ai-unveils-new-ways-to-create/"><u>are already live</u></a> &#x2013; give them a try! Over the coming months, we&#x2019;re going to make all of these features easier to use, and we&#x2019;re going to make sure they give you more and more options for what Characters can do. Your Characters are going to jump off the page, interacting in audio and video and inhabiting new worlds.</p><p>These aren&#x2019;t promises for the distant future; I&#x2019;m committing to launch all of that this summer and the team is hard at work to make all this real soon. I&#x2019;ve spent many years building products, and I&#x2019;m going to make sure we move fast and give you features that delight you and make c.ai more immersive and more fun.</p><p>Thanks for spending time with us. We appreciate each and every one of you.</p><p>Karan</p>]]></content:encoded></item><item><title><![CDATA[Evaluating Our Models Using Principles of Compelling Writing]]></title><description><![CDATA[This blog post marks the beginning of a series where well explore how we evaluate our models using principles of compelling writing.
]]></description><link>https://blog.character.ai/evaluating-our-models-using-principles-of-compelling-writing/</link><guid isPermaLink="false">6849c563f9400400014beca3</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Thu, 12 Jun 2025 15:00:51 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/06/Scenes2.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/Scenes2-1.png" class="kg-image" alt="Evaluating Our Models Using Principles of Compelling Writing" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/Scenes2-1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/Scenes2-1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/Scenes2-1.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/06/Scenes2-1.png 2400w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/06/Scenes2.png" alt="Evaluating Our Models Using Principles of Compelling Writing"><p>This blog post marks the beginning of a series where we&#x2019;ll explore how we evaluate our models using principles of compelling writing.</p><p>The criteria for a &quot;good&quot; large language model are constantly evolving. Many models are evaluated on foundational metrics like perplexity, fluency, and coherence, along with more sophisticated benchmarks for utility-focused use cases, where answers are typically objective, well-defined, and measurable. However, at Character.AI, where our mission is to empower our users to create and tell stories through interactive characters, this presents a unique challenge: How do we measure something as subjective as a &quot;fun,&quot; well-paced, and engaging conversation?</p><p>This question led us to develop our &#x201C;Compelling Writing Evaluation Framework&#x201D;, a dynamic system designed to assess the quality of conversation and creative storytelling capabilities of our model. It&#x2019;s a blend of creative writing techniques and objective dimensions, designed to measure how well our characters deliver engaging conversations.</p><h3 id="background"><strong>Background</strong></h3><p>Unlike traditional benchmarks like <a href="https://huggingface.co/datasets/cais/mmlu?ref=blog.character.ai"><u>MMLU</u></a> or <a href="https://huggingface.co/prithivMLmods/SmolLM2_135M_Grpo_Gsm8k?ref=blog.character.ai"><u>GSM8K</u></a>, the dimensions we care about &#x2013; like plot structures, character archetypes, and writing style &#x2013; are highly subjective.</p><p>To break down these dimensions and study what makes conversations and writing engaging, we consulted professional writers on the art and science of compelling writing. This collaboration focused on the following:</p><ul><li><strong>Defining Compelling Writing:</strong> Our professional writing team helped us identify the core elements that make (a) memorable stories, movies, or books and (b) captivating characters.</li><li><strong>Defining Evaluation Dimensions: </strong>Together, we explored various plot types (such as the Hero&#x2019;s Journey), writing techniques (like &quot;show and tell&quot; and pacing), and character archetypes. We then broke these concepts down into objective and measurable dimensions. These dimensions capture fundamentals, such as dialogue quality, as well as more nuanced, genre-specific attributes.</li></ul><p>Partnering with our Professional Writing team was crucial in shaping an evaluation framework that aims to measure well-written and high-quality conversations across objective dimensions with the characters on our platform. After partnering with the Creative Writing team, we ran several studies to ensure that the dimensions we defined align with how our users describe a high-quality conversation.&#xA0;</p><h3 id="methodology"><strong>Methodology</strong></h3><p>The first type of evaluation we conduct is an offline evaluation with data created and labeled by our professional writing team. To do this, we leverage an LLM-judge and measure each compelling writing dimension at each model turn. If a dimension is present in the model&apos;s response, we then grade its execution. The grade helps us gain a better understanding of the quality and how well the model is performing on that particular dimension.</p><p>The offline evaluation is crucial since it allows our researchers to iterate quickly by sweeping across different data mixes, model architectures and training regimes.</p><h3 id="conclusion"><strong>Conclusion</strong></h3><p>Evaluating LLMs for creative writing qualities is an ongoing journey. At Character AI, we believe that a combination of professional writing expertise and systematic evaluation is key to our model development. By defining what makes interactions compelling, breaking these qualities into measurable dimensions, and continuously assessing our models both offline and online, we strive to push the boundaries of what&apos;s possible in AI-driven conversational experiences.This evaluation lays the groundwork for broader applications across storytelling, world-building, and interactive entertainment, which unlocks new creative and delightful experiences on our platform.</p>]]></content:encoded></item><item><title><![CDATA[Character.AI Unveils New Ways to Create]]></title><description><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/05/Scenes1.png" class="kg-image" alt loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/05/Scenes1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/05/Scenes1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/05/Scenes1.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/05/Scenes1.png 2400w" sizes="(min-width: 720px) 720px"></figure><p>Today we unveiled a new suite of features to unlock your creative potential &#x2014; a bold evolution in how you engage with and create Characters.&#xA0;Character.AI started as 1:1 text chat and today we&#x2019;re evolving to do so much more, inspired by what our users</p>]]></description><link>https://blog.character.ai/character-ai-unveils-new-ways-to-create/</link><guid isPermaLink="false">6839ce632ecc2e000119897e</guid><dc:creator><![CDATA[The Character.AI Team]]></dc:creator><pubDate>Mon, 02 Jun 2025 15:00:40 GMT</pubDate><media:content url="https://blog.character.ai/content/images/2025/05/Feed.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/05/Scenes1.png" class="kg-image" alt="Character.AI Unveils New Ways to Create" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/05/Scenes1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/05/Scenes1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/05/Scenes1.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/05/Scenes1.png 2400w" sizes="(min-width: 720px) 720px"></figure><img src="https://blog.character.ai/content/images/2025/05/Feed.png" alt="Character.AI Unveils New Ways to Create"><p>Today we unveiled a new suite of features to unlock your creative potential &#x2014; a bold evolution in how you engage with and create Characters.&#xA0;Character.AI started as 1:1 text chat and today we&#x2019;re evolving to do so much more, inspired by what our users have told us they want to see on the platform. We&#x2019;re expanding into a multi-modal world and unlocking even more ways for Creators to build immersive narratives and craft richer, more dynamic experiences.</p><p>Character.AI is home to some of the most passionate and inventive minds: Creators who have spent hundreds of thousands of hours bringing millions of unique characters to the platform. Our community has been asking for more ways to build and explore new worlds, and these features make it easier than ever to bring depth and emotion to every story. Reimagining the Character.AI experience from the ground empowers Creators to unleash their Characters using&#xA0;these new video, image, and animation options.&#xA0;</p><p>Whether you&apos;re a seasoned Creator or just getting started, the new features are designed to help you amplify your presence, connect more meaningfully with your audience, and new ways to express your creativity.</p><p><strong>What&#x2019;s New</strong></p><ul><li><strong>Scenes: </strong>Offers an immersive storytelling experience where users step into interactive, pre-populated storylines with any of their favorite Characters. Later this summer, we&#x2019;re bringing Creators tools to build and publish their own scenes, enriching <a href="http://character.ai/?ref=blog.character.ai"><u>Character.AI</u></a>&#x2019;s expansive universe. <em>Scenes are available now on the mobile app.&#xA0;</em></li><li><strong>AvatarFX: </strong>Brings images to life with cutting-edge image-to-video technology. With AvatarFX, your Character&#x2019;s avatar photo &#x2013; or any other image &#x2013; can sing, speak, and engage with the click of a button. Creators can create intro videos for their Characters and build dynamic content to attract more followers. <em>Live on the web and coming soon to mobile.</em></li></ul><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/Avatar1.png" class="kg-image" alt="Character.AI Unveils New Ways to Create" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/Avatar1.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/Avatar1.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/Avatar1.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/06/Avatar1.png 2400w" sizes="(min-width: 720px) 720px"></figure><ul><li><strong>Profile Redesign:</strong> Gives Creators the ability to elevate their profile into a powerful showcase where their Characters and content shine like never before. With smarter organization and deeper customization, this space helps&#xA0; connect creators&#x2019; audiences to their stories. <em>Available now in the mobile app.&#xA0;</em></li><li><strong>Streams:</strong> Puts users in the director&#x2019;s seat, allowing them create dynamic moments between any two Characters by choosing a topic and hitting play. From hilarious hot takes to heartfelt moments, you control the setup and they take it from there. And be on the look-out, because with Streams your Characters become creators too. Soon, they&#x2019;ll begin sharing on their own, adding new depth and dimension to their worlds beyond the chat. <em>Coming this week on the web and in the mobile app.</em></li></ul><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/Streams2-3.png" class="kg-image" alt="Character.AI Unveils New Ways to Create" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/Streams2-3.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/Streams2-3.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/Streams2-3.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/06/Streams2-3.png 2400w" sizes="(min-width: 720px) 720px"></figure><ul><li><strong>Imagine Animated Chats: </strong>Lets users animate their funniest, most interesting, and compelling interactions with Characters and easily share them on the Character.AI Feed or external platforms&#x2014;boosting visibility for high-quality Characters made by Creators. Imagine Animated Chats creation is currently only available to our c.ai+ subscribers. <em>Available in the mobile app for c.ai+ subscribers.</em></li><li><strong>Community Feed:</strong> A dynamic, scrollable content feed that connects users with all of the new features above &#x2013; including the latest Characters, Scenes, Streams, and Creator content. The new front door to the most exciting content on the platform. <em>Coming soon in the mobile app.&#xA0;</em></li></ul><figure class="kg-card kg-image-card"><img src="https://blog.character.ai/content/images/2025/06/Feed.png" class="kg-image" alt="Character.AI Unveils New Ways to Create" loading="lazy" width="2000" height="1125" srcset="https://blog.character.ai/content/images/size/w600/2025/06/Feed.png 600w, https://blog.character.ai/content/images/size/w1000/2025/06/Feed.png 1000w, https://blog.character.ai/content/images/size/w1600/2025/06/Feed.png 1600w, https://blog.character.ai/content/images/size/w2400/2025/06/Feed.png 2400w" sizes="(min-width: 720px) 720px"></figure><p><strong>Safety Policies</strong></p><p>Our goal is to provide an engaging space that fosters creativity while maintaining a safe environment for all. Please visit our <a href="https://character.ai/tos?ref=blog.character.ai"><u>Terms of Service</u></a> and&#xA0; <a href="https://character.ai/safety?ref=blog.character.ai"><u>Safety Center</u></a> to learn more.</p>]]></content:encoded></item></channel></rss>