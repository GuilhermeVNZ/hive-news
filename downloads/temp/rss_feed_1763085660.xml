
  <rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
      <title>Apple Machine Learning Research</title>
      <link>https://machinelearning.apple.com</link>
      <description>Apple machine learning teams are engaged in state of the art research in machine learning and artificial intelligence. Learn about the latest advancements.</description>
      <language>en</language>
      <lastBuildDate>Wed, 12 Nov 2025 00:00:00 GMT</lastBuildDate>
      <atom:link href="https://machinelearning.apple.com/rss.xml" rel="self" type="application/rss+xml"/>
      
  <item>
    <guid>car-flow</guid>
    <title>CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching</title>
    <link>https://machinelearning.apple.com/research/car-flow</link>
    <description>Conditional generative modeling aims to learn a conditional data distribution from samples containing data-condition pairs. For this, diffusion and flow-based methods have attained compelling results. These methods use a learned (flow) model to transport an initial standard Gaussian noise that ignores the condition to the conditional data distribution. The model is hence required to learn both mass transport and conditional injection. To ease the demand on the model, we propose Condition-Aware Reparameterization for Flow Matching (CAR-Flow) — a lightweight, learned shift that conditions the…</description>
    <pubDate>Wed, 12 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>expertlens-activation</guid>
    <title>ExpertLens: Activation Steering Features Are Highly Interpretable</title>
    <link>https://machinelearning.apple.com/research/expertlens-activation</link>
    <description>This paper was accepted at the Workshop on Unifying Representations in Neural Models (UniReps) at NeurIPS 2025.
Activation steering methods in large language models (LLMs) have emerged as an effective way to perform targeted updates to enhance generated language without requiring large amounts of adaptation data. We ask whether the features discovered by activation steering methods are interpretable. We identify neurons responsible for specific concepts (e.g., “cat”) using the “finding experts” method from research on activation steering and show that the ExpertLens, i.e., inspection of these…</description>
    <pubDate>Fri, 07 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>polynorm</guid>
    <title>PolyNorm: Few-Shot LLM-Based Text Normalization for Text-to-Speech</title>
    <link>https://machinelearning.apple.com/research/polynorm</link>
    <description>Text Normalization (TN) is a key preprocessing step in Text-to-Speech (TTS) systems, converting written forms into their canonical spoken equivalents. Traditional TN systems can exhibit high accuracy, but involve substantial engineering effort, are difficult to scale, and pose challenges to language coverage, particularly in low-resource settings. We propose PolyNorm, a prompt-based approach to TN using Large Language Models (LLMs), aiming to reduce the reliance on manually crafted rules and enable broader linguistic applicability with minimal human intervention. Additionally, we present a…</description>
    <pubDate>Thu, 06 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>self-supervised-representations</guid>
    <title>Adapting Self-Supervised Representations as a Latent Space for Efficient Generation</title>
    <link>https://machinelearning.apple.com/research/self-supervised-representations</link>
    <description>We introduce Representation Tokenizer (RepTok), a generative modeling framework that represents an image using a single continuous latent token obtained from self-supervised vision transformers. Building on a pre-trained SSL encoder, we fine-tune only the semantic token embedding and pair it with a generative decoder trained jointly using a standard flow matching objective. This adaptation enriches the token with low-level, reconstruction-relevant details, enabling faithful image reconstruction. To preserve the favorable geometry of the original SSL space, we add a cosine-similarity loss that…</description>
    <pubDate>Tue, 04 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>learning-deformable-body</guid>
    <title>Learning Deformable Body Interactions With Adaptive Spatial Tokenization</title>
    <link>https://machinelearning.apple.com/research/learning-deformable-body</link>
    <description>This paper was accepted at the AI for Science Workshop at NeurIPS 2025.
Simulating interactions between deformable bodies is vital in fields like material science, mechanical design, and robotics. While learning-based methods with Graph Neural Networks (GNNs) are effective at solving complex physical systems, they encounter scalability issues when modeling deformable body interactions. To model interactions between objects, pairwise global edges have to be created dynamically, which is computationally intensive and impractical for large-scale meshes. To overcome these challenges, drawing on…</description>
    <pubDate>Tue, 04 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>embedding-atlas</guid>
    <title>Embedding Atlas: Low-Friction, Interactive Embedding Visualization</title>
    <link>https://machinelearning.apple.com/research/embedding-atlas</link>
    <description>Embedding projections are popular for visualizing large datasets and models. However, people often encounter “friction” when using embedding visualization tools: (1) barriers to adoption, e.g., tedious data wrangling and loading, scalability limits, no integration of results into existing workflows, and (2) limitations in possible analyses, without integration with external tools to additionally show coordinated views of metadata. In this paper, we present Embedding Atlas, a scalable, interactive visualization tool designed to make interacting with large embeddings as easy as possible…</description>
    <pubDate>Mon, 03 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>policy-maps</guid>
    <title>Policy Maps: Tools for Guiding the Unbounded Space of LLM Behaviors</title>
    <link>https://machinelearning.apple.com/research/policy-maps</link>
    <description>AI policy sets boundaries on acceptable behavior for AI models, but this is challenging in the context of large language models (LLMs): how do you ensure coverage over a vast behavior space? We introduce policy maps, an approach to AI policy design inspired by the practice of physical mapmaking. Instead of aiming for full coverage, policy maps aid effective navigation through intentional design choices about which aspects to capture and which to abstract away. With Policy Projector, an interactive tool for designing LLM policy maps, an AI practitioner can survey the landscape of model…</description>
    <pubDate>Mon, 03 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>end-to-end-learning</guid>
    <title>LinEAS: End-to-end Learning of Activation Steering with a Distributional Loss</title>
    <link>https://machinelearning.apple.com/research/end-to-end-learning</link>
    <description>The growing use of generative models in daily life calls for efficient mechanisms to control their generation, to e.g., produce safe content or provide users with tools to explore style changes. Ideally, such mechanisms should require low volume of unpaired data (i.e., without explicit preference), and should be cheap, both at train and inference time, while preserving output quality. Recent research has shown that such mechanisms can be obtained by intervening exclusively on model activations, with the goal of correcting distributional differences between activations seen when using prompts…</description>
    <pubDate>Mon, 03 Nov 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>semorec</guid>
    <title>SEMORec: A Scalarized Efficient Multi-Objective Recommendation Framework</title>
    <link>https://machinelearning.apple.com/research/semorec</link>
    <description>Recommendation systems in multi-stakeholder environments often require optimizing for multiple objectives simultaneously to meet supplier and consumer demands. Serving recommendations in these settings relies on efficiently combining the objectives to address each stakeholder’s expectations, often through a scalarization function with pre-determined and fixed weights. In practice, selecting these weights becomes a consequent problem. Recent work has developed algorithms that adapt these weights based on application-specific needs by using RL to train a model. While this solves for automatic…</description>
    <pubDate>Thu, 30 Oct 2025 00:00:00 GMT</pubDate>
  </item>

  <item>
    <guid>toward-machine-interpreting</guid>
    <title>Toward Machine Interpreting: Lessons from Human Interpreting Studies</title>
    <link>https://machinelearning.apple.com/research/toward-machine-interpreting</link>
    <description>Current speech translation systems, while having achieved impressive accuracies, are rather static in their behavior and do not adapt to real-world situations in ways human interpreters do. In order to improve their practical usefulness and enable interpreting-like experiences, a precise understanding of the nature of human interpreting is crucial. To this end, we discuss human interpreting literature from the perspective of the machine translation field, while considering both operational and qualitative aspects. We identify implications for the development of speech translation systems and…</description>
    <pubDate>Wed, 29 Oct 2025 00:00:00 GMT</pubDate>
  </item>

    </channel>
  </rss>
