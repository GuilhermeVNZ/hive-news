<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0">
    <channel>
        <title>AI | VentureBeat</title>
        <link>https://venturebeat.com/category/ai/feed/</link>
        <description>Transformative tech coverage that matters</description>
        <lastBuildDate>Fri, 14 Nov 2025 01:25:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>https://github.com/jpmonette/feed</generator>
        <language>en</language>
        <copyright>Copyright 2025, VentureBeat</copyright>
        <item>
            <title><![CDATA[Baidu unveils proprietary ERNIE 5 beating GPT-5 performance on charts, document understanding and more]]></title>
            <link>https://venturebeat.com/ai/baidu-unveils-proprietary-ernie-5-beating-gpt-5-performance-on-charts</link>
            <guid isPermaLink="false">60u3P5sAxXDZ7rLs5xCdzl</guid>
            <pubDate>Thu, 13 Nov 2025 20:23:00 GMT</pubDate>
            <description><![CDATA[<p>Mere hours after OpenAI updated its flagship foundation model <a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5">GPT-5 to GPT-5.1</a>, promising reduced token usage overall and a more pleasant personality with more preset options, Chinese search giant <a href="https://www.prnewswire.com/news-releases/baidu-unveils-ernie-5-0-and-a-series-of-ai-applications-at-baidu-world-2025--ramps-up-global-push-302614531.html?tc=eml_cleartime">Baidu unveiled its next-generation foundation model, ERNIE 5.0,</a> alongside a suite of AI product upgrades and strategic international expansions.</p><p>The goal: to position as a global contender in the increasingly competitive enterprise AI market.</p><p>Announced at the company&#x27;s Baidu World 2025 event, ERNIE 5.0 is a proprietary, natively omni-modal model designed to jointly process and generate content across text, images, audio, and video. </p><p>Unlike Baidu’s recently released <a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5">ERNIE-4.5-VL-28B-A3B-Thinking</a>, which is open source under an enterprise-friendly and permissive Apache 2.0 license, ERNIE 5.0 is a proprietary model and is available only via <a href="https://ernie.baidu.com/">Baidu’s ERNIE Bot</a> website (I needed to select it manuallyu from the model picker dropdown) and the <a href="https://cloud.baidu.com/doc/qianfan/s/wmh4sv6ya">Qianfan cloud platform application programming interface (API) for enterprise customers. </a></p><p>Alongside the model launch, Baidu introduced major updates to its digital human platform, no-code tools, and general-purpose AI agents — all targeted at expanding its AI footprint beyond China.</p><p>The company also introduced ERNIE 5.0 Preview 1022, a variant optimized for text-intensive tasks, alongside the general preview model that balances across modalities.</p><p>Baidu emphasized that ERNIE 5.0 represents a shift in how intelligence is deployed at scale, with CEO Robin Li stating: “When you internalize AI, it becomes a native capability and transforms intelligence from a cost into a source of productivity.”</p><h3><b>Where ERNIE 5.0 outshines GPT-5 and Gemini 2.5 Pro</b></h3><p>ERNIE 5.0’s benchmark results suggest that Baidu has achieved parity—or near-parity—with the top Western foundation models across a wide spectrum of tasks. </p><p>In public benchmark slides shared during the Baidu World 2025 event, ERNIE 5.0 Preview outperformed or matched OpenAI’s GPT-5-High and Google’s Gemini 2.5 Pro in <b>multimodal reasoning, document understanding, and image-based QA</b>, while also <b>demonstrating strong language modeling and code execution abilities. </b></p><p>The company emphasized its ability to handle joint inputs and outputs across modalities, rather than relying on post-hoc modality fusion, which it framed as a technical differentiator.</p><p>On visual tasks, ERNIE 5.0 achieved leading scores on OCRBench, DocVQA, and ChartQA, three benchmarks that test document recognition, comprehension, and structured data reasoning. </p><p>Baidu claims the model beat both GPT-5-High and Gemini 2.5 Pro on these document and chart-based benchmarks, areas it describes as core to enterprise applications like automated document processing and financial analysis. </p><p>In image generation, ERNIE 5.0 tied or exceeded Google’s Veo3 across categories including semantic alignment and image quality, according to Baidu’s internal GenEval-based evaluation. Baidu claimed that the model’s multimodal integration allows it to generate and interpret visual content with greater contextual awareness than models relying on modality-specific encoders.</p><p>For audio and speech tasks, ERNIE 5.0 demonstrated competitive results on MM-AU and TUT2017 audio understanding benchmarks, as well as question answering from spoken language inputs. Its audio performance, while not as heavily emphasized as vision or text, suggests a broad capability footprint intended to support full-spectrum multimodal applications.</p><p>In language tasks, the model showed strong results on instruction following, factual question answering, and mathematical reasoning—core areas that define the enterprise utility of large language models. </p><p>The Preview 1022 variant of ERNIE 5.0, tailored for textual performance, showed even stronger language-specific results in early developer access. While Baidu does not claim broad superiority in general language reasoning, its internal evaluations suggest that ERNIE 5.0 Preview 1022 closes the gap with top-tier English-language models and outperforms them in Chinese-language performance.</p><p>While Baidu did not release full benchmark details or raw scores publicly, its performance positioning suggests a deliberate attempt to frame ERNIE 5.0 not as a niche multimodal system but as a flagship model competitive with the largest closed models in general-purpose reasoning. </p><p><b>Where Baidu claims a clear lead is in structured document understanding, visual chart reasoning, and integration of multiple modalities into a single, native modeling architecture</b>. Independent verification of these results remains pending, but the breadth of claimed capabilities positions ERNIE 5.0 as a serious alternative in the multimodal foundation model landscape.</p><h3><b>Enterprise Pricing Strategy</b></h3><p>ERNIE 5.0 is positioned at the <b>premium end</b> of Baidu’s model pricing structure. The company has released specific pricing for API usage on its Qianfan platform, aligning the cost with other top-tier offerings from Chinese competitors like Alibaba.</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input Cost (per 1K tokens)</b></p></td><td><p><b>Output Cost (per 1K tokens)</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p><b>ERNIE 5.0</b></p></td><td><p>$0.00085 (¥0.006)</p></td><td><p>$0.0034 (¥0.024)</p></td><td><p><a href="cloud.baidu.com/doc/qianfan/s/wmh4sv6ya">Qianfan</a></p></td></tr><tr><td><p>ERNIE 4.5 Turbo (ex.)</p></td><td><p>$0.00011 (¥0.0008)</p></td><td><p>$0.00045 (¥0.0032)</p></td><td><p><a href="cloud.baidu.com/doc/qianfan/s/wmh4sv6ya">Qianfan</a></p></td></tr><tr><td><p>Qwen3 (Coder ex.)</p></td><td><p>$0.00085 (¥0.006)</p></td><td><p>$0.0034 (¥0.024)</p></td><td><p><a href="cloud.baidu.com/doc/qianfan/s/wmh4sv6ya">Qianfan</a></p></td></tr></tbody></table><p>The contrast in cost between ERNIE 5.0 and earlier models such as ERNIE 4.5 Turbo underscores Baidu’s strategy to differentiate between high-volume, low-cost models and high-capability models designed for complex tasks and multimodal reasoning.</p><p>Compared to other U.S. alternatives, it remains mid-range in pricing:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1 M tokens)</b></p></td><td><p><b>Output (/1 M tokens)</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>GPT-5.1</p></td><td><p>$1.25</p></td><td><p>$10.00</p></td><td><p><a href="https://openai.com/api/pricing/?utm_source=chatgpt.com">OpenAI</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p><a href="cloud.baidu.com/doc/qianfan/s/wmh4sv6ya">Qianfan</a></p></td></tr><tr><td><p>ERNIE 4.5 Turbo (ex.)</p></td><td><p>$0.11</p></td><td><p>$0.45</p></td><td><p><a href="cloud.baidu.com/doc/qianfan/s/wmh4sv6ya">Qianfan</a></p></td></tr><tr><td><p>Claude Opus 4.1</p></td><td><p>$15.00</p></td><td><p>$75.00</p></td><td><p><a href="https://www.anthropic.com/claude/opus?utm_source=chatgpt.com">Anthropic</a> </p></td></tr><tr><td><p>Gemini 2.5 Pro</p></td><td><p>$1.25 (≤200k) / $2.50 (&gt;200k)</p></td><td><p>$10.00 (≤200k) / $15.00 (&gt;200k)</p></td><td><p><a href="cloud.google.com/vertex-ai/generative-ai/pricing">Google Vertex AI Pricing</a></p></td></tr><tr><td><p>Grok 4 (grok-4-0709)</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p><a href="https://docs.x.ai/docs/models/grok-4-0709?utm_source=chatgpt.com"> xAI API</a></p></td></tr></tbody></table><h3><b>Global Expansion: Products and Platforms</b></h3><p>In tandem with the model release, Baidu is expanding internationally:</p><ul><li><p><b>GenFlow 3.0</b>, now with 20M+ users, is the company’s largest general-purpose AI agent and features enhanced memory and multimodal task handling.</p></li><li><p><b>Famou</b>, a self-evolving agent capable of dynamically solving complex problems, is now commercially available via invite.</p></li><li><p><b>MeDo</b>, the international version of Baidu’s no-code builder Miaoda, is live globally via <a href="https://medo.dev">medo.dev</a>.</p></li><li><p><b>Oreate</b>, a productivity workspace with document, slide, image, video, and podcast support, has reached over 1.2M users worldwide.</p></li></ul><p>Baidu’s digital human platform, already rolled out in Brazil, is also part of the global push. According to company data, 83% of livestreamers during this year’s “Double 11” shopping event in China used Baidu’s digital human tech, contributing to a 91% increase in GMV.</p><p>Meanwhile, Baidu’s autonomous ride-hailing service Apollo Go has surpassed 17 million rides, operating driverless fleets in 22 cities and claiming the title of the world’s largest robotaxi network.</p><h3><b>Open-Source Vision-Language Model Garners Industry Attention</b></h3><p>Two days before the flagship ERNIE 5.0 event, Baidu also released an open-source multimodal model under the Apache 2.0 license: <a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5">ERNIE-4.5-VL-28B-A3B-Thinking</a>. </p><p>As <a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5">reported by my colleague Michael Nuñez at VentureBeat</a>, the model activates just 3 billion parameters while maintaining a total of 28 billion, using a Mixture-of-Experts (MoE) architecture for efficient inference.</p><p>Key technical innovations include:</p><ul><li><p>“Thinking with Images”, which enables dynamic zoom-based visual analysis</p></li><li><p>Support for chart interpretation, document understanding, visual grounding, and temporal awareness in video</p></li><li><p>Runtime on a single 80GB GPU, making it accessible to mid-sized organizations</p></li><li><p>Full compatibility with Transformers, vLLM, and Baidu’s FastDeploy toolkits</p></li></ul><p>This release adds pressure on closed-source competitors. With Apache 2.0 licensing, ERNIE-4.5-VL-28B-A3B-Thinking becomes a viable foundation model for commercial applications without licensing restrictions — something few high-performing models in this class offer.</p><h3><b>Community Feedback and Baidu’s Response</b></h3><p>Following the launch of ERNIE 5.0, developer and AI evaluator Lisan al Gaib (@scaling01) <a href="https://x.com/scaling01/status/1988961630273646872">posted a mixed review on X.</a> While initially impressed by the model’s benchmark performance, they reported a persistent issue where ERNIE 5.0 would repeatedly invoke tools — even when explicitly instructed not to — during SVG generation tasks.</p><blockquote><p>“ERNIE 5.0 benchmarks looked insane until I tested it… unfortunately it’s RL braindamaged or they have a serious issue with their chat platform / system prompt,” Lisan wrote.</p></blockquote><p>In a matter of hours, Baidu’s developer-focused support account, <a href="https://x.com/ErnieforDevs/status/1989001980430393688">@ErnieforDevs, responded</a>:</p><blockquote><p>“Thanks for the feedback! It’s a known bug — certain syntax can consistently trigger it. We’re working on a fix. You can try rephrasing or changing the prompt to avoid it for now.”</p></blockquote><p>The quick turnaround reflects Baidu’s increasing emphasis on developer communication, especially as it courts international users through both proprietary and open-source offerings.</p><h3><b>Outlook for Baidu and its ERNIE foundational LLM family</b></h3><p>Baidu’s ERNIE 5.0 marks a strategic escalation in the global foundation model race. With performance claims that put it on par with the most advanced systems from OpenAI and Google, and a mix of premium pricing and open-access alternatives, Baidu is signaling its ambition to become not just a domestic AI leader, but a credible global infrastructure provider.</p><p>At a time when enterprise AI users are increasingly demanding multimodal performance, flexible licensing, and deployment efficiency, Baidu’s two-track approach—premium hosted APIs and open-source releases—may broaden its appeal across both corporate and developer communities.</p><p>Whether the company’s performance claims hold up under third-party testing remains to be seen. But in a landscape shaped by rising costs, model complexity, and compute bottlenecks, ERNIE 5.0 and its supporting ecosystem give Baidu a competitive position in the next wave of AI deployment.</p>]]></description>
            <author>carl.franzen@venturebeat.com (Carl Franzen)</author>
            <category>AI</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/7tpZTCavJ5IcG1LDI66Xae/5066d5c70ead90c2f63e0ef888b9a9ef/YPf93J54wCLeSJI7yvPQK.png?w=300&amp;q=30" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[Upwork study shows AI agents excel with human partners but fail independently]]></title>
            <link>https://venturebeat.com/ai/upwork-study-shows-ai-agents-excel-with-human-partners-but-fail</link>
            <guid isPermaLink="false">3aLuBB8gLAg16BgJAqBJQ4</guid>
            <pubDate>Thu, 13 Nov 2025 18:30:00 GMT</pubDate>
            <description><![CDATA[<p>Artificial intelligence agents powered by the world&#x27;s most advanced language models routinely fail to complete even straightforward professional tasks on their own, according to <a href="https://www.upwork.com/static/webflow/assets/webflow-human-agent-productivity-index/upbench_paper.pdf"><u>groundbreaking research</u></a> released Thursday by <a href="https://www.upwork.com/"><u>Upwork</u></a>, the largest online work marketplace.</p><p>But the same study reveals a more promising path forward: When AI agents collaborate with human experts, <a href="https://www.globenewswire.com/news-release/2025/11/13/3187462/0/en/Upwork-Human-Agent-Productivity-Index-Reveals-Up-to-70-Boost-in-Work-Completion-from-Human-and-AI-Agent-Collaboration-vs-Agents-Working-Alone.html"><u>project completion rates surge by up to 70%</u></a>, suggesting the future of work may not pit humans against machines but rather pair them together in powerful new ways.</p><p>The findings, drawn from more than 300 real client projects posted to Upwork&#x27;s platform, marking the first systematic evaluation of how human expertise amplifies AI agent performance in actual professional work — not synthetic tests or academic simulations. The research challenges both the hype around fully autonomous AI agents and fears that such technology will imminently replace knowledge workers.</p><p>&quot;AI agents aren&#x27;t that agentic, meaning they aren&#x27;t that good,&quot; Andrew Rabinovich, Upwork&#x27;s chief technology officer and head of AI and machine learning, said in an exclusive interview with VentureBeat. &quot;However, when paired with expert human professionals, project completion rates improve dramatically, supporting our firm belief that the future of work will be defined by humans and AI collaborating to get more work done, with human intuition and domain expertise playing a critical role.&quot;</p><h2><b>How AI agents performed on 300+ real freelance jobs—and why they struggled</b></h2><p><a href="https://www.upwork.com/human-agent-productivity-index"><u>Upwork&#x27;s Human+Agent Productivity Index (HAPI) </u></a>evaluated how three leading AI systems — <a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/"><u>Gemini 2.5 Pro</u></a>, OpenAI&#x27;s <a href="https://openai.com/index/introducing-gpt-5/"><u>GPT-5</u></a>, and Claude <a href="https://www.anthropic.com/news/claude-4"><u>Sonnet 4</u></a> — performed on actual jobs posted by paying clients across categories including writing, data science, web development, engineering, sales, and translation.</p><p>Critically, Upwork deliberately selected simple, well-defined projects where AI agents stood a reasonable chance of success. These jobs, priced under $500, represent less than 6% of Upwork&#x27;s total gross services volume — a tiny fraction of the platform&#x27;s overall business and an acknowledgment of current AI limitations.</p><p>&quot;The reality is that although we study AI, and I&#x27;ve been doing this for 25 years, and we see significant breakthroughs, the reality is that these agents aren&#x27;t that agentic,&quot; Rabinovich told VentureBeat. &quot;So if we go up the value chain, the problems become so much more difficult, then we don&#x27;t think they can solve them at all, even to scratch the surface. So we specifically chose simpler tasks that would give an agent some kind of traction.&quot;</p><p>Even on these deliberately simplified tasks, AI agents working independently struggled. But when expert freelancers provided feedback — spending an average of just 20 minutes per review cycle — the agents&#x27; performance improved substantially with each iteration.</p><h2><b>20 minutes of human feedback boosted AI completion rates up to 70%</b></h2><p>The research reveals stark differences in how AI agents perform with and without human guidance across different types of work. For data science and analytics projects, Claude <a href="https://www.anthropic.com/news/claude-4"><u>Sonnet 4</u></a> achieved a 64% completion rate working alone but jumped to 93% after receiving feedback from a human expert. In sales and marketing work, <a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/"><u>Gemini 2.5 Pro</u></a>&#x27;s completion rate rose from 17% independently to 31% with human input. OpenAI&#x27;s <a href="https://openai.com/gpt-5/"><u>GPT-5</u></a> showed similarly dramatic improvements in engineering and architecture tasks, climbing from 30% to 50% completion.</p><p>The pattern held across virtually all categories, with agents responding particularly well to human feedback on qualitative, creative work requiring editorial judgment — areas like writing, translation, and marketing — where completion rates increased by up to 17 percentage points per feedback cycle.</p><p>The finding challenges a fundamental assumption in the AI industry: that agent benchmarks conducted in isolation accurately predict real-world performance.</p><p>&quot;While we show that in the tasks that we have selected for agents to perform in isolation, they perform similarly to the previous results that we&#x27;ve seen published openly, what we&#x27;ve shown is that in collaboration with humans, the performance of these agents improves surprisingly well,&quot; Rabinovich said. &quot;It&#x27;s not just a one-turn back and forth, but the more feedback the human provides, the better the agent gets at performing.&quot;</p><h2><b>Why ChatGPT can ace the SAT but can&#x27;t count the R&#x27;s in &#x27;strawberry&#x27;</b></h2><p>The research arrives as the AI industry grapples with a measurement crisis. Traditional benchmarks — standardized tests that AI models can master, sometimes scoring perfectly on SAT exams or mathematics olympiads — have proven poor predictors of real-world capability.</p><p>&quot;With advances of large language models, what we&#x27;re now seeing is that these static, academic datasets are completely saturated,&quot; Rabinovich said. &quot;So you could get a perfect score in the SAT test or LSAT or any of the math olympiads, and then you would ask ChatGPT how many R&#x27;s there are in the word strawberry, and it would get it wrong.&quot;</p><p>This phenomenon — where AI systems ace formal tests but stumble on trivial real-world questions — has led to growing skepticism about AI capabilities, even as companies race to deploy autonomous agents. Several recent benchmarks from other firms have tested AI agents on Upwork jobs, but those evaluations measured only isolated performance, not the collaborative potential that Upwork&#x27;s research reveals.</p><p>&quot;We wanted to evaluate the quality of these agents on actual real work with economic value associated with it, and not only see how well these agents do, but also see how these agents do in collaboration with humans, because we sort of knew already that in isolation, they&#x27;re not that advanced,&quot; Rabinovich explained.</p><p>For <a href="https://www.upwork.com/"><u>Upwork</u></a>, which connects roughly 800,000 active clients posting more than 3 million jobs annually to a global pool of freelancers, the research serves a strategic business purpose: establishing quality standards for AI agents before allowing them to compete or collaborate with human workers on its platform.</p><h2><b>The economics of human-AI teamwork: Why paying for expert feedback still saves money</b></h2><p>Despite requiring multiple rounds of human feedback — each lasting about 20 minutes — the time investment remains &quot;orders of magnitude different between a human doing the work alone, versus a human doing the work with an AI agent,&quot; Rabinovich said. Where a project might take a freelancer days to complete independently, the agent-plus-human approach can deliver results in hours through iterative cycles of automated work and expert refinement.</p><p>The economic implications extend beyond simple time savings. Upwork recently reported that gross services volume from <a href="https://finance.yahoo.com/news/upworks-stock-soars-q3-blowout-201700500.html"><u>AI-related work grew 53% year-over-year</u></a> in the third quarter of 2025, one of the strongest growth drivers for the company. But executives have been careful to frame AI not as a replacement for freelancers but as an enhancement to their capabilities.</p><p>&quot;AI was a huge overhang for our valuation,&quot; Erica Gessert, Upwork&#x27;s CFO, told <a href="https://www.cfobrew.com/stories/2025/10/16/the-cfo-of-upwork-answers-every-cfo-s-most-burning-question"><u>CFO Brew</u></a> in October. &quot;There was this belief that all work was going to go away. AI was going to take it, and especially work that&#x27;s done by people like freelancers, because they are impermanent. Actually, the opposite is true.&quot;</p><p>The company&#x27;s strategy centers on enabling freelancers to handle more complex, higher-value work by offloading routine tasks to AI. &quot;Freelancers actually prefer to have tools that automate the manual labor and repetitive part of their work, and really focus on the creative and conceptual part of the process,&quot; Rabinovich said.</p><p>Rather than replacing jobs, he argues, AI will transform them: &quot;Simpler tasks will be automated by agents, but the jobs will become much more complex in the number of tasks, so the amount of work and therefore earnings for freelancers will actually only go up.&quot;</p><h2><b>AI coding agents excel, but creative writing and translation still need humans</b></h2><p>The research reveals a clear pattern in agent capabilities. AI systems perform best on &quot;deterministic and verifiable&quot; tasks with objectively correct answers, like solving math problems or writing basic code. &quot;Most coding tasks are very similar to each other,&quot; Rabinovich noted. &quot;That&#x27;s why coding agents are becoming so good.&quot;</p><p>In Upwork&#x27;s tests, web development, mobile app development, and data science projects — especially those involving structured, computational work — saw the highest standalone agent completion rates. Claude <a href="https://www.anthropic.com/news/claude-4"><u>Sonnet 4</u></a> completed 68% of web development jobs and 64% of data science projects without human help, while <a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/"><u>Gemini 2.5 Pro</u></a> achieved 74% on certain technical tasks.</p><p>But qualitative work proved far more challenging. When asked to create website layouts, write marketing copy, or translate content with appropriate cultural nuance, agents floundered without expert guidance. &quot;When you ask it to write you a poem, the quality of the poem is extremely subjective,&quot; Rabinovich said. &quot;Since the rubrics for evaluation were provided by humans, there&#x27;s some level of variability in representation.&quot;</p><p>Writing, translation, and sales and marketing projects showed the most dramatic improvements from human feedback. For writing work, completion rates increased by up to 17 percentage points after expert review. Engineering and architecture projects requiring creative problem-solving — like civil engineering or architectural design — improved by as much as 23 percentage points with human oversight.</p><p>This pattern suggests AI agents excel at pattern matching and replication but struggle with creativity, judgment, and context — precisely the skills that define higher-value professional work.</p><h2><b>Inside the research: How Upwork tested AI agents with peer-reviewed scientific methods</b></h2><p><a href="https://www.upwork.com/"><u>Upwork</u></a> partnered with elite freelancers on its platform to evaluate every deliverable produced by AI agents, both independently and after each cycle of human feedback. These evaluators created detailed rubrics defining whether projects met core requirements specified in job descriptions, then scored outputs across multiple iterations.</p><p>Importantly, evaluators focused only on objective completion criteria, excluding subjective factors like stylistic preferences or quality judgments that might emerge in actual client relationships. &quot;Rubric-based completion rates should not be viewed as a measure of whether an agent would be paid in a real marketplace setting,&quot; <a href="https://www.upwork.com/static/webflow/assets/webflow-human-agent-productivity-index/upbench_paper.pdf"><u>the research</u></a> notes, &quot;but as an indicator of its ability to fulfill explicitly defined requests.&quot;</p><p>This distinction matters: An AI agent might technically complete all specified requirements yet still produce work a client rejects as inadequate. Conversely, subjective client satisfaction — the true measure of marketplace success — remains beyond current measurement capabilities.</p><p>The research underwent double-blind peer review and was accepted to <a href="https://neurips.cc/"><u>NeurIPS</u></a>, the premier academic conference for AI research, where Upwork will present full results in early December. The company plans to publish a complete methodology and make the benchmark available to the research community, updating the task pool regularly to prevent overfitting as agents improve.</p><p>&quot;The idea is for this benchmark to be a living and breathing platform where agents can come in and evaluate themselves on all categories of work, and the tasks that will be offered on the platform will always update, so that these agents don&#x27;t overfit and basically memorize the tasks at hand,&quot; Rabinovich said.</p><h2><b>Upwork&#x27;s AI strategy: Building Uma, a &#x27;meta-agent&#x27; that manages human and AI workers</b></h2><p>The research directly informs Upwork&#x27;s product roadmap as the company positions itself for what executives call &quot;the age of AI and beyond.&quot; Rather than building its own AI agents to complete specific tasks, <a href="https://investors.upwork.com/news-releases/news-release-details/upwork-evolves-uma-ai-ai-work-agent-advances-human-ai"><u>Upwork is developing Uma</u></a>, a &quot;meta orchestration agent&quot; that coordinates between human workers, AI systems, and clients.</p><p>&quot;Today, Upwork is a marketplace where clients look for freelancers to get work done, and then talent comes to Upwork to find work,&quot; Rabinovich explained. &quot;This is getting expanded into a domain where clients come to Upwork, communicate with Uma, this meta-orchestration agent, and then Uma identifies the necessary talent to get the job done, gets the tasks outcomes completed, and then delivers that to the client.&quot;</p><p>In this vision, clients would interact primarily with Uma rather than directly hiring freelancers. The AI system would analyze project requirements, determine which tasks require human expertise versus AI execution, coordinate the workflow, and ensure quality — acting as an intelligent project manager rather than a replacement worker.</p><p>&quot;We don&#x27;t want to build agents that actually complete the tasks, but we are building this meta orchestration agent that figures out what human and agent talent is necessary in order to complete the tasks,&quot; Rabinovich said. &quot;Uma evaluates the work to be delivered to the client, orchestrates the interaction between humans and agents, and is able to learn from all the interactions that happen on the platform how to break jobs into tasks so that they get completed in a timely and effective manner.&quot;</p><p>The company recently <a href="https://investors.upwork.com/news-releases/news-release-details/upwork-announces-forthcoming-lisbon-office-scale-ai-innovation"><u>announced plans to open its first international office</u></a> in Lisbon, Portugal, by the fourth quarter of 2026, with a focus on AI infrastructure development and technical hiring. The expansion follows Upwork&#x27;s record-breaking third quarter, driven partly by AI-powered product innovation and strong demand for workers with AI skills.</p><h2><b>OpenAI, Anthropic, and Google race to build autonomous agents—but reality lags hype</b></h2><p>Upwork&#x27;s findings arrive amid escalating competition in the AI agent space. OpenAI, Anthropic, Google, and numerous startups are racing to develop autonomous agents capable of complex multi-step tasks, from booking travel to analyzing financial data to writing software.</p><p>But recent high-profile stumbles have tempered initial enthusiasm. AI agents frequently misunderstand instructions, make logical errors, or produce confidently wrong results — a phenomenon researchers call &quot;hallucination.&quot; The gap between controlled demonstration videos and reliable real-world performance remains vast.</p><p>&quot;There have been some evaluations that came from OpenAI and other platforms where real Upwork tasks were considered for completion by agents, and across the board, the reported results were not very optimistic, in the sense that they showed that agents—even the best ones, meaning powered by most advanced LLMs — can&#x27;t really compete with humans that well, because the completion rates are pretty low,&quot; Rabinovich said.</p><p>Rather than waiting for AI to fully mature — a timeline that remains uncertain—Upwork is betting on a hybrid approach that leverages AI&#x27;s strengths (speed, scalability, pattern recognition) while retaining human strengths (judgment, creativity, contextual understanding).</p><p>This philosophy extends to learning and improvement. Current AI models train primarily on static datasets scraped from the internet, supplemented by human preference feedback. But most professional work is qualitative, making it difficult for AI systems to know whether their outputs are actually good without expert evaluation.</p><p>&quot;Unless you have this collaboration between the human and the machine, where the human is kind of the teacher and the machine is the student trying to discover new solutions, none of this will be possible,&quot; Rabinovich said. &quot;Upwork is very uniquely positioned to create such an environment because if you try to do this with, say, self-driving cars, and you tell Waymo cars to explore new ways of getting to the airport, like avoiding traffic signs, then a bunch of bad things will happen. In doing work on Upwork, if it creates a wrong website, it doesn&#x27;t cost very much, and there&#x27;s no negative side effects. But the opportunity to learn is absolutely tremendous.&quot;</p><h2><b>Will AI take your job? The evidence suggests a more complicated answer</b></h2><p>While much public discourse around AI focuses on job displacement, Rabinovich argues the historical pattern suggests otherwise — though the transition may prove disruptive.</p><p>&quot;The narrative in the public is that AI is eliminating jobs, whether it&#x27;s writing, translation, coding or other digital work, but no one really talks about the exponential amount of new types of work that it will create,&quot; he said. &quot;When we invented electricity and steam engines and things like that, they certainly replaced certain jobs, but the amount of new jobs that were introduced is exponentially more, and we think the same is going to happen here.&quot;</p><p>The research identifies emerging job categories focused on AI oversight: designing effective human-machine workflows, providing high-quality feedback to improve agent performance, and verifying that AI-generated work meets quality standards. These skills—prompt engineering, agent supervision, output verification—barely existed two years ago but now command premium rates on platforms like Upwork.</p><p>&quot;New types of skills from humans are becoming necessary in the form of how to design the interaction between humans and machines, how to guide agents to make them better, and ultimately, how to verify that whatever agentic proposals are being made are actually correct, because that&#x27;s what&#x27;s necessary in order to advance the state of AI,&quot; Rabinovich said.</p><p>The question remains whether this transition—  from doing tasks to overseeing them — will create opportunities as quickly as it disrupts existing roles. For freelancers on Upwork, the answer may already be emerging in their bank accounts: The platform saw AI-related work grow 53% year-over-year, even as fears of AI-driven unemployment dominated headlines.</p>]]></description>
            <author>michael.nunez@venturebeat.com (Michael Nuñez)</author>
            <category>AI</category>
            <category>Automation</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/1v1ddqAyA62qgnuh9O3ek5/6c2c87800376ecfd23a29d2c01c593e4/nuneybits_Robot_and_human_working_side_by_side_in_a_modern_offi_8b67c654-4d49-42c2-a291-5a9bb86c99db.webp?w=300&amp;q=30" length="0" type="image/webp"/>
        </item>
        <item>
            <title><![CDATA[Inside LinkedIn’s generative AI cookbook: How it scaled people search to 1.3 billion users ]]></title>
            <link>https://venturebeat.com/ai/inside-linkedins-generative-ai-cookbook-how-it-scaled-people-search-to-1-3</link>
            <guid isPermaLink="false">2xa9OSjO1OK4xuOEusNmr4</guid>
            <pubDate>Thu, 13 Nov 2025 16:00:00 GMT</pubDate>
            <description><![CDATA[<p>LinkedIn is launching its new AI-powered people search this week, after what seems like a very long wait for what should have been a natural offering for generative AI.</p><p>It comes a full three years after the launch of ChatGPT and six months after LinkedIn launched its AI job search offering. For technical leaders, this timeline illustrates a key enterprise lesson: Deploying generative AI in real enterprise settings is challenging, especially at a scale of 1.3 billion users. It’s a slow, brutal process of pragmatic optimization.</p><p>The following account is based on several exclusive interviews with the LinkedIn product and engineering team behind the launch.</p><p>First, here’s how the product works: A user can now type a natural language query like, <b>&quot;Who is knowledgeable about curing cancer?&quot; </b>into LinkedIn’s search bar.</p><p>LinkedIn&#x27;s old search, based on keywords, would have been stumped. It would have looked only for references to &quot;cancer&quot;. If a user wanted to get sophisticated, they would have had to run separate, rigid keyword searches for &quot;cancer&quot; and then &quot;oncology&quot; and manually try to piece the results together.</p><p>The new AI-powered system, however, understands the <i>intent</i> of the search because the LLM under the hood grasps semantic meaning. It recognizes, for example, that &quot;cancer&quot; is conceptually related to &quot;oncology&quot; and even less directly, to &quot;genomics research.&quot; As a result, it surfaces a far more relevant list of people, including oncology leaders and researchers, even if their profiles don&#x27;t use the exact word &quot;cancer.&quot;</p><p>The system also balances this relevance with <i>usefulness</i>. Instead of just showing the world&#x27;s top oncologist (who might be an unreachable third-degree connection), it will also weigh who in your immediate network — like a first-degree connection — is &quot;pretty relevant&quot; and can serve as a crucial bridge to that expert.</p><p>See the video below for an example.</p><p>Arguably, though, the more important lesson for enterprise practitioners is the &quot;cookbook&quot; LinkedIn has developed: a replicable, multi-stage pipeline of distillation, co-design, and relentless optimization. LinkedIn had to perfect this on one product before attempting it on another.</p><p>&quot;Don&#x27;t try to do too much all at once,&quot; writes Wenjing Zhang, LinkedIn&#x27;s VP of Engineering, in a  post about the product launch, and who also spoke with VentureBeat last week in an interview. She notes that an earlier &quot;sprawling ambition&quot; to build a unified system for all of LinkedIn&#x27;s products &quot;stalled progress.&quot;</p><p>Instead, LinkedIn focused on winning one vertical first. The success of its previously launched AI Job Search — which led to job seekers without a four-year degree being <b>10% more likely to get hired</b>, according to VP of Product Engineering Erran Berger — provided the blueprint.</p><p>Now, the company is applying that blueprint to a far larger challenge. &quot;It&#x27;s one thing to be able to do this across tens of millions of jobs,&quot; Berger told VentureBeat. &quot;It&#x27;s another thing to do this across north of a billion members.&quot;</p><p>For enterprise AI builders, LinkedIn&#x27;s journey provides a technical playbook for what it <i>actually</i> takes to move from a successful pilot to a billion-user-scale product.</p><h2><b>The new challenge: a 1.3 billion-member graph</b></h2><p>The job search product created a robust recipe that the new people search product could build upon, Berger explained. </p><p>The recipe started with with a &quot;golden data set&quot; of just a few hundred to a thousand real query-profile pairs, meticulously scored against a detailed 20- to 30-page &quot;product policy&quot; document. To scale this for training, LinkedIn used this small golden set to prompt a large foundation model to generate a massive volume of <i>synthetic</i> training data. This synthetic data was used to train a <b>7-billion-parameter</b> &quot;Product Policy&quot; model — a high-fidelity judge of relevance that was too slow for live production but perfect for teaching smaller models.</p><p>However, the team hit a wall early on. For six to nine months, they struggled to train a single model that could balance strict policy adherence (relevance) against user engagement signals. The &quot;aha moment&quot; came when they realized they needed to break the problem down. They distilled the 7B policy model into a <b>1.7B teacher model</b> focused solely on relevance. They then paired it with separate teacher models trained to predict specific member actions, such as job applications for the jobs product, or connecting and following for people search. This &quot;multi-teacher&quot; ensemble produced soft probability scores that the final student model learned to mimic via KL divergence loss.</p><p>The resulting architecture operates as a two-stage pipeline. First, a larger <b>8B parameter model</b> handles broad retrieval, casting a wide net to pull candidates from the graph. Then, the highly distilled student model takes over for fine-grained ranking. While the job search product successfully deployed a <b>0.6B (600-million)</b> parameter student, the new people search product required even more aggressive compression. As Zhang notes, the team pruned their new student model from 440M down to just <b>220M parameters</b>, achieving the necessary speed for 1.3 billion users with less than 1% relevance loss.</p><p>But applying this to people search broke the old architecture. The new problem included not just <i>ranking</i> but also <i>retrieval</i>.</p><p>“A billion records,&quot; Berger said, is a &quot;different beast.&quot;</p><p>The team’s prior retrieval stack was built on CPUs. To handle the new scale and the latency demands of a &quot;snappy&quot; search experience, the team had to move its indexing to <b>GPU-based infrastructure</b>. This was a foundational architectural shift that the job search product did not require.</p><p>Organizationally, LinkedIn benefited from multiple approaches. For a time, LinkedIn had two separate teams <!-- -->— <!-- -->job search and people search <!-- -->— <!-- -->attempting to solve the problem in parallel. But once the job search team achieved its breakthrough using the policy-driven distillation method, Berger and his leadership team intervened. They brought over the architects of the job search win <!-- -->—  <!-- -->product lead Rohan Rajiv and engineering lead Wenjing Zhang <!-- -->— <!-- -->to transplant their &#x27;cookbook&#x27; directly to the new domain.</p><h2><b>Distilling for a 10x throughput gain</b></h2><p>With the retrieval problem solved, the team faced the ranking and efficiency challenge. This is where the cookbook was adapted with new, aggressive optimization techniques.</p><p>Zhang’s technical post <b>(I’ll insert the link once it goes live)</b> provides the specific details our audience of AI engineers will appreciate. One of the more significant optimizations was input size.</p><p>To feed the model, the team trained <i>another</i> LLM with reinforcement learning (RL) for a single purpose: to summarize the input context. This &quot;summarizer&quot; model was able to reduce the model&#x27;s input size by <b>20-fold</b> with minimal information loss.</p><p>The combined result of the 220M-parameter model and the 20x input reduction? A <b>10x increase in ranking throughput</b>, allowing the team to serve the model efficiently to its massive user base.</p><h2><b>Pragmatism over hype: building tools, not agents</b></h2><p>Throughout our discussions, Berger was adamant about something else that might catch peoples’ attention: The real value for enterprises today lies in perfecting recommender systems, not in chasing &quot;agentic hype.&quot; He also refused to talk about the specific models that the company used for the searches, suggesting it almost doesn&#x27;t matter. The company selects models based on which one it finds the most efficient for the task.</p><p>The new AI-powered people search is a manifestation of Berger’s philosophy that it’s best to optimize the recommender system first. The architecture includes a new &quot;intelligent query routing layer,&quot; as Berger explained, that itself is LLM-powered. This router pragmatically decides if a user&#x27;s query — like &quot;trust expert&quot; — should go to the new semantic, natural-language stack or to the old, reliable lexical search.</p><p>This entire, complex system is designed to be a &quot;tool&quot; that a <i>future</i> agent will use, not the agent itself.</p><p>&quot;Agentic products are only as good as the tools that they use to accomplish tasks for people,&quot; Berger said. &quot;You can have the world&#x27;s best reasoning model, and if you&#x27;re trying to use an agent to do people search but the people search engine is not very good, you&#x27;re not going to be able to deliver.&quot; </p><p>Now that the people search is available, Berger suggested that one day the company will be offering agents to use it. But he didn’t provide details on timing. He also said the recipe used for job and people search will be spread across the company’s other products.</p><p>For enterprises building their own AI roadmaps, LinkedIn&#x27;s playbook is clear:</p><ol><li><p><b>Be pragmatic:</b> Don&#x27;t try to boil the ocean. Win one vertical, even if it takes 18 months.</p></li><li><p><b>Codify the &quot;cookbook&quot;:</b> Turn that win into a repeatable process (policy docs, distillation pipelines, co-design).</p></li><li><p><b>Optimize relentlessly:</b> The real 10x gains come <i>after</i> the initial model, in pruning, distillation, and creative optimizations like an RL-trained summarizer.</p></li></ol><p>LinkedIn&#x27;s journey shows that for real-world enterprise AI, emphasis on specific models or cool agentic systems should take a back seat. The durable, strategic advantage comes from mastering the <i>pipeline</i> — the &#x27;AI-native&#x27; cookbook of co-design, distillation, and ruthless optimization.</p><p><i>(Editor&#x27;s note: We will be publishing a full-length podcast with LinkedIn&#x27;s Erran Berger, which will dive deeper into these technical details, on the VentureBeat podcast feed soon.)</i></p>]]></description>
            <author>mmarshall@venturebeat.com (Matt Marshall)</author>
            <category>AI</category>
            <category>Data Infrastructure</category>
            <category>Data management</category>
            <category>Enterprise</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/lgGMZPiCCaW1DNedEGAbm/a05d0e3b39eea0fae4e58895fad8d198/Screenshot_2025-11-12_at_4.53.46â__PM.png?w=300&amp;q=30" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[Alembic melted GPUs chasing causal A.I. — now it's running one of the fastest supercomputers in the world]]></title>
            <link>https://venturebeat.com/ai/alembic-melted-gpus-chasing-causal-a-i-now-its-running-one-of-the-fastest</link>
            <guid isPermaLink="false">emyIY1Ck5VnbUo26gGdqF</guid>
            <pubDate>Thu, 13 Nov 2025 10:00:00 GMT</pubDate>
            <description><![CDATA[<p><a href="https://getalembic.com/"><u>Alembic Technologies</u></a> has raised <a href="https://www.wsj.com/articles/accenture-and-jeffrey-katzenbergs-wndrco-invest-in-ai-marketing-startup-0d128cdf?gaa_at=eafs&amp;gaa_n=AWEtsqdAgTQlPWgG_zv7n1SIS4Of1exsALNEgz80-hPnE-H3wcyRNF34nWNExI000IU%3D&amp;gaa_ts=69165918&amp;gaa_sig=aOxQL4j4oFVsOjvwebrVj1MQQhZL4ME3iA9Xa6C4-nhcIF6iHrzIotnwSO8OMWrWhrwM6mZYirOw7pOAZpzmZw%3D%3D"><u>$145 million in Series B</u></a> and growth funding at a valuation 13 times higher than its previous round, betting that the next competitive advantage in artificial intelligence will come not from better language models but from proprietary data and causal reasoning.</p><p>The San Francisco-based startup, which builds AI systems that identify <a href="https://venturebeat.com/ai/exclusive-alembic-debuts-hallucination-free-ai-for-enterprise-data-analysis-and-decision-support"><u>cause-and-effect relationships</u></a> rather than mere correlations, is using a significant portion of the capital to deploy what it claims is one of the fastest privately owned supercomputers ever built — an <a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/"><u>Nvidia NVL72 superPOD</u></a> that will power its enterprise-grade causal AI models.</p><p>The investment, led by <a href="https://www.prysmcapital.com/"><u>Prysm Capital</u></a> and <a href="https://www.accenture.com/us-en"><u>Accenture</u></a> with participation from <a href="https://www.slw.vc/"><u>Silver Lake Waterman</u></a>, <a href="https://www.liquid2.vc/"><u>Liquid 2 Ventures</u></a>, <a href="https://www.nextequity.com/"><u>NextEquity</u></a>, <a href="https://www.fafc.com/"><u>Friends &amp; Family Capital</u></a> and <a href="https://www.wndrco.com/"><u>WndrCo</u></a>, positions Alembic among a select group of well-funded AI laboratories transforming how corporations make multimillion-dollar decisions.</p><p>The funding round and the company&#x27;s strategic direction reflect a broader shift taking place in enterprise AI as the performance gap between competing large language models narrows. While startups and tech giants have poured billions into building ever-larger chatbots, Alembic is pursuing a different thesis: that the real value in AI will accrue to systems that can process private corporate data to answer questions that generic models cannot.</p><p>&quot;As powerful artificial intelligence models increasingly converge in capability, the key competitive advantage shifts to proprietary data,&quot; said Tomás Puig, Alembic&#x27;s founder and chief executive, in an interview with VentureBeat. &quot;Getting a real edge isn&#x27;t about using the best LLM; it&#x27;s leveraging the unique information rivals can&#x27;t access.&quot;</p><p>Puig illustrated the problem facing enterprise executives: &quot;Imagine I run a CPG company and I install the latest ChatGPT. I ask, &#x27;Hey, ChatGPT, give me a strategy for how to increase my revenue share in the northeast.&#x27; Then your competitor down the road asks the exact same question. How much trouble are you in when they get the exact same answer?&quot;</p><h2><b>How a broke startup on Mac Pros discovered a breakthrough that changed everything</b></h2><p>The dramatic valuation increase—from roughly <a href="https://venturebeat.com/ai/katzenberg-backed-alembic-raises-14m-pioneers-new-frontier-in-marketing-analytics"><u>$50 million at the Series A</u></a> to approximately $645 million now, according to people familiar with the matter — reflects a fundamental transformation in Alembic&#x27;s technology and market positioning since its previous funding round.</p><p>When the company <a href="https://venturebeat.com/ai/katzenberg-backed-alembic-raises-14m-pioneers-new-frontier-in-marketing-analytics"><u>raised its Series A in early 2024</u></a>, it was primarily a signal processing and correlation analytics company focused on marketing measurement. &quot;Causal did not exist as a technology for us till after the Series A,&quot; Puig told VentureBeat. The company was so resource-constrained that it couldn&#x27;t even run simulations to test whether its causal models would work.</p><p>The breakthrough came after the Series A when the company finally had enough capital to test its theories. &quot;We were so broke that we couldn&#x27;t even run the simulation to see if it worked,&quot; Puig recalled. When they did run the tests — initially on an &quot;army of Mac Pros&quot; because they didn&#x27;t yet have GPU infrastructure — they discovered something unexpected: their causal model worked not just for marketing analytics but across virtually any business domain with time-series data.</p><p>&quot;We started adding capabilities as customers requested them, which was just sensible—iterative,&quot; Puig explained. &quot;We found out the model works across a huge majority of data universally. What we thought might be a model for a specific vertical ended up being a full, generalized foundational model.&quot;</p><p>That discovery transformed Alembic from a marketing technology vendor into a company building what Puig describes as &quot;the entire central nervous system of the enterprise across all verticals — not just sales, marketing, supply chain, finance, and beyond.&quot;</p><h2><b>Why cause-and-effect AI matters more than correlation for enterprise decision-making</b></h2><p><a href="https://venturebeat.com/ai/exclusive-alembic-debuts-hallucination-free-ai-for-enterprise-data-analysis-and-decision-support"><u>Causal AI</u></a> is a fundamentally different approach from the correlation-based analytics that dominate most business intelligence tools and even many AI systems. Where traditional analytics might show that social media engagement correlates with sales increases, causal AI can determine whether the social media activity actually caused the sales lift — or whether both were driven by some third factor, like a viral news event.</p><p>The distinction matters enormously for executives making budget allocation decisions. &quot;Most businesses are not short on data,&quot; Puig said. &quot;They are short on answers.&quot;</p><p>For Alembic&#x27;s customers, which now include <a href="https://www.delta.com/"><u>Delta Air Lines</u></a>, <a href="https://www.mars.com/"><u>Mars</u></a>, <a href="https://www.nvidia.com/en-us/"><u>Nvidia</u></a> and several Fortune 500 companies across financial services, technology and consumer packaged goods, the platform can answer previously unanswerable questions about marketing effectiveness, operational efficiency and strategic investments.</p><p>&quot;Alembic&#x27;s ability to connect marketing exposure directly to business outcomes—with speed, precision and granularity—is what made this relationship so transformative for us,&quot; said Alicia Tillman, chief marketing officer at Delta Air Lines. &quot;Unlike traditional measurement tools, Alembic gave us a unified view across channels and campaigns, unlocking insights we simply couldn&#x27;t access before.&quot;</p><p>The airline used Alembic to quantify the revenue lift from its <a href="https://www.delta.com/us/en/about-delta/team-usa"><u>Team USA Olympics sponsorship</u></a> within days of activation, directly linking brand activities to ticket sales—a type of measurement that has eluded marketers for decades. Traditional attribution models either ignore brand-building entirely or assign it vague &quot;awareness&quot; metrics that don&#x27;t translate to financial impact.</p><p>&quot;It&#x27;s very transformative,&quot; Puig said of the customer impact. &quot;What&#x27;s interesting is that executives themselves are the users of our software and our outputs. It&#x27;s not a tool used by a single campaign manager.&quot;</p><h2><b>Inside the two-story liquid-cooled supercomputer that literally melted GPUs</b></h2><p>Alembic&#x27;s decision to invest heavily in owned computing infrastructure rather than rely on cloud providers stems from both the technical demands of its causal models and the extreme data sensitivity requirements of its enterprise customers.</p><p>The company is deploying an <a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/"><u>Nvidia NVL72 superPOD</u></a> — a massive liquid-cooled system equipped with Nvidia&#x27;s most advanced Blackwell graphics processing units — in partnership with data center operator <a href="https://www.equinix.com/"><u>Equinix</u></a> in San Jose, Calif. According to Puig, Nvidia informed Alembic that it is the only non-Fortune 500 company in the world to operate such a system.</p><p>The need for this level of compute stems from how Alembic&#x27;s models work. Unlike large language models that are trained once on historical data and then deployed, Alembic&#x27;s system uses &quot;online and evolving&quot; models built on spiking neural networks — brain-inspired architectures that continuously learn as new data arrives.</p><p>&quot;It creates itself as you feed it data, like human evolution,&quot; Puig explained. &quot;The model is singular, but it ends up creating a different brain for every single company.&quot;</p><p>This continuous learning happens at massive scale. When a customer brings in data, Alembic&#x27;s system automatically permutates through billions of possible combinations of how that data could be analyzed — testing every conceivable way to slice metrics and dimensions to find the strongest causal signals. That level of computation requires what Puig calls &quot;F1 car&quot; infrastructure rather than the &quot;production Porsche&quot; offered by cloud providers.</p><p>The company writes custom <a href="https://developer.nvidia.com/cuda-toolkit"><u>CUDA code</u></a> and low-level <a href="https://huggingface.co/blog/kernel-builder"><u>GPU kernels</u></a> optimized specifically for causal inference workloads — optimizations that aren&#x27;t possible on standard cloud configurations. The approach has proven so demanding that Alembic famously once melted down its GPUs by pushing them beyond their thermal limits. &quot;We literally just drive these circuits so hard that we need the F1 car version and we have to have access to it,&quot; Puig said.</p><p>The move to liquid-cooled systems addresses that problem, but it also enables Alembic to run workloads that would cost orders of magnitude more on cloud platforms. &quot;We did the math—if we were to buy just one subsection of our compute from AWS, it would be $62 million a year,&quot; Puig said. Owning the infrastructure costs &quot;a fraction of that.&quot;</p><p>The supercomputer strategy serves another crucial purpose: data sovereignty. Many of Alembic&#x27;s customers — particularly in financial services, consumer packaged goods and regulated industries — have contractual prohibitions against putting sensitive data on <a href="https://aws.amazon.com/"><u>Amazon Web Services</u></a>, <a href="https://azure.microsoft.com/en-us/"><u>Microsoft Azure</u></a> or <a href="https://cloud.google.com/?hl=en"><u>Google Cloud</u></a>.</p><p>&quot;CPG companies do not want any data to exist on Amazon, ever,&quot; Puig said. &quot;They simply won&#x27;t allow it. Some customers refuse to use Microsoft, others avoid different providers. And certain banks and financial institutions are legally prohibited from using cloud platforms at all.&quot;</p><p>By operating its own infrastructure in neutral data centers, Alembic can serve customers who would never consider cloud-based analytics — a competitive moat that would be difficult for hyperscale cloud providers to replicate.</p><h2><b>How Jensen Huang read a news article and changed Alembic&#x27;s destiny</b></h2><p>Alembic&#x27;s relationship with Nvidia illustrates both the startup&#x27;s technical ambitions and how the chip giant supports promising AI companies. Nvidia is Alembic&#x27;s founding enterprise customer, exclusive supercomputing partner and a key technical collaborator — though notably not an investor.</p><p>The relationship began in an unlikely way. After Alembic announced its Series A funding in early 2024, Nvidia co-founder and CEO <a href="https://venturebeat.com/ai/katzenberg-backed-alembic-raises-14m-pioneers-new-frontier-in-marketing-analytics"><u>Jensen Huang read the VentureBeat coverage</u></a> and emailed his staff suggesting they explore the company, according to Puig. Because Alembic didn&#x27;t yet have a contact form on its website, an Nvidia director reached out via LinkedIn.</p><p>The partnership nearly foundered on a basic constraint: computing capacity. After Alembic delivered its first causal analysis — which took weeks to generate on an array of Mac Pros — Nvidia asked if they could produce weekly reports. &quot;I said no, because it took weeks on this army of machines,&quot; Puig recalled.</p><p>When Alembic said they could do it with GPUs but couldn&#x27;t secure the necessary compute — cloud providers at the time required committee approvals and offered two- to six-week lead times with no guarantees — Nvidia intervened directly. The chip maker arranged for <a href="https://www.equinix.com/"><u>Equinix</u></a> to provide a private cage in Northern Virginia with sufficient power capacity and helped Alembic source its first <a href="https://www.nvidia.com/en-us/data-center/h100/"><u>H100 GPU</u></a> cluster.</p><p>&quot;Without that, the company would never have existed,&quot; Puig said. &quot;We couldn&#x27;t get the compute in the configuration we needed anywhere else.&quot;</p><p>The partnership has since deepened. Alembic uses <a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/"><u>Nvidia&#x27;s AI Enterprise software suite</u></a>, including specialized libraries like cuGraph for graph processing and TensorRT for high-speed inference. The tight integration, Puig said, allows &quot;our research teams to leverage multi-exaflop-level compute and Nvidia&#x27;s algorithmic software stack. This integration is one of our secret weapons: we spend more time on breakthrough research and mathematics and less time on repetitive low-level engineering.&quot;</p><p>Nvidia&#x27;s support extended beyond technology. When Alembic kept destroying GPUs under extreme workloads — pushing chips so hard that thermal stress cracked circuit boards — Nvidia fast-tracked the startup&#x27;s access to next-generation liquid-cooled systems. &quot;The funny reason we got [the <a href="https://www.nvidia.com/en-us/data-center/gb200-nvl72/"><u>NVL72</u></a>],&quot; Puig said, &quot;is because when we melted the chips, Nvidia was literally annoyed with how often they had to service our warranty.&quot;</p><h2><b>From Olympics sponsorships to viral candy moments: How Fortune 500s measure what was unmeasurable</b></h2><p>Alembic&#x27;s customer roster has expanded rapidly as enterprises seek ways to measure AI and marketing investments that traditional analytics cannot capture. The company now works with <a href="https://www.delta.com/"><u>Delta Air Lines</u></a>, <a href="https://www.mars.com/"><u>Mars</u></a>, multiple Fortune 500 technology and financial services firms, and <a href="https://www.tamu.edu/athletics/index.html"><u>Texas A&amp;M University&#x27;s</u></a> athletics program.</p><p>The use cases span far beyond Alembic&#x27;s original marketing focus. Mars used the platform to measure the sales impact of changing candy shapes for themed promotions. A Fortune 500 technology company expanded its sales pipeline by 37% using Alembic&#x27;s attribution models. Financial services firms are using it to connect CEO public appearances and co-marketing expenditures to actual fund flows.</p><p>&quot;Alembic helped us move past impression counts to show what actually drove net-new investment,&quot; said the head of co-marketing at a Fortune 200 financial services company. &quot;For the first time, we could see how our CEO in the public eye and our co-marketing dollars with exchanges translated into real fund flows.&quot;</p><p>For Mars, the ability to measure previously unmeasurable activities has transformed decision-making. &quot;We are using math to liberate creativity,&quot; said Gülen Bengi, lead global chief marketing officer for Mars and global chief growth officer for Mars Snacking. &quot;Our fans and communities create billions of organic conversations and content about our brands. When a viral moment happens, we normally know it&#x27;s directionally positive, but we can&#x27;t attribute the sales uplift or its place in the customer journey. Alembic&#x27;s Causal AI is a breakthrough, allowing us to move beyond correlation to see exactly how that organic conversation created a sequence that directly impacted sales.&quot;</p><p>The platform can predict revenue, close rates and customer acquisition up to two years in advance with 95% confidence, according to Puig. &quot;What they were doing before was they actually literally did not know about certain things,&quot; he said, describing how customers previously estimated the value of stadium naming rights or major sponsorships without ever measuring actual dollar impact. &quot;Now you can go and be like it had this effect on this much P&amp;L, and this is where it&#x27;s flowing, and you can know within days or near real time.&quot;</p><h2><b>Why Google, Meta and Nielsen can&#x27;t easily replicate what Alembic built</b></h2><p>Alembic operates in a competitive landscape that includes traditional marketing measurement vendors like <a href="https://www.nielsen.com/"><u>Nielsen</u></a>, analytics platforms from <a href="https://marketingplatform.google.com/about/analytics/"><u>Google</u></a> and <a href="https://www.facebook.com/business/"><u>Meta</u></a>, and emerging AI-powered analytics startups. But Puig argues the company has built structural advantages that would be difficult to replicate.</p><p>First, the company&#x27;s causal models rely on proprietary mathematics developed over years and protected by patents. &quot;You would have to start from scratch,&quot; Puig said. &quot;This is not like an LLM that uses a transformer that has a paper, and you could attempt to recreate. You&#x27;d actually have to go and recreate the methodology from scratch.&quot;</p><p>Second, the massive computing requirements create a natural barrier. Alembic operates at &quot;foundational model levels of compute, not like even something you would run from [AWS] Sagemaker,&quot; Puig said. &quot;We&#x27;re talking about hundreds of millions of dollars a year&quot; in equivalent cloud costs.</p><p>Third, the data sovereignty requirements of enterprise customers create opportunities for neutral third parties that hyperscale cloud providers struggle to address. As one venture capital investor noted, enterprises increasingly worry about putting strategic data into systems owned by potential competitors.</p><p>Finally, Alembic&#x27;s ability to work with messy, fragmented data reflects years of engineering that preceded its causal AI breakthrough. &quot;The first four [or] five years of the company&#x27;s life was building that giant signal processor that dealt with messy data,&quot; Puig said. &quot;We would not be able to do it if we had not taken all that time.&quot;</p><h2><b>Why Alembic&#x27;s contrarian bet on private data could reshape enterprise AI</b></h2><p>The $145 million funding round validates a contrarian bet in an AI landscape dominated by the race to build ever-larger language models. While <a href="https://openai.com/"><u>OpenAI</u></a>, <a href="https://www.anthropic.com/"><u>Anthropic</u></a> and others compete on whose chatbot can write better code or answer more trivia questions, Alembic is building infrastructure for a different kind of intelligence — one that understands cause and effect in the messy, proprietary data that defines each company&#x27;s unique competitive position.</p><p>The company&#x27;s evolution from a bootstrapped startup running simulations on Mac Pros to operating one of the world&#x27;s fastest private supercomputers mirrors the broader maturation of enterprise AI. As the technology moves from experimentation to mission-critical deployment, companies need more than general-purpose models trained on public data. They need systems that can process their private information to answer questions their competitors cannot.</p><p>Puig&#x27;s thesis — that private data becomes the key differentiator as public models converge — resonates with how other technologies evolved. Search engines commoditized access to public information, making proprietary data more valuable. Cloud computing made infrastructure a utility, elevating the importance of what you build on top of it. If large language models similarly converge in capability, the competitive advantage flows to whoever can best extract intelligence from data others cannot access.</p><p>The company is already testing its technology beyond marketing analytics. Pilots are underway in robotics, where causal models could help autonomous systems understand how actions lead to outcomes. New product lines are launching, including the GPU-accelerated database that customers are buying separately. The ambition, Puig said, is to become &quot;the central nervous system&quot; of the enterprise — the layer that connects cause and effect across every business function.</p><p>Whether <a href="https://getalembic.com/"><u>Alembic</u></a> can deliver on that vision remains to be seen. The company operates in complex enterprise environments where sales cycles are long and integration challenges are significant. Competitors aren&#x27;t standing still, and the technical moats that protect it today may erode as causal AI techniques become better understood.</p><p>But for now, Alembic occupies a unique position. It has marquee customers achieving measurable results. It has infrastructure that would cost hundreds of millions to replicate on cloud platforms. It has proprietary mathematics refined over years of dealing with messy enterprise data. And it has $145 million to scale what Puig describes as a fundamental shift from correlation to causation.</p><p>In his interview with VentureBeat, Puig drew a parallel to quantitative hedge funds that use mathematics to gain trading advantages that general-purpose AI cannot match. &quot;ChatGPT still can&#x27;t equal Renaissance Technologies,&quot; he said, referring to the secretive firm that has generated historic returns through quantitative models.</p><p>The comparison captures Alembic&#x27;s core insight: that in a world where everyone has access to the same general-purpose AI, sustainable advantage comes from specialized systems that understand the cause-and-effect relationships hiding in your data. It&#x27;s a bet that the future of enterprise AI looks less like a universal chatbot and more like a private intelligence engine — one that, to Puig&#x27;s original point, prevents your competitor from getting the same answer when they ask the same question.</p>]]></description>
            <author>michael.nunez@venturebeat.com (Michael Nuñez)</author>
            <category>AI</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/1X74wYDQUVik71TsArk7Jy/74e1646a1c4505e1057cc623128925a8/nuneybits_Vector_art_of_melting_GPUs_image_in_lime_green_0fe12726-8bf9-4abe-baed-911e9574724f.webp?w=300&amp;q=30" length="0" type="image/webp"/>
        </item>
        <item>
            <title><![CDATA[Weibo's new open source AI model VibeThinker-1.5B outperforms DeepSeek-R1 on $7,800 post-training budget]]></title>
            <link>https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on</link>
            <guid isPermaLink="false">3J3sqDAlGsxmqW2T1ViuEq</guid>
            <pubDate>Wed, 12 Nov 2025 19:31:00 GMT</pubDate>
            <description><![CDATA[<p>Another day in late 2025, another impressive result from a Chinese company in open source artificial intelligence.</p><p>Chinese social networking company <a href="https://huggingface.co/WeiboAI/VibeThinker-1.5B">Weibo&#x27;s AI division recently released its open source VibeThinker-1.5B</a>—a 1.5 billion parameter large language model (LLM) that is a fine-tuned variant of rival Chinese tech firm <a href="https://huggingface.co/Qwen/Qwen2.5-Math-1.5B">Alibaba&#x27;s Qwen2.5-Math-1.5B. </a></p><p>It&#x27;s available now for free download and usage by researchers and enterprise developers—even for commercial purposes—under a permissive MIT License on <a href="https://huggingface.co/WeiboAI/VibeThinker-1.5B">Hugging Face</a>, <a href="https://github.com/WeiboAI/VibeThinker">GitHub</a> and <a href="https://modelscope.cn/models/WeiboAI/VibeThinker-1.5B">ModelScope</a>, with a <a href="https://arxiv.org/pdf/2511.06221">technical report</a> on open access science publishing site arxiv.org.</p><p>And yet, despite its compact size, VibeThinker-1.5B achieves benchmark-topping reasoning performance on math and code tasks, rivaling or surpassing models hundreds of times its size, even outperforming Chinese rival DeepSeek&#x27;s famed R1 that went viral at the start of this year—a 671-billion parameter model—on formal reasoning benchmark.</p><p>It further eclipses Mistral AI&#x27;s Magistral Medium and holds its own against Anthropic&#x27;s Claude Opus 4 and OpenAI&#x27;s gpt-oss-20B Medium, all while requiring a fraction of the infrastructure and investment.</p><p>It also does so having been post-trained on a budget of merely $7800 USD for compute resources (3900 GPU hours on Nvidia H800s) — far less than the tens, or even hundreds, of thousands of dollars typically required to fine-tune models of similar or larger scale.</p><p>Recall this is not the total cost of the model&#x27;s development, however: LLMs are trained in stages. First comes pre-training, when the model learns basic language structure and general knowledge by predicting the next word across enormous amounts of text from the internet, books, and articles. This gives it fluency but not much sense of how to follow instructions or hold a conversation</p><p>Post-training comes next, using much smaller, higher-quality datasets—typically collections of example questions, prompts, and expert-written answers—to teach the model how to respond helpfully, reason through problems, and align with human expectations. Still, Weibo&#x27;s post-training cost effectiveness on VibeThinker-1.5B is noteworthy and should be commended.</p><p>The open-source release upends assumptions about parameter scale, compute intensity, and the minimum viable size for high-performance LLMs.</p><h3><b>A Different Training Approach: Spectrum-to-Signal</b></h3><p>VibeThinker-1.5B owes its performance not to scale, but to the training framework behind it: the Spectrum-to-Signal Principle (SSP).</p><p>Instead of optimizing a model purely for single-answer correctness (Pass@1), the SSP framework decouples supervised fine-tuning (SFT) and reinforcement learning (RL) into two distinct phases with different goals:</p><ul><li><p><b>SFT (“Spectrum Phase”)</b>: The model is trained to maximize diversity across potential correct answers, improving its Pass@K score. This builds a wide range of plausible solution paths.</p></li><li><p><b>RL (“Signal Phase”)</b>: A second-stage reinforcement learning system (called MaxEnt-Guided Policy Optimization, or MGPO) is used to identify and amplify the most correct paths from this diverse solution pool. MGPO prioritizes problems where the model is most uncertain, using entropy-based weighting to focus learning.</p></li></ul><p>The authors argue this separation allows small models to explore reasoning space more effectively—achieving signal amplification without relying on massive parameter counts.</p><p>VibeThinker-1.5B makes a compelling case that the industry’s reliance on parameter scaling as the only route to better reasoning performance may be outdated. </p><p>By adopting a diversity-first training pipeline, WeiboAI has shown that smaller, more accessible models can match and even outperform billion-dollar systems in logic-heavy tasks.</p><p>The low resource footprint is among the most significant aspects of VibeThinker-1.5B. At under $8,000, the post-training cost is 30–60x lower than models like DeepSeek R1 and MiniMax-M1, which cost between $294K and $535K to train.</p><h3><b>Performance Across Domains</b></h3><p>Despite its small size, VibeThinker-1.5B delivers cross-domain reasoning that outpaces many larger open-source and commercial models:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>AIME25</b></p></td><td><p><b>LiveCodeBench v6</b></p></td><td><p><b>GPQA-Diamond</b></p></td></tr><tr><td><p><i>VibeThinker-1.5B</i></p></td><td><p><b>74.4</b></p></td><td><p><b>51.1</b></p></td><td><p>46.7</p></td></tr><tr><td><p>GPT-OSS-20B-Medium</p></td><td><p>72.1</p></td><td><p>54.9</p></td><td><p>66.0</p></td></tr><tr><td><p>Claude Opus 4</p></td><td><p>69.2</p></td><td><p>56.6</p></td><td><p>79.6</p></td></tr><tr><td><p>MiniMax M1 (456B)</p></td><td><p>74.6</p></td><td><p>62.3</p></td><td><p>69.2</p></td></tr><tr><td><p>DeepSeek R1 (671B)</p></td><td><p>70.0</p></td><td><p>65.9</p></td><td><p>71.5</p></td></tr><tr><td><p>Kimi K2 (1.09T)</p></td><td><p>49.5</p></td><td><p>53.7</p></td><td><p>75.1</p></td></tr></tbody></table><p>VibeThinker was benchmarked against both reasoning-centric models (Magistral, Claude, OpenAI o3-mini) and non-reasoning LLMs (GPT-4.1, Kimi K2, DeepSeek V3). Across structured reasoning benchmarks, the model consistently outperformed non-reasoning models, regardless of size:</p><ul><li><p>On AIME24 (math), it beat Kimi K2 (1.09T) by over 10 points (80.3 vs. 69.6).</p></li><li><p>On LiveCodeBench v6, it surpassed Claude Opus 4 (51.1 vs. 47.4).</p></li><li><p>On GPQA, it scored below GPT-4.1 and Claude, but still doubled its base model (from 16.4 to 46.7).</p></li></ul><p>This supports the authors’ claim that size is not the only path to reasoning capability—with proper training design, smaller models can reach or even exceed the performance of far larger systems in targeted tasks.</p><p>Notably, it achieves parity with models hundreds of times larger on math and code, though it lags behind in general knowledge reasoning (GPQA), where larger models maintain an edge.</p><p>This suggests a potential specialization trade-off: while VibeThinker excels at structured logical tasks, it has less capacity for wide-ranging encyclopedic recall, a known limitation of smaller architectures.</p><h3><b>Guidance for Enterprise Adoption</b></h3><p>The release includes recommended inference settings (temperature = 0.6, top_p = 0.95, max tokens = 40960).</p><p>The model is small enough to be deployed on edge devices, including mobile phones and vehicle-embedded systems, while inference costs are estimated to be 20–70x cheaper than with large models.</p><p>This positions VibeThinker-1.5B not just as a research achievement, but as a potential foundation for cost-efficient, locally deployable reasoning systems.</p><h3><b>Weibo’s Strategy and Market Position</b></h3><p>Weibo, launched by Sina Corporation in 2009, remains a cornerstone of China’s social media ecosystem. Often described as China’s version of X (formerly Twitter), the platform blends microblogging, multimedia content, and trending-topic features with a regulatory environment shaped by tight government oversight. </p><p>Despite counting 600 million monthly active users (more than twice that of X), <a href="https://m.aastocks.com/en/stocks/analysis/stock-aafn-con/9898/HK6/NOW.1483101/hk-stock-news">investors are not optimistic about its advertising revenue growth potential</a> in the near term, and Weibo is navigating intensifying competition from video-first platforms like Douyin, which are drawing younger users and increasing time-spent elsewhere. </p><p>In response, Weibo has leaned into creator-economy monetization, live-streaming, and vertical video—adding tools for influencer engagement, e-commerce integration, and richer analytics for brands.</p><p>The platform’s role as a digital public square also makes it a focus of regulatory scrutiny. Chinese authorities continue to apply pressure on issues ranging from content governance to data security. In September 2025, <a href="https://www.reuters.com/technology/chinas-internet-regulator-issues-warnings-kuaishou-weibo-over-content-violations-2025-09-20/">Weibo was among the platforms cited in official warnings</a>, highlighting its ongoing exposure to policy risks.</p><p>Weibo’s push into AI R&amp;D—exemplified by the release of VibeThinker-1.5B—signals a shift in ambition. Beyond being a media platform, Weibo is positioning itself as a player in the next phase of Chinese AI development, using its capital reserves, user behavior data, and in-house research capacity to pursue adjacent technical domains.</p><h3><b>What It Means for Enterprise Technical Decision Makers</b></h3><p>For engineering leaders and enterprise AI teams, VibeThinker’s release has practical implications for everything from orchestration pipelines to cost modeling. </p><p>A 1.5B-parameter model that outperforms 100x larger models on math and programming tasks doesn’t just save compute—it shifts the architectural balance. It enables LLM inference on constrained infrastructure, reduces latency at the edge, and lowers the barrier to entry for applications that otherwise would have required API access to closed, frontier-scale models.</p><p>That matters for enterprise ML leads trying to deploy reasoning-capable agents within existing systems, or for platform owners tasked with integrating LLMs into automated workflows. </p><p>It also speaks to those running reinforcement learning from human feedback (RLHF) pipelines or managing inference optimization across hybrid cloud environments. </p><p>The model’s post-training methodology—particularly its entropy-targeted reinforcement learning approach—offers a roadmap for teams looking to refine smaller checkpoints instead of relying on large-scale pretraining.</p><p>VibeThinker’s benchmark transparency and data decontamination steps also address another emerging priority in enterprise AI: auditability. While its performance on general-knowledge tests still trails large frontier models, its task-specific reliability makes it an attractive candidate for controlled environments where correctness matters more than coverage.</p><p>In short, VibeThinker-1.5B isn’t just a research milestone—it’s a strong candidate for practical enterprise use, deployment and learnings. It suggests that a new class of compact, reasoning-optimized models is viable for enterprise use cases that were previously the domain of far larger systems. For organizations trying to balance cost, latency, interpretability, and control, it’s a good new option to the long, growing list of Chinese open source offerings.</p>]]></description>
            <author>carl.franzen@venturebeat.com (Carl Franzen)</author>
            <category>AI</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/4s7atIbhZpkjUNIE9NqvrE/de645440ccc36273944e9ba58f78fea7/ChatGPT_Image_Nov_12__2025__02_29_18_PM.png?w=300&amp;q=30" length="0" type="image/png"/>
        </item>
        <item>
            <title><![CDATA[How Deductive AI saved DoorDash 1,000 engineering hours by automating software debugging]]></title>
            <link>https://venturebeat.com/ai/how-deductive-ai-saved-doordash-1-000-engineering-hours-by-automating</link>
            <guid isPermaLink="false">5eB6WWAPJjU76ZCvwit306</guid>
            <pubDate>Wed, 12 Nov 2025 14:00:00 GMT</pubDate>
            <description><![CDATA[<p>As software systems grow more complex and AI tools generate code faster than ever, a fundamental problem is getting worse: <a href="https://algocademy.com/blog/why-debugging-takes-longer-than-writing-the-actual-code/"><u>Engineers are drowning in debugging work</u></a>, spending up to half their time hunting down the causes of software failures instead of building new products. The challenge has become so acute that it&#x27;s creating a new category of tooling — AI agents that can diagnose production failures in minutes instead of hours.</p><p><a href="https://www.deductive.ai/"><u>Deductive AI</u></a>, a startup emerging from stealth mode Wednesday, believes it has found a solution by applying reinforcement learning — the same technology that powers game-playing AI systems — to the messy, high-stakes world of production software incidents. The company announced it has raised $7.5 million in seed funding led by <a href="https://www.crv.com/"><u>CRV</u></a>, with participation from <a href="https://www.databricks.com/databricks-ventures"><u>Databricks Ventures</u></a>, <a href="https://www.thomvest.com/"><u>Thomvest Ventures</u></a>, and <a href="https://www.primeset.com/"><u>PrimeSet</u></a>, to commercialize what it calls &quot;<a href="https://www.deductive.ai/product"><u>AI SRE agents</u></a>&quot; that can diagnose and help fix software failures at machine speed.</p><p>The pitch resonates with a growing frustration inside engineering organizations: Modern observability tools can show that something broke, but they rarely explain why. When a production system fails at 3 a.m., engineers still face hours of manual detective work, cross-referencing logs, metrics, deployment histories, and code changes across dozens of interconnected services to identify the root cause.</p><p>&quot;The complexities and inter-dependencies of modern infrastructure means that investigating the root cause of an outage or incident can feel like searching for a needle in a haystack, except the haystack is the size of a football field, it&#x27;s made of a million other needles, it&#x27;s constantly reshuffling itself, and is on fire — and every second you don&#x27;t find it equals lost revenue,&quot; said Sameer Agarwal, Deductive&#x27;s co-founder and chief technology officer, in an exclusive interview with VentureBeat.</p><p>Deductive&#x27;s system builds what the company calls a &quot;knowledge graph&quot; that maps relationships across codebases, telemetry data, engineering discussions, and internal documentation. When an incident occurs, multiple AI agents work together to form hypotheses, test them against live system evidence, and converge on a root cause — mimicking the investigative workflow of experienced site reliability engineers, but completing the process in minutes rather than hours.</p><p>The technology has already shown measurable impact at some of the world&#x27;s most demanding production environments. <a href="https://www.deductive.ai/blogs/how-doordash-powers-a-reliable-high-performance-ad-platform-with-deductive-ai"><u>DoorDash&#x27;s advertising platform</u></a>, which runs real-time auctions that must complete in under 100 milliseconds, has integrated Deductive into its incident response workflow. The company has set an ambitious 2026 goal of resolving production incidents within 10 minutes.</p><p>&quot;Our Ads Platform operates at a pace where manual, slow-moving investigations are no longer viable. Every minute of downtime directly affects company revenue,&quot; said Shahrooz Ansari, Senior Director of Engineering at DoorDash, in an interview with VentureBeat. &quot;Deductive has become a critical extension of our team, rapidly synthesizing signals across dozens of services and surfacing the insights that matter—within minutes.&quot;</p><p><a href="https://www.doordash.com/"><u>DoorDash</u></a> estimates that Deductive has root-caused approximately 100 production incidents over the past few months, translating to more than 1,000 hours of annual engineering productivity and a revenue impact &quot;in millions of dollars,&quot; according to Ansari. At location intelligence company <a href="https://foursquare.com/"><u>Foursquare</u></a>, Deductive reduced the time to diagnose Apache Spark job failures by 90% —t urning a process that previously took hours or days into one that completes in under 10 minutes — while generating over $275,000 in annual savings.</p><h2><b>Why AI-generated code is creating a debugging crisis</b></h2><p>The timing of Deductive&#x27;s launch reflects a brewing tension in software development: AI coding assistants are enabling engineers to generate code faster than ever, but the resulting software is often harder to understand and maintain.</p><p>&quot;<a href="https://x.com/karpathy/status/1886192184808149383?lang=en"><u>Vibe coding</u></a>,&quot; a term popularized by AI researcher <a href="https://karpathy.ai/"><u>Andrej Karpathy</u></a>, refers to using natural-language prompts to generate code through AI assistants. While these tools accelerate development, they can introduce what Agarwal describes as &quot;redundancies, breaks in architectural boundaries, assumptions, or ignored design patterns&quot; that accumulate over time.</p><p>&quot;Most AI-generated code still introduces redundancies, breaks architectural boundaries, makes assumptions, or ignores established design patterns,&quot; Agarwal told Venturebeat. &quot;In many ways, we now need AI to help clean up the mess that AI itself is creating.&quot;</p><p>The claim that engineers spend roughly half their time on debugging isn&#x27;t hyperbole. The Association for Computing Machinery reports that developers spend <a href="https://queue.acm.org/detail.cfm?id=3404974"><u>35% to 50% of their time validating and debugging software</u></a>. More recently, <a href="https://www.harness.io/blog/announcing-harness-ai"><u>Harness&#x27;s State of Software Delivery 2025</u></a> report found that 67% of developers are spending more time debugging AI-generated code.</p><p>&quot;We&#x27;ve seen world-class engineers spending half of their time debugging instead of building,&quot; said Rakesh Kothari, Deductive&#x27;s co-founder and CEO. &quot;And as vibe coding generates new code at a rate we&#x27;ve never seen, this problem is only going to get worse.&quot;</p><h2><b>How Deductive&#x27;s AI agents actually investigate production failures</b></h2><p>Deductive&#x27;s technical approach differs substantially from the AI features being added to existing observability platforms like <a href="https://www.datadoghq.com/"><u>Datadog</u></a> or <a href="https://newrelic.com/"><u>New Relic</u></a>. Most of those systems use large language models to summarize data or identify correlations, but they lack what Agarwal calls &quot;code-aware reasoning&quot;—the ability to understand not just that something broke, but why the code behaves the way it does.</p><p>&quot;Most enterprises use multiple observability tools across different teams and services, so no vendor has a single holistic view of how their systems behave, fail, and recover—nor are they able to pair that with an understanding of the code that defines system behavior,&quot; Agarwal explained. &quot;These are key ingredients to resolving software incidents and it is exactly the gap Deductive fills.&quot;</p><p>The system connects to existing infrastructure using read-only API access to observability platforms, code repositories, incident management tools, and chat systems. It then continuously builds and updates its knowledge graph, mapping dependencies between services and tracking deployment histories.</p><p>When an alert fires, Deductive launches what the company describes as a multi-agent investigation. Different agents specialize in different aspects of the problem: one might analyze recent code changes, another examines trace data, while a third correlates the timing of the incident with recent deployments. The agents share findings and iteratively refine their hypotheses.</p><p>The critical difference from rule-based automation is Deductive&#x27;s use of reinforcement learning. The system learns from every incident which investigative steps led to correct diagnoses and which were dead ends. When engineers provide feedback, the system incorporates that signal into its learning model.</p><p>&quot;Each time it observes an investigation, it learns which steps, data sources, and decisions led to the right outcome,&quot; Agarwal said. &quot;It learns how to think through problems, not just point them out.&quot;</p><p>At DoorDash, a recent latency spike in an API initially appeared to be an isolated service issue. Deductive&#x27;s investigation revealed that the root cause was actually timeout errors from a downstream machine learning platform undergoing a deployment. The system connected these dots by analyzing log volumes, traces, and deployment metadata across multiple services.</p><p>&quot;Without Deductive, our team would have had to manually correlate the latency spike across all logs, traces, and deployment histories,&quot; Ansari said. &quot;Deductive was able to explain not just what changed, but how and why it impacted production behavior.&quot;</p><h2><b>The company keeps humans in the loop—for now</b></h2><p>While Deductive&#x27;s technology could theoretically push fixes directly to production systems, the company has deliberately chosen to keep humans in the loop—at least for now.</p><p>&quot;While our system is capable of deeper automation and could push fixes to production, currently, we recommend precise fixes and mitigations that engineers can review, validate, and apply,&quot; Agarwal said. &quot;We believe maintaining a human in the loop is essential for trust, transparency and operational safety.&quot;</p><p>However, he acknowledged that &quot;over time, we do think that deeper automation will come and how humans operate in the loop will evolve.&quot;</p><h2><b>Databricks and ThoughtSpot veterans bet on reasoning over observability</b></h2><p>The founding team brings deep expertise from building some of Silicon Valley&#x27;s most successful data infrastructure platforms. Agarwal earned his Ph.D. at UC Berkeley, where he created <a href="https://arxiv.org/abs/1203.5485"><u>BlinkDB</u></a>, an influential system for approximate query processing. He was among the first engineers at <a href="https://www.databricks.com/"><u>Databricks</u></a>, where he helped build <a href="https://docs.databricks.com/gcp/en/spark/?scid=701Vp000004h4b1IAA&amp;utm_medium=paid+search&amp;utm_source=google&amp;utm_campaign=23156677199&amp;utm_adgroup=189768475320&amp;utm_content=aimax&amp;utm_offer=aimax&amp;utm_ad=779965794184&amp;utm_term=apache%20iceberg%20spark&amp;gad_source=1&amp;gad_campaignid=23156677199&amp;gbraid=0AAAAABYBeAhSzbWjXCf1Ok8HU2XzyuNAb&amp;gclid=CjwKCAiA_dDIBhB6EiwAvzc1cN1MnT40-rmesA_-YwBm870Sksy-DQYqWaR9mqQLAIQjzo7yRJpIfBoC7GsQAvD_BwE"><u>Apache Spark</u></a>. Kothari was an early engineer at <a href="https://www.thoughtspot.com/"><u>ThoughtSpot</u></a>, where he led teams focused on distributed query processing and large-scale system optimization.</p><p>The investor syndicate reflects both the technical credibility and market opportunity. Beyond CRV&#x27;s <a href="https://www.crv.com/team/max-gazor"><u>Max Gazor</u></a>, the round included participation from <a href="https://sequoiacap.com/podcast/training-data-ion-stoica/"><u>Ion Stoica</u></a>, founder of Databricks and Anyscale; <a href="https://www.thoughtspot.com/author/ajeet-singh"><u>Ajeet Singh</u></a>, founder of Nutanix and ThoughtSpot; and <a href="http://bensigelman.org/"><u>Ben Sigelman</u></a>, founder of Lightstep.</p><p>Rather than competing with platforms like <a href="https://www.datadoghq.com/"><u>Datadog</u></a> or <a href="https://www.pagerduty.com/"><u>PagerDuty</u></a>, Deductive positions itself as a complementary layer that sits on top of existing tools. The pricing model reflects this: Instead of charging based on data volume, Deductive charges based on the number of incidents investigated, plus a base platform fee.</p><p>The company offers both cloud-hosted and self-hosted deployment options and emphasizes that it doesn&#x27;t store customer data on its servers or use it to train models for other customers — a critical assurance given the proprietary nature of both code and production system behavior.</p><p>With fresh capital and early customer traction at companies like <a href="https://www.doordash.com/"><u>DoorDash</u></a>, <a href="https://foursquare.com/"><u>Foursquare</u></a>, and <a href="https://kumo.ai/"><u>Kumo AI</u></a>, Deductive plans to expand its team and deepen the system&#x27;s reasoning capabilities from reactive incident analysis to proactive prevention. The near-term vision: helping teams predict problems before they occur.</p><p>DoorDash&#x27;s Ansari offers a pragmatic endorsement of where the technology stands today: &quot;Investigations that were previously manual and time-consuming are now automated, allowing engineers to shift their energy toward prevention, business impact, and innovation.&quot;</p><p>In an industry where every second of downtime translates to lost revenue, that shift from firefighting to building increasingly looks less like a luxury and more like table stakes.</p><p>
</p>]]></description>
            <author>michael.nunez@venturebeat.com (Michael Nuñez)</author>
            <category>AI</category>
            <category>Automation</category>
            <category>Data Infrastructure</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/7mfhEiM01EDWrgDZYpDbte/23713914379b94e43303f9965ccc40ae/nuneybits_Vector_art_of_robot_holding_blueprint_193c9fc5-bbb5-46ea-9ff6-1a08bb03716e.webp?w=300&amp;q=30" length="0" type="image/webp"/>
        </item>
        <item>
            <title><![CDATA[OpenAI reboots ChatGPT experience with GPT-5.1 after mixed reviews of GPT-5]]></title>
            <link>https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5</link>
            <guid isPermaLink="false">68cB0FLnP4Ba9G7ByvSs4J</guid>
            <pubDate>Wed, 12 Nov 2025 05:00:00 GMT</pubDate>
            <description><![CDATA[<p>ChatGPT is about to become faster and more conversational as <a href="https://openai.com/"><u>OpenAI</u></a> upgrades its <a href="https://venturebeat.com/ai/openai-launches-gpt-5-not-agi-but-capable-of-generating-software-on-demand"><u>flagship model GPT-5</u></a> to GPT-5.1.</p><p>OpenAI <a href="https://openai.com/index/gpt-5-1"><u>announced</u></a> two updates to the GPT-5 series: GPT-5.1 Instant and GPT-5.1 Thinking. Both models are now accessible on ChatGPT. </p><p>GPT-5.1 Instant, essentially the default and most-used model, is now “warmer, more intelligent, and better at following your instructions,” according to OpenAI. Meanwhile, GPT-5.1 Thinking is an advanced reasoning model that responds faster for simple tasks and more persistently on complex ones.</p><p>“We heard clearly from users that great AI should not only be smart, but also enjoyable to talk to,” OpenAI said in a <a href="https://openai.com/index/gpt-5-1/">blog post</a>. “GPT-5.1 improves meaningfully on both intelligence and communication style.” </p><p>The company added that both models offer a way for users to “shape ChatGPT’s tone,” allowing people to control how the chat platform responds depending on the conversation they are having. </p><p>Both models were rolled out to ChatGPT Pro, Plus, Go and Business users, as well as the free tier. Those on the Enterprise and Edu plans will get a seven-day early-access toggle for the models before GPT-5.1 becomes the default model. OpenAI said the models can also be accessible through the API, both with adapted reasoning. </p><p>OpenAI has noted that it will soon update GPT-5 Pro to version 5.1. </p><h2>Instant and Thinking models </h2><p>T<!-- -->he 5.1 tag reflects improvements to the base model, and OpenAI considers these part of the GPT-5 family, trained on the same stack and data as its reasoning models. The biggest difference between 5.1 and 5 is its more natural and conversational tone, OpenAI CEO for Applications Fidji Simo said in a Substack <a href="https://fidjisimo.substack.com/p/moving-beyond-one-size-fits-all"><u>post</u></a>. </p><p>“Based on early testing, it often surprises people with its playfulness while remaining clear and useful,” OpenAI said in its post. </p><p>Instant can use adaptive reasoning to help it decide when it needs to think about its answers, especially when it comes to more complicated questions. OpenAI noted that it has improved the model&#x27;s instruction following, so that while it continues to respond quickly, it also directly addresses the user’s query. </p><p>Recent model releases, such as <a href="https://www.baidu.com/"><u>Baidu</u></a>’s ERNIE-4.5-VL-28B-A3B-Thinking, have <a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5"><u>been outperforming GPT-5</u></a> in benchmarks like instruction-following. </p><p>GPT-5.1 Thinking can figure out on its own how much reasoning power it should devote to a prompt. It adapts to the type and complexity of a query, so it will take longer to answer a fuller, complex question than a simple summary request. </p><p>OpenAI said evaluations showed that GPT-5.1 Thinking spends less time and therefore uses fewer tokens on simple tasks compared to GPT-5, outperforming the base model in speed of response. </p><p>One thing enterprises should note is that GPT-5.1 Thinking answers “with less jargon and fewer undefined terms.” OpenAI said removing jargony responses makes Thinking more approachable when it comes to explaining technical concepts.</p><h2>More personalization</h2><p>Another big update to ChatGPT is increased personalization. This allows users to toggle between a friendly and authoritative chat platform experience in their conversations. </p><p>ChatGPT already allows users to choose preset options for model tone, but the new update expands these options “to better reflect the most common ways people use ChatGPT.”</p><p>O<!-- -->ptions include &quot;default,&quot; &quot;friendly&quot; (formerly &quot;listener&quot;), &quot;efficient&quot; (previously &quot;robot&quot;), &quot;professional,&quot; &quot;candid&quot; and &quot;quirky.&quot; Two other personalities, &quot;cynical&quot; and &quot;nerdy,&quot; remain unchanged. </p><p>“We think many people will find that GPT-5.1 does a better job of bringing IQ and EQ together, but one default clearly can’t meet everyone’s needs,&quot; Simo said. &quot;That’s why we’re also making it easier to customize ChatGPT with a range of presets to choose from. The model has the same capabilities whether you select default or one of these options, but the style of its responses will differ — more formal or familiar, more playful or direct, more or less jargon or slang. Of course, eight personalities still don&#x27;t cover the full range of human diversity, but we know from our research that many people prefer simple, guided control over too many settings or open-ended options.&quot;</p><p>People can also adjust how much ChatGPT uses emojis. OpenAI offers granular controls for responses and is experimenting with the ability to make the models more concise, warm or scannable.</p><h2>Saving a rollout</h2><p>OpenAI’s GPT-5 rollout was…<a href="https://venturebeat.com/ai/openai-is-editing-its-gpt-5-rollout-on-the-fly-heres-whats-changing-in-chatgpt"><u>less than perfect</u></a>. While company executives, including CEO Sam Altman, touted the new model’s capabilities, a decision to initially sunset older and beloved models on ChatGPT was met with dissatisfaction. Worse yet, many early adopters found that GPT-5 didn’t perform better than older options in domains such as math, science and writing. </p><p>This led Altman to walk back some of his statements around model removal, blaming performance issues on GPT-5’s router. The router, which automatically directs queries to the most suited models, is not going away, as GPT-5.1 Auto will route prompts to the model type that can best answer queries.  </p><p>OpenAI is careful to note that GPT-5 models Instant, Thinking and Pro are still available in ChatGPT’s model dropdown, although paid subscribers only have three months to compare these older versions with the 5.1 update. The sunset period for GPT-5, however, will not impact models like GPT-4o.</p><p>“Going forward, when we introduce new ChatGPT models, our approach is to give people ample space to evaluate what’s changed and share feedback, allowing us to continue innovating our frontier models while transitioning smoothly,” the company said. “Sunset periods will be communicated clearly and with plenty of advance notice.”</p>]]></description>
            <category>AI</category>
            <enclosure url="https://images.ctfassets.net/jdtwqhzvc2n1/3CpLfvpU0TfycKYEA3DBLw/f7dc8b8d4db1e3eef3d0b619d662879e/crimedy7_illustration_of_a_conversation_abstract_--ar_169_--v_5a880096-9873-4985-85ae-e8c247d831fc_0.png?w=300&amp;q=30" length="0" type="image/png"/>
        </item>
    </channel>
</rss>