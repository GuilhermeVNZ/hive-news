<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[LangChain Blog]]></title><description><![CDATA[LangChain Blog]]></description><link>https://blog.langchain.com/</link><image><url>https://blog.langchain.com/favicon.png</url><title>LangChain Blog</title><link>https://blog.langchain.com/</link></image><generator>Ghost 6.7</generator><lastBuildDate>Thu, 13 Nov 2025 18:57:26 GMT</lastBuildDate><atom:link href="https://blog.langchain.com/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Execute Code with Sandboxes for DeepAgents]]></title><description><![CDATA[<p>By Vivek Trivedy</p><p>Today we&apos;re excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: <a href="https://www.runloop.ai/?ref=blog.langchain.com">Runloop</a>, <a href="https://www.daytona.io/?ref=blog.langchain.com">Daytona</a>, and <a href="https://modal.com/?ref=blog.langchain.com">Modal</a>. Below, we dive into what you can</p>]]></description><link>https://blog.langchain.com/execute-code-with-sandboxes-for-deepagents/</link><guid isPermaLink="false">6915620a8126f100018f8181</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Thu, 13 Nov 2025 16:22:20 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/11/Blog-Header_02.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/11/Blog-Header_02.png" alt="Execute Code with Sandboxes for DeepAgents"><p>By Vivek Trivedy</p><p>Today we&apos;re excited to launch Sandboxes for DeepAgents, a new set of integrations that allow you to safely execute arbitrary DeepAgent code in remote sandboxes. We currently support sandboxes from 3 of our partners: <a href="https://www.runloop.ai/?ref=blog.langchain.com">Runloop</a>, <a href="https://www.daytona.io/?ref=blog.langchain.com">Daytona</a>, and <a href="https://modal.com/?ref=blog.langchain.com">Modal</a>. Below, we dive into what you can do with sandboxes and how to use them with with the DeepAgents-CLI.</p><h2 id="why-do-we-need-sandboxes">Why Do We Need Sandboxes?</h2><p>Sandboxes give us a simple, configurable environment to execute code and do work outside of our local machine. Here are some scenarios where this may be useful:</p><ol><li><strong>Safety</strong>: Your agent is executing arbitrary code which could be harmful to your local machine (ex: <code>rm -rf</code>). Running in a sandbox means your machine is safe from potentially malicious code.</li><li><strong>Clean Environments</strong>: You need specific dependencies, languages, or OS configurations without polluting your local setup. Spin up a sandbox with exactly what you need, use it, then terminate it.</li><li><strong>Parallel Execution</strong>: Run multiple agents simultaneously, each in their own isolated environment, without resource conflicts or interference.</li><li><strong>Long-Running Tasks</strong>: Let agents work on time-intensive operations without blocking your local machine.</li><li><strong>Reproducibility</strong>: Guarantee consistent execution environments across your team.</li></ol><h2 id="how-it-works">How It Works</h2><p>The sandbox integration has three main steps:</p><ol><li>Setup the sandbox (with an optional setup script)</li><li>The agent wants to execute a command</li><li>The remote sandbox runs the command and sends it back to the user</li></ol><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.langchain.com/content/images/2025/11/deepagents-sandbox.png" class="kg-image" alt="Execute Code with Sandboxes for DeepAgents" loading="lazy" width="1820" height="701" srcset="https://blog.langchain.com/content/images/size/w600/2025/11/deepagents-sandbox.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/11/deepagents-sandbox.png 1000w, https://blog.langchain.com/content/images/size/w1600/2025/11/deepagents-sandbox.png 1600w, https://blog.langchain.com/content/images/2025/11/deepagents-sandbox.png 1820w" sizes="(min-width: 720px) 720px"><figcaption><i><em class="italic" style="white-space: pre-wrap;">Easily attach, configure, and use sandboxes with DeepAgents to safely execute code</em></i></figcaption></figure><p>Your DeepAgent runs locally (or wherever you want), but when it needs to execute code, create files, or run commands, those operations happen in the remote sandbox. The agent maintains full visibility into the sandbox filesystem and command outputs, so it can iterate naturally. The setup script can be used to load in environment variables, clone git repos, prepare your environment, and more.</p><h2 id="how-to-get-started">How to Get Started</h2><p>To use Daytona and Runloop sandboxes, simply create an account and store the API key as an environment variable (<code>DAYTONA_API_KEY</code> and <code>RUNLOOP_API_KEY</code>). To use Modal sandboxes, follow the setup instructions found <a href="https://modal.com/docs/guide?ref=blog.langchain.com#getting-started">here</a> and run <code>modal setup</code>.</p><p>After completing the setup, the DeepAgents CLI provides simple commands to get started with sandboxes in minutes with convenient <code>sandbox</code> and <code>sandbox-setup</code> commands.</p><p><strong>Note:</strong> we have context managers to automatically clean up sandboxes but we recommend checking your provider dashboard to be sure there&#x2019;s no agent or sandbox that&#x2019;s accidentally left running.</p><p>For example, the following command can be used to attach a runloop sandbox to your DeepAgent with a custom setup script located in your current directory: <code>uvx deepagents-cli --sandbox runloop --sandbox-setup ./setup.sh</code></p><h3 id="note-using-sandboxes-securely">Note: Using Sandboxes Securely</h3><blockquote>While the sandbox is isolated, when working with untrusted inputs, agents are still prone to prompt injection. To mitigate the risks of having secrets present in the sandbox, we recommend running trusted setup scripts, using human-in-the-loop, and assigning short lived secrets. Sandbox APIs are evolving rapidly, and we expect more providers to support proxies that help mitigate prompt injection and secrets management concerns.</blockquote><p>Here&apos;s an example of a simple setup script that adds local environment variables like a GitHub token or OpenAI key into the sandbox, and pulls down a repository. The pre-requisites to run this script is that your local <code>.env</code> file contains the keys and tokens you need:</p><pre><code class="language-bash">#!/bin/bash
set -e  # Exit on any error

echo &quot;Configuring sandbox environment...&quot;

# 1. Clone your repository using GitHub token
echo &quot;Cloning repository...&quot;
git clone &lt;https://x-access-token:${GITHUB_TOKEN}@github.com/username/repo.git&gt; $$HOME/workspace
cd $$HOME/workspace
echo &quot;&#x2713; Repository cloned&quot;

# 2. Make environment variables persistent for all future commands
echo &quot;Setting up environment variables...&quot;
cat &gt;&gt; ~/.bashrc &lt;&lt;&apos;EOF&apos;

# Add selected env variables to sandbox from local
export GITHUB_TOKEN=&quot;${GITHUB_TOKEN}&quot;
export FAL_API_KEY=&quot;${FAL_API_KEY}&quot;

# Auto-navigate to workspace
cd $$HOME/workspace
EOF

# 3. Activate the environment
source ~/.bashrc
echo &quot;&#x2713; Environment configured&quot;
</code></pre><h2 id="whats-next">What&apos;s Next?</h2><p>We&apos;re excited to see how builders will use sandboxes with their DeepAgents. We&apos;ll be adding more configuration options for sandboxes and sharing more examples on integrating sandboxes to do real work.</p><p>If you want to watch a tutorial on how to get started with sandboxes, get check our tutorial <a href="https://youtu.be/CejntUP3muU?ref=blog.langchain.com">here</a>.</p><p>Ready to start building? Get started with our <a href="https://github.com/langchain-ai/deepagents?ref=blog.langchain.com">DeepAgents</a> documentation and <a href="https://github.com/langchain-ai/deepagents?ref=blog.langchain.com">GitHub</a> repository today.</p>]]></content:encoded></item><item><title><![CDATA[Join LangChain at AWS re:Invent 2025]]></title><description><![CDATA[<p>If you&apos;re attending AWS re:Invent in Las Vegas this year and working on agent development, here&apos;s what we have planned:</p><h2 id="visit-us-at-booth-524">Visit Us at Booth #524</h2><p>We&apos;ll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our</p>]]></description><link>https://blog.langchain.com/join-langchain-at-aws-re-invent-2025/</link><guid isPermaLink="false">690e3ac957869f00017b9d96</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Tue, 11 Nov 2025 00:58:44 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/11/AWS-Reinvent-blog-post.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/11/AWS-Reinvent-blog-post.png" alt="Join LangChain at AWS re:Invent 2025"><p>If you&apos;re attending AWS re:Invent in Las Vegas this year and working on agent development, here&apos;s what we have planned:</p><h2 id="visit-us-at-booth-524">Visit Us at Booth #524</h2><p>We&apos;ll be at Booth #524 in the Venetian Expo Center, next to the Industry Pavilion, December 1-4. Our engineering team will be running demos throughout the week and available for technical conversations.</p><h3 id="see-whats-new"><strong>See What&apos;s New</strong></h3><p>We&apos;ll be showing our latest features, such as Insights Agent and Multi-turn Evaluations. Come by and learn how you can run LangSmith on your AWS infrastructure. If you&apos;re hitting challenges with production agents or trying to figure out evaluation strategies, this is a good place to get technical feedback.</p><h3 id="meet-harrison">Meet Harrison</h3><p>Harrison will be at the booth on December 3rd from 12:00-1:00pm PT. This is a chance to ask questions about roadmap decisions, share what&apos;s working (or not working) in your implementations, and hear what we&apos;re learning from teams who have agents in production. Space is limited, so if you want to attend, add it to your calendar.</p><p>If you aren&apos;t able to make it, our engineering team will be at the booth throughout the conference for technical discussions and demos.</p><h2 id="events-throughout-the-week"><strong>Events Throughout the Week</strong></h2><p>We&apos;re participating in a few technical sessions during the week:</p><h3 id="langchain-x-opensearch-event">LangChain x OpenSearch Event</h3><p><em>December 1st | 5:30-8:30pm PT | Encore Hotel</em></p><p>Our engineering team will cover context engineering patterns we&apos;ve seen work well with LangGraph and OpenSearch. There will be live demos, a panel discussion, and time to connect with other developers. This event is open to all attendees. <a href="https://pulse.aws/application/RYGWW6LK?p=0&amp;ref=blog.langchain.com"><u>Register now</u></a>.</p><h3 id="redis-partner-lightning-session">Redis Partner Lightning Session</h3><p><em>December 3rd at 2pm | Redis Booth, Expo Floor - Booth #1520</em></p><p>Our engineering team will present a 10-minute lightning talk on building scalable AI architectures with LangChain and Redis.</p><h2 id="self-host-langsmith-on-aws">Self-Host LangSmith on AWS</h2><p>LangSmith is now available on AWS Marketplace. You can host LangSmith on your own AWS infrastructure and bill against your AWS commit. If you&apos;re exploring self-hosted options, we&apos;ll have live demos at Booth #524. Check out LangSmith on<u> </u><a href="https://aws.amazon.com/marketplace/pp/prodview-vmzygmggk4gms?ref=blog.langchain.com"><u>AWS Marketplace</u></a>.</p><h2 id="lets-connect">Let&apos;s Connect</h2><p>If you want to dig into specific challenges you&apos;re facing&#x2014;whether that&apos;s evaluation strategies, deployment patterns, or scaling multi-agent systems&#x2014;our team is available to meet during re:Invent. Request a meeting and let us know what you&apos;d like to discuss.</p>
<!--kg-card-begin: html-->
<script src="https://js-na2.hsforms.net/forms/embed/242623570.js" defer></script>
<div class="hs-form-frame" data-region="na2" data-form-id="d91da27c-ee56-4a79-b977-c9efe2224f3a" data-portal-id="242623570"></div>

<!--kg-card-end: html-->
<p>Can&apos;t make it to re:Invent? We&apos;re happy to connect afterward.</p><h2 id="see-you-in-vegas">See You in Vegas</h2><p>Whether you&apos;re evaluating tools, debugging production issues, or exploring new patterns&#x2014; stop by. We&apos;ll have our engineering team available for technical conversations about what you&apos;re building.</p><p><strong>Booth #524 | December 1-5, 2025 | Venetian Expo Center</strong></p>]]></content:encoded></item><item><title><![CDATA[Why We Rebuilt LangChainâ€™s Chatbot and What We Learned]]></title><description><![CDATA[<p><em>By Liam Bush</em></p><h2 id="background">Background</h2><p>Every successful platform needs reliable support, but we realized our own team was spending hours tracking down answers to technical questions. This friction wasn&apos;t just slowing down our engineers&#x2014;it was a critical <strong>bottleneck</strong> for our users.</p><p>We set out to solve this</p>]]></description><link>https://blog.langchain.com/rebuilding-chat-langchain/</link><guid isPermaLink="false">690adc85eab788000153a26b</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Wed, 05 Nov 2025 16:28:53 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/11/Rebuilding-Chat-LangChain.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/11/Rebuilding-Chat-LangChain.png" alt="Why We Rebuilt LangChain&#x2019;s Chatbot and What We Learned"><p><em>By Liam Bush</em></p><h2 id="background">Background</h2><p>Every successful platform needs reliable support, but we realized our own team was spending hours tracking down answers to technical questions. This friction wasn&apos;t just slowing down our engineers&#x2014;it was a critical <strong>bottleneck</strong> for our users.</p><p>We set out to solve this using the very tools we champion: <strong>LangChain, LangGraph</strong> and <strong>LangSmith</strong>. We originally built <a href="http://chat.langchain.com/?ref=blog.langchain.com"><strong>chat.langchain.com</strong></a> as a prototype, explicitly designed to serve two functions:</p><ol><li><strong>Product Q&amp;A:</strong> Help users&#x2014;and our own team&#x2014;get instant, authoritative answers to product questions.</li><li><strong>Customer Prototype:</strong> Serve as a living example demonstrating how customers could build sophisticated, reliable agents using the LangChain stack.</li></ol><p>We had a strong intent and a functional product. But we have a confession: our support engineers weren&apos;t actively using the LangChain Chatbot. That&apos;s where our real learning began. This is the story of <strong>how we fixed our own agent</strong>&#x2014;and what we learned about building truly reliable, production-grade applications that our customers can adapt and use.</p><p>Our team was not actively using Chat LangChain not because it was broken and not because they didn&apos;t believe in it. But because when someone asked <em>&quot;Why isn&apos;t streaming working in production?&quot;</em> they needed something more thorough than just using docs as it&#x2019;s only resource. We all know there&#x2019;s never enough documentation.</p><p>So they built their own workflow:</p><ul><li><strong>Step 1:</strong> Search our docs (<a href="http://docs.langchain.com/?ref=blog.langchain.com">docs.langchain.com</a>) to understand what the feature is supposed to do.</li><li><strong>Step 2:</strong> Check our knowledge base (<a href="http://support.langchain.com/?ref=blog.langchain.com">support.langchain.com</a>) to see if other users hit the same issue and how it was resolved.</li><li><strong>Step 3:</strong> Open <code>Claude Code</code>, search the actual implementation, and verify what the code actually does.</li></ul><p><strong>Docs for the official story. Knowledge base for real-world issues. Codebase for ground truth.</strong></p><hr><h2 id="we-decided-to-automate-it">We Decided to Automate It</h2><p>This three-step ritual worked incredibly well. We watched them do it dozens of times a day and thought: <em>what if we just automated this exact workflow?</em></p><p>So we built an internal <a href="https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com"><code>Deep Agent</code></a> (a library for building agents that can tackle complex, multi-step tasks) with three specialized subagents &#x2014; one for docs, one for knowledge base, one for codebase search &#x2014; each one asking follow-up questions and filtering results before passing insights to a main orchestrator agent.</p><p>The main agent would synthesize everything and deliver answers like this:</p><blockquote>Example output:<br><br><em>&quot;To stream from subgraphs, set subgraphs: true in your stream config according to the </em><a href="https://docs.langchain.com/oss/python/langgraph/use-subgraphs?ref=blog.langchain.com#stream-subgraph-outputs"><em>LangGraph streaming docs.</em></a><em> There&apos;s a support article titled [&apos;Why is token streaming not working after upgrade](</em><a href="https://support.langchain.com/articles/7150806184-Why-is-token-by-token-streaming-not-working-after-upgrading-LangGraph?%29%5B%3F%5D%28https%3A%2F%2Fwww.notion.so%2F263808527b1780db9f26fa75aed5e7e3%3Fpvs=21%29&amp;ref=blog.langchain.com"><em>https://support.langchain.com/articles/7150806184-Why-is-token-by-token-streaming-not-working-after-upgrading-LangGraph?)[?](https://www.notion.so/263808527b1780db9f26fa75aed5e7e3?pvs=21)</em></a><em>&apos; that explains this exact issue &#x2014; you need to enable subgraph streaming to get token-level updates from nested agents. The implementation is in</em> <a href="https://github.com/langchain-ai/langgraph/blob/main/libs/langgraph/langgraph/pregel/main.py?ref=blog.langchain.com#L3273-L3279">pregel/main.py lines 3373-3279,</a> <em>where the subgraphs flag controls whether nested graph outputs are included in the stream.&quot;</em></blockquote><p>Our engineers loved it.</p><p>It saved them hours every week on complex debugging. They&apos;d describe a production issue and get back a comprehensive answer that cited documentation, referenced known solutions, and pointed to the exact lines of code that mattered.</p><hr><h2 id="then-we-had-a-realization">Then We Had a Realization</h2><p>Then someone asked the obvious question: <strong>if this works so well for us, why doesn&apos;t our public Chat LangChain work this way?</strong></p><p>It was a fair point. Our public tool was chunking documents into fragments, generating embeddings, storing them in a vector database. We had to reindex constantly as docs updated. Users got answers, but the citations needed love and the context was fragmented.</p><p>We&apos;d accidentally built something better internally just by copying what worked. It was time to bring that same approach to the public product.</p><p>When we started rebuilding, we quickly realized we needed to combine two different architectures driven by two broad categories of questions. Most questions could be answered using docs and knowledge base. The remainder would require analysis of foundation of code.</p><hr><h2 id="how-we-built-the-new-agent">How We Built The New Agent</h2><h3 id="for-simple-docs-create-agent">For Simple Docs: Create Agent</h3><p>We chose <a href="https://docs.langchain.com/oss/javascript/releases/langchain-v1?ref=blog.langchain.com#createagent"><code>createAgent</code></a> (Agent abstraction in <a href="https://docs.langchain.com/oss/javascript/langchain/overview?ref=blog.langchain.com"><code>langchain</code></a>) for <a href="https://chat.langchain.com/?ref=blog.langchain.com">chat.langchain.com</a> as the default mode because it&apos;s best for <strong>speed</strong>.</p><p>There&apos;s no planning phase, no orchestration overhead &#x2014; just immediate tool calls and answers. The agent searches the docs, checks the knowledge base if needed, refines its query if the results are unclear, and returns an answer. Most documentation questions can be handled with <strong>3-6 tool calls</strong>, and Create Agent executes those in seconds.</p><p><strong>Model options:</strong></p><p>We give end-users access to multiple models &#x2014; <code>Claude Haiku 4.5</code>, <code>GPT-4o Mini</code>, and <code>GPT-4o-nano</code> &#x2014; and we&apos;ve found that <strong>Haiku 4.5 is exceptionally fast at tool calling</strong> while maintaining strong accuracy. The combination of createAgent and Haiku 4.5 delivers <strong>sub-15-second responses</strong> for most queries, which is exactly what documentation Q&amp;A demands.</p><p><strong>How we optimized it:</strong></p><p>We used <a href="https://smith.langchain.com/?ref=blog.langchain.com"><code>LangSmith</code></a> to trace every conversation, identify where the agent was making unnecessary tool calls, and refine our prompts. The data showed us that most questions could be answered with 3-6 tool calls if we taught the agent to ask better follow-up questions. LangSmith&apos;s evaluation suite let us A/B test different prompting strategies and measure improvements in both speed and accuracy.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.langchain.com/content/images/2025/11/langsmith-jewel.png" class="kg-image" alt="Why We Rebuilt LangChain&#x2019;s Chatbot and What We Learned" loading="lazy" width="972" height="1088" srcset="https://blog.langchain.com/content/images/size/w600/2025/11/langsmith-jewel.png 600w, https://blog.langchain.com/content/images/2025/11/langsmith-jewel.png 972w" sizes="(min-width: 720px) 720px"><figcaption><i><em class="italic" style="white-space: pre-wrap;">This 30-second trace includes 7 tool calls: 4 doc searches, a knowledge-base article lookup, and 2 article reads, with 20 seconds devoted to streaming the final response. </em></i><a href="https://smith.langchain.com/public/c1059a52-d045-4013-a17f-3bdc07ef3f0d/r/67669d45-0065-47de-b0ee-0b4ca2687060?ref=blog.langchain.com"><i><em class="italic" style="white-space: pre-wrap;">View Here</em></i></a></figcaption></figure><h3 id="for-answering-using-code-deep-agent-with-subgraphs">For answering using code: Deep Agent with Subgraphs</h3><p>A lot of questions needed searching diving into our codebases to verify implementation details in addition to leveraging documentation, knowledge bases and cross-referencing known issues as resources.</p><p><strong>The architecture:</strong></p><p>For these tasks, we built a <code>Deep Agent</code> with <strong>specialized subgraphs</strong>: one for <strong>documentation search</strong>, one for <strong>knowledge base search</strong>, and one for <strong>codebase search</strong>.</p><p>Each subagent operates independently, asking follow-up questions, filtering through information, and extracting only the most relevant insights before passing them up to a main orchestrator agent. This prevents the main agent from drowning in context while allowing each domain expert to dig as deep as necessary.</p><p><strong>The codebase search advantage:</strong></p><p>The codebase search subagent is particularly powerful. It can search our private repositories using pattern matching, navigate file structures to understand context, and read specific implementations with line-number precision.</p><p><strong>The tradeoff:</strong></p><p>This deep agent architecture takes longer to run &#x2014; sometimes <strong>1-3 minutes</strong> for complex queries &#x2014; but the thoroughness is worth it. We leverage DeepAgent when the initial response is not addressing the core question.</p><p>Disclaimer: This mode is only enabled for a subset of users at launch and will be made generally available in a few days.</p><hr><h2 id="why-we-got-moved-away-from-vector-embeddings">Why We Got Moved Away from Vector Embeddings</h2><p>The standard approach to documentation search &#x2014; chunk docs into pieces, generate embeddings, store in a vector database, retrieve by similarity &#x2014; works fine for unstructured content like PDFs. But for structured product documentation, we kept hitting three problems.</p><p><strong>Chunking breaks structure.</strong> When you chop documentation into 500-token fragments, you lose headers, subsections, and context. The agent would cite <code>&quot;set streaming=True&quot;</code> without explaining why or when. Users had to hunt through pages to find what they needed.</p><p><strong>Constant reindexing.</strong> Our docs update multiple times daily. Every change meant re-chunking, re-embedding, and re-uploading. It slowed us down.</p><p><strong>Vague citations.</strong> Users couldn&apos;t verify answers or trace where information came from.</p><p>The breakthrough was realizing we were solving the wrong problem. Documentation is already organized. Knowledge bases are already categorized. Codebases are already navigable. We didn&apos;t need smarter retrieval &#x2014; we needed to give the agent direct access to that existing structure.</p><hr><h2 id="the-better-approach-direct-api-access-and-smart-prompting">The Better Approach: Direct API Access and Smart Prompting</h2><p>Instead of chunking and embedding, we gave the agent direct access to the real thing. For documentation, we use <code>Mintlify&apos;s API</code>, which returns <strong>full pages</strong> with all their headers, subsections, and code examples intact. For the knowledge base, we query our support articles by title first, then read the most promising ones in full. For codebase search, <strong>we uploaded our codebase to our LangGraph Cloud deployment</strong> and use <code>ripgrep</code>for pattern matching, directory traversal to understand structure, and file reading to extract specific implementations.</p><p>The agent doesn&apos;t retrieve based on similarity scores. It <strong>searches like a human would</strong> &#x2014; with keywords, refinement, and follow-up questions.</p><p>This is where the magic happens. We don&apos;t just tell the agent to search once and return whatever it finds. We prompt it to <strong>think critically</strong> about whether it has enough information. If the results are ambiguous or incomplete, the agent refines its query and searches again. If documentation mentions a concept without explaining it, the agent searches for that concept specifically. If multiple interpretations are possible, the agent narrows down to the most relevant one.</p><hr><h2 id="tool-design-building-for-human-workflows">Tool Design: Building for Human Workflows</h2><p>We designed our tools to mirror how humans actually search, not how retrieval algorithms work.</p><h3 id="documentation-search-full-pages-not-fragments">Documentation Search: Full Pages, Not Fragments</h3><p>The documentation search tool queries <code>Mintlify&apos;s API</code> and returns <strong>complete pages</strong>. When someone asks about streaming, the agent doesn&apos;t get three disjointed paragraphs from different sections &#x2014; it gets the entire streaming documentation page, structured exactly as a human would read it.</p><pre><code class="language-python">@tool
def SearchDocsByLangChain(query: str, page_size: int = 5, language: Optional[str] = None) -&gt; str:
    &quot;&quot;&quot;Search LangChain documentation via Mintlify API&quot;&quot;&quot;
    params = {&quot;query&quot;: query, &quot;page_size&quot;: page_size}
    if language:
        params[&quot;language&quot;] = language
    response = requests.get(MINTLIFY_API_URL, params=params)
    return _format_search_results(response.json())

</code></pre><p>But we don&apos;t stop there. We prompt the agent to evaluate whether the initial results actually answer the question. <em>Is this the right section? Are there related concepts that need clarification? Would a more specific search term be better?</em></p><p>The agent has a budget of <strong>4-6 tool calls</strong>, and we encourage it to use them strategically to refine its understanding before responding.</p><p><strong>Here&apos;s what that looks like in practice:</strong></p><p>A user asks, <em>&quot;How do I add memory to my agent?&quot;</em></p><p>The agent searches for <code>&quot;memory&quot;</code> and gets results that cover checkpointing, conversation history, and the Store API. Instead of picking one at random, the agent realizes the question is ambiguous &#x2014; memory could mean persisting conversation state within a thread or storing facts across multiple conversations.</p><p>It searches again with <code>&quot;checkpointing&quot;</code> to narrow down thread-level persistence, fetches the support article <em>&quot;How do I configure checkpointing in LangGraph?&quot;</em> and recognizes it doesn&apos;t cover cross-thread memory.</p><p>So it searches for <code>&quot;store API&quot;</code> to fill the gap.</p><p>The final answer covers both checkpointing for conversation history and the Store API for long-term memory, with precise citations to the support article and documentation used.</p><hr><p>This iterative search process happens in seconds with Create Agent, but it fundamentally changes the quality of responses. The agent isn&apos;t just retrieving &#x2014; it&apos;s reasoning about what the user actually needs.</p><h3 id="knowledge-base-search-scan-then-read">Knowledge Base Search: Scan, Then Read</h3><p>We built the knowledge base (powered by Pylon) search as a <strong>two-step process</strong> because that&apos;s how humans use knowledge bases.</p><p>First, the agent retrieves article titles &#x2014; sometimes dozens of them &#x2014; and scans them to identify which ones seem relevant. Then it reads only those articles in full.</p><pre><code class="language-python">@tool
def search_support_articles(collections: str = &quot;all&quot;, limit: int = 50) -&gt; str:
    &quot;&quot;&quot;Step 1: Get article titles to scan&quot;&quot;&quot;
    articles = pylon_client.list_articles(collections=collections, limit=limit)
    return json.dumps([{
        &quot;id&quot;: a[&quot;id&quot;],
        &quot;title&quot;: a[&quot;title&quot;],
        &quot;url&quot;: a[&quot;url&quot;]
    } for a in articles])

@tool
def get_article_content(article_ids: List[str]) -&gt; str:
    &quot;&quot;&quot;Step 2: Read the most relevant articles&quot;&quot;&quot;
    articles = pylon_client.get_articles(article_ids)
    return &quot;\\n\\n---\\n\\n&quot;.join([
        f&quot;# {a[&apos;title&apos;]}\\n\\n{a[&apos;content&apos;]}\\n\\nSource: {a[&apos;url&apos;]}&quot;
        for a in articles
    ])

</code></pre><p><strong>Why this works:</strong></p><p>This prevents the agent from drowning in information. Instead of passing 30 full articles to the context window, the agent filters down to the 2-3 that actually matter, reads them thoroughly, and extracts the key insights.</p><p>The prompting reinforces this: <em>focus on quality over quantity, narrow your search if needed, and return only the information that directly answers the question.</em></p><hr><h3 id="codebase-search-search-navigate-verify">Codebase Search: Search, Navigate, Verify</h3><p>This is where our <code>Deep Agent</code> shines.</p><p>We gave the agent three tools that mirror the workflow from the opening &#x2014; the same pattern our engineers follow when using <code>Claude Code</code>:</p><pre><code class="language-python">@tool
def search_public_code(pattern: str, path: Optional[str] = None) -&gt; str:
    &quot;&quot;&quot;Step 1: Find code matching a pattern&quot;&quot;&quot;
    cmd = [&quot;rg&quot;, pattern, str(path or search_path)]
    return subprocess.run(cmd, capture_output=True, text=True).stdout

@tool
def list_public_directory(path: str, max_depth: int = 2) -&gt; str:
    &quot;&quot;&quot;Step 2: Understand the file structure&quot;&quot;&quot;
    cmd = [&quot;tree&quot;, &quot;-L&quot;, str(max_depth), str(path)]
    return subprocess.run(cmd, capture_output=True, text=True).stdout

@tool
def read_public_file(file_path: str, start_line: int = 1, num_lines: int = 100) -&gt; str:
    &quot;&quot;&quot;Step 3: Read the actual implementation&quot;&quot;&quot;
    with open(file_path, &quot;r&quot;) as f:
        lines = f.readlines()
    return &quot;\\n&quot;.join(lines[start_line-1:start_line-1+num_lines])

</code></pre><p><strong>How it works:</strong></p><p>First, it searches the codebase for a pattern using <code>ripgrep</code>. Then it lists the directory structure to understand how files are organized. Finally, it reads the specific file, focusing on the relevant section, and returns the implementation with line numbers.</p><p><strong>Real-world example:</strong></p><p>A user reports that streaming tokens hang in production. The docs subagent finds that streaming configuration involves buffer settings. The knowledge base subagent surfaces a support article about token streaming issues after upgrades.</p><p>But the codebase subagent is the one that finds the actual implementation &#x2014; it searches for <code>&quot;streaming buffer&quot;</code>, navigates to <code>callbacks/streaming.py</code>, and returns <strong>lines 47-83</strong> where the default buffer size is hardcoded.</p><p>That&apos;s the kind of deep investigation that solves real problems.</p><p><strong>The difference?</strong> The <code>Deep Agent</code> can work in parallel across all three domains, and summarize the interim findings into one coherent answer.</p><hr><h2 id="how-deep-agent-and-subgraphs-solve-context-overload">How Deep Agent and Subgraphs Solve Context Overload</h2><p>When we first built the deep agent as a single system with access to all three tools, it would return everything it found. The main agent would get five documentation pages, twelve knowledge base articles, and twenty code snippets &#x2014; all at once.</p><p>The context window would explode, and the final response would either be bloated with irrelevant details or miss the key insight entirely.</p><p>That&apos;s when we restructured it with specialized subgraphs.</p><p><strong>How it works:</strong></p><p>Each subagent operates independently. It searches its domain, asks follow-up questions to clarify ambiguity, filters through the results, and extracts only the <strong>golden data</strong>: the essential facts, citations, and context needed to answer the question.</p><p>The main orchestrator agent never sees the raw search results. It only receives the refined insights from each domain expert. Look at a full trace along with prompts **<a href="https://smith.langchain.com/public/c1059a52-d045-4013-a17f-3bdc07ef3f0d/r/67669d45-0065-47de-b0ee-0b4ca2687060?ref=blog.langchain.com">here</a>.</p><p><strong>Why this matters:</strong></p><p>The docs subagent might read five full pages but return only two key paragraphs. The knowledge base subagent might scan twenty article titles but return only three relevant summaries. The codebase subagent might search fifty files but return only the specific implementation with line numbers.</p><p>The main agent gets clean, curated information that it can synthesize into a comprehensive answer.</p><hr><h2 id="making-it-production-ready"><strong>Making It Production-Ready</strong></h2><p>Even elegant agent designs need production infrastructure to survive contact with real users. We built modular <a href="https://docs.langchain.com/oss/javascript/langchain/middleware?ref=blog.langchain.com#middleware">middleware</a> to handle the operational concerns that would otherwise clutter our prompts.</p><pre><code class="language-python">middleware = [
    guardrails_middleware,      # Filter off-topic queries
    model_retry_middleware,     # Retry on API failures
    model_fallback_middleware,  # Switch models if needed
    anthropic_cache_middleware  # Cache expensive calls
]

</code></pre><p><strong>What each layer does:</strong></p><p><strong>Guardrails</strong> filter out off-topic queries so the agent stays focused on LangChain questions.</p><p><strong>Retry middleware</strong> handles temporary API failures gracefully, so users never see cryptic error messages.</p><p><strong>Fallback middleware</strong> switches between Haiku, GPT-4o Mini, and Gemini Nano if a model is unavailable.</p><p><strong>Caching</strong> reduces costs by reusing results for identical queries.</p><p>These layers are invisible to users, but they&apos;re essential for reliability. They let the agent focus on reasoning while the infrastructure handles failure modes, cost optimization, and quality control.</p><hr><h2 id="getting-the-agent-to-users">Getting the Agent to Users</h2><p>Building a great agent is only half the battle. The other half? Getting it to users in a way that feels fast and intelligent.</p><p>We use the <strong>LangGraph SDK</strong> to handle all the complexity of streaming and state management.</p><h3 id="loading-user-threads"><strong>Loading User Threads:</strong></h3><p>When someone opens Chat LangChain, we fetch their conversation history using the LangGraph SDK:</p><pre><code class="language-tsx">const userThreads = await client.threads.search({
  metadata: { user_id: userId },
  limit: THREAD_FETCH_LIMIT,
})
</code></pre><p>Every thread stores the user&apos;s ID in metadata, so conversations stay private and persistent across sessions. The LangGraph SDK handles the filtering automatically.</p><h3 id="streaming-responses-in-real-time">S<strong>treaming Responses in Real Time:</strong></h3><p>When a user sends a message, the LangGraph SDK streams the response as it generates:</p><p>typescript</p><pre><code class="language-tsx">const streamResponse = client.runs.stream(threadId, &quot;docs_agent&quot;, {
  input: { messages: [{ role: &quot;user&quot;, content: userMessage }] },
  streamMode: [&quot;values&quot;, &quot;updates&quot;, &quot;messages&quot;],
  streamSubgraphs: true,
})

for await (const chunk of streamResponse) {
  if (chunk.event === &quot;messages/partial&quot;) {
    setMessages(prev =&gt; updateWithPartialContent(chunk.data.content))
  }
}
</code></pre><p><strong>What users see:</strong></p><p>Three stream modes show the agent&apos;s entire thought process:</p><ul><li><strong><code>messages</code></strong> &#x2014; Tokens appear progressively as the agent writes</li><li><strong><code>updates</code></strong> &#x2014; Tool calls reveal what the agent is searching</li><li><strong><code>values</code></strong> &#x2014; Final complete state after processing</li></ul><p>Users watch the agent think, search docs, check the knowledge base, and build the response token-by-token. No loading spinners.</p><h3 id="conversation-memory">Conversation Memory</h3><p>Pass the same <code>thread_id</code> across messages and LangGraph&apos;s checkpointer handles the rest. It stores conversation history, retrieves context for each turn, and maintains state across sessions. We set a 7-day TTL. That&apos;s it.</p><hr><h2 id="the-results">The Results</h2><p>Since launching the new systems, we&apos;ve seen dramatic improvements.</p><p>For public Chat LangChain, users get <strong>sub-15-second responses</strong> with precise citations. They can verify answers immediately because we link directly to the relevant documentation page or knowledge base article. And we no longer spend hours reindexing &#x2014; the documentation updates automatically.</p><p>Internally, our support engineers use the <code>Deep Agent</code> to handle the most complex tickets. It searches documentation, cross-references known issues, and dives into our private codebase to find the implementation details that actually explain what&apos;s happening. <strong>The agent doesn&apos;t replace our engineers &#x2014; it amplifies them</strong>, handling the research so they can focus on solving the problem.</p><hr><h2 id="key-takeaways">Key Takeaways</h2><ul><li><strong>Follow the user&apos;s workflow:</strong> Don&apos;t reinvent the wheel; automate the successful workflow your best users (or internal experts) already use. For LangChain, this meant replicating the three-step ritual of checking <strong>docs,</strong> the <strong>knowledge base,</strong> and the <strong>codebase</strong>.</li><li><strong>Evaluate if vector embeddings are appropriate:</strong> For structured content like product documentation and code, using vector embeddings could break the document structure, leads to vague citations, and requires constant reindexing. Vector embeddings are fantastic for unstructured content or shorter blocks or clustering use cases.</li><li><strong>Give the agent direct access to structure:</strong> This approach allows the agent direct API access to the content&apos;s existing structure. This allows the agent to search like a human, with keywords and refinement.</li><li><strong>Prioritize reasoning over retrieval:</strong> Design tools to mirror human workflows: scan article titles then read content, and use pattern matching and directory navigation for code. Prompt the agent to ask follow-up questions and refine its query if initial results are ambiguous, ensuring the final answer covers the user&apos;s real need.</li><li><strong>Use Deep Agents and subgraphs to manage context:</strong> For complex, multi-domain questions, using a <strong>Deep Agent</strong> with specialized <strong>subgraphs</strong> prevents the main orchestrator agent from drowning in raw search results. Each subagent filters and extracts only the &quot;golden data&quot; from its domain before passing the refined insights up.</li><li><strong>The need for production middleware:</strong> Even an elegant agent design needs robust infrastructure to be reliable. Implementing modular middleware for <strong>guardrails</strong> (filtering off-topic queries), <strong>retries</strong> (on API failures), <strong>fallbacks</strong> (switching models), and <strong>caching</strong> is essential for production-grade reliability, cost-optimization, and quality control.</li></ul><hr><h2 id="whats-next">What&apos;s Next</h2><p><strong>Public codebase search</strong> (launching in the next few days) &#x2014; When docs and knowledge base aren&apos;t sufficient, the agent will search our public repositories to verify implementations and cite exact line numbers</p><hr><h2 id="try-it-yourself">Try It Yourself</h2><p>Chat LangChain is live at <a href="https://chat.langchain.com/?ref=blog.langchain.com">chat.langchain.com</a>. Try it with <code>Claude Haiku 4.5</code> for the fastest responses, or experiment with <code>GPT-5 Mini</code> and <code>GPT-5 Nano</code> to see how different models perform.</p><hr><h2 id="join-the-conversation">Join the Conversation</h2><p>Building agents that balance speed and depth is hard, and we&apos;re still learning. If you&apos;re working on similar problems, we&apos;d love to hear what you&apos;re discovering.</p><p>Join the LangChain community on our <a href="https://forum.langchain.com/?ref=blog.langchain.com">forum</a> or follow us on <a href="https://twitter.com/LangChainAI?ref=blog.langchain.com">Twitter</a>.</p><p>Subscribe to our newsletter for updates from the team and community.</p>]]></content:encoded></item><item><title><![CDATA[Introducing DeepAgents CLI]]></title><description><![CDATA[<p><em>By </em><a href="https://www.linkedin.com/in/vivek-trivedy-433509134/?ref=blog.langchain.com"><em>Vivek Trivedy</em></a></p><p>We&apos;re excited to introduce <strong>DeepAgents CLI</strong> for coding, research, and building agents with persistent memory. Now you can easily create and run custom DeepAgents directly from the terminal. It supports:</p><ul><li><strong>Read, write, and edit files</strong> in your project</li><li><strong>Execute shell commands</strong> with human approval</li><li><strong>Search</strong></li></ul>]]></description><link>https://blog.langchain.com/introducing-deepagents-cli/</link><guid isPermaLink="false">69039825eab78800015398d9</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Thu, 30 Oct 2025 16:55:35 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Deep-Agents-CLI-blog.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Deep-Agents-CLI-blog.png" alt="Introducing DeepAgents CLI"><p><em>By </em><a href="https://www.linkedin.com/in/vivek-trivedy-433509134/?ref=blog.langchain.com"><em>Vivek Trivedy</em></a></p><p>We&apos;re excited to introduce <strong>DeepAgents CLI</strong> for coding, research, and building agents with persistent memory. Now you can easily create and run custom DeepAgents directly from the terminal. It supports:</p><ul><li><strong>Read, write, and edit files</strong> in your project</li><li><strong>Execute shell commands</strong> with human approval</li><li><strong>Search the web</strong> for current information</li><li><strong>Make HTTP requests</strong> to APIs</li><li><strong>Learn and remember</strong> information across sessions</li><li><strong>Plan tasks</strong> with visual todo lists</li></ul><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/IrnacLa9PJc?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Deep Agent CLI: Coding Assistant with Memory"></iframe></figure><h2 id="installation">Installation</h2><p>Install DeepAgents with CLI support:</p><pre><code class="language-bash">
pip install deepagents-cli

</code></pre><p>Or if you&apos;re using <code>uv</code>:</p><pre><code class="language-bash">
uv pip install deepagents-cli

</code></pre><h2 id="quick-start">Quick Start</h2><h3 id="1-set-up-your-api-keys">1. Set Up Your API Keys</h3><p>DeepAgents CLI supports both Anthropic (Claude) and OpenAI models. <strong>Anthropic Claude Sonnet 4 is the default</strong> model and Tavily is used for web search. Add these to your <code>.env</code> file in your project root, and DeepAgents will automatically load them:</p><pre><code class="language-bash">
export ANTHROPIC_API_KEY=your_api_key_here
export OPENAI_API_KEY=your_api_key_here
export TAVILY_API_KEY=your_tavily_key_here

</code></pre><h3 id="2-launch-the-cli">2. Launch the CLI</h3><p>Start DeepAgents in your project directory:</p><pre><code class="language-bash">
deepagents

</code></pre><p>Or, if you&#x2019;re using <code>uv</code>:</p><pre><code class="language-jsx">uv run deepagents
</code></pre><h3 id="3-your-first-task">3. Your First Task</h3><p>Try asking the agent to help with a simple task:</p><pre><code>
You: Add type hints to all functions in src/utils.py

</code></pre><p>The agent will:</p><ol><li>Read the file</li><li>Analyze the functions</li><li>Show you a diff of proposed changes</li><li>Ask for your approval before writing</li></ol><p>There&apos;s also an option to Auto-Accept Edits to speed up development</p><h2 id="learning-through-memory">Learning Through Memory</h2><p>One of DeepAgents&apos; most powerful features is its <strong>persistent memory system</strong>. The agent can learn information and recall it across sessions. Each agent stores its knowledge in <code>~/.deepagents/AGENT_NAME/memories/</code>:</p><p>By default, if you spin up DeepAgents it will create an agent with the name <code>agent</code> and use that by default. You can change the agent used (and therefor what memories are used) by specifying an agent name, eg <code>deepagents --agent foo</code>. See next section for more details.</p><p>The agent automatically follows a <strong>Memory-First Protocol</strong>:</p><ol><li><strong>During Research</strong> - Checks <code>/memories/</code> for relevant knowledge</li><li><strong>Before answering</strong> - Searches memory files in case of uncertainty</li><li><strong>When learning</strong> - Saves new information to <code>/memories/</code></li></ol><h3 id="example-teaching-api-patterns">Example: Teaching API Patterns</h3><pre><code>
You: Remember that our API endpoints follow this pattern:
- Use /api/v1/ prefix
- All POST requests return 201 on success
- Error responses include a &quot;code&quot; and &quot;message&quot; field

Save this as our API conventions.

Agent: I&apos;ll save these API conventions to memory.
&#x2699; write_file(/memories/api-conventions.md)

</code></pre><p>Because this memory is persistent, the agent can use this information across future conversations.</p><pre><code>You: Create a new endpoint for user registration
Agent: Based on our API conventions, I&apos;ll create an endpoint at
/api/v1/users that returns 201 on success and follows
our error format.
&#x2699; read_file(/memories/api-conventions.md)
&#x2699; write_file(src/routes/users.py)

</code></pre><h3 id="memory-best-practices">Memory Best Practices</h3><p><strong>1. Use descriptive filenames</strong> &#x2713; /memories/deployment-checklist.md &#x2717; /memories/notes.md</p><p><strong>2. Organize by topic</strong></p><pre><code>/memories/
&#x251C;&#x2500;&#x2500; backend/

&#x2502; &#x251C;&#x2500;&#x2500; tools_to_use.md

&#x2502; &#x2514;&#x2500;&#x2500; api-design.md

&#x251C;&#x2500;&#x2500; frontend/

&#x2502; &#x251C;&#x2500;&#x2500; component-patterns.md

&#x2514;&#x2500;&#x2500; security-setup.md

</code></pre><p><strong>3. Verify saved knowledge</strong> Because memory is just a set of files, you can always inspect and validate its content manually or with the agent.</p><pre><code>You: Check what you know about our database

Agent: Let me check my memories...
&#x2699; ls /memories/
&#x2699; read_file(/memories/backend/database-schema.md)

Based on my memory, we use PostgreSQL with these tables...

</code></pre><p>You can also inspect the memory files manually by just looking at <code>~/.deepagents/AGENT_NAME/memories/</code></p><h3 id="managing-multiple-agents">Managing Multiple Agents</h3><p>You can create specialized agents for different projects or roles: From the DeepAgents CLI you can list existing agents, create new agents, or reset an agent to its default state (system prompts, memories, etc).</p><pre><code class="language-bash">deepagents list

</code></pre><pre><code class="language-bash">deepagents agent backend-dev

</code></pre><pre><code class="language-bash">deepagents reset backend-dev

</code></pre><h2 id="get-started-today">Get Started Today</h2><p>Get started with DeepAgents and the DeepAgent CLI today! We&apos;re excited to see what you build.</p><p>Join the community and contribute:</p><ul><li><strong>GitHub</strong>: <a href="https://github.com/langchain-ai/deepagents?ref=blog.langchain.com">https://github.com/langchain-ai/deepagents</a></li><li><strong>Documentation</strong>: <a href="https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com">docs.langchain.com/oss/python/deepagents</a></li><li><strong>YouTube:</strong> <a href="https://youtu.be/IrnacLa9PJc?ref=blog.langchain.com">https://youtu.be/IrnacLa9PJc</a></li></ul>]]></content:encoded></item><item><title><![CDATA[Introducing LangSmithâ€™s No Code Agent Builder]]></title><description><![CDATA[<p><em>By Brace Sproul and Sam Crowder</em></p><p>Today, we&#x2019;re expanding who can build agents beyond developers. While a lot of the highest volume, customer-facing agents will be built by technical teams, nearly every business user has use cases for agentic applications in their daily routines. Our new <strong>LangSmith Agent</strong></p>]]></description><link>https://blog.langchain.com/langsmith-agent-builder/</link><guid isPermaLink="false">690164caeab7880001539265</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Wed, 29 Oct 2025 14:38:43 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Blog-04--1--1.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Blog-04--1--1.png" alt="Introducing LangSmith&#x2019;s No Code Agent Builder"><p><em>By Brace Sproul and Sam Crowder</em></p><p>Today, we&#x2019;re expanding who can build agents beyond developers. While a lot of the highest volume, customer-facing agents will be built by technical teams, nearly every business user has use cases for agentic applications in their daily routines. Our new <strong>LangSmith Agent Builder</strong> provides a no code agent-building experience &#x2014; complete with memory and guided prompt creation &#x2014; that lowers the barrier to building agents.</p><p>Sign up for <a href="http://langchain.com/langsmith-agent-builder-waitlist?ref=blog.langchain.com">the waitlist today</a>, and learn more about our approach below.</p><h2 id="what%E2%80%99s-different">What&#x2019;s different</h2><p>We&#x2019;ve spent the past three years building agents alongside millions of developers. We hear from engineering teams how much their colleagues want to build their own agents. Even technical users have asked for faster ways to get started with agents that doesn&apos;t always involve writing and deploying code.</p><p>That&#x2019;s why we&#x2019;re launching <strong>LangSmith</strong> <strong>Agent Builder</strong> in private preview. It empowers everyone in an organization to build agents in a safe and accessible way. Unlike other solutions out there, LangSmith Agent Builder is an agent builder, <a href="https://blog.langchain.com/not-another-workflow-builder/" rel="noreferrer">not a visual workflow builder</a>. Visual workflows builders have two major pitfalls:</p><ol><li><strong>A visual workflow builder is not &#x201C;low&#x201D; barrier to entry.</strong></li><li><strong>Complex tasks quickly get too complicated to manage in a visual builder.</strong></li></ol><p>Rather than follow a predetermined path, agents can delegate more decision-making to an LLM, allowing for more dynamic responses. By focusing on letting users build agents, we make agent building accessible to a broader audience while enabling users to tackle more complicated and complex tasks, rather than simple workflows.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/97iiCrHPOpw?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Get Started with LangSmith Agent Builder"></iframe></figure><h2 id="what-an-agent-consists-of">What an agent consists of</h2><p>Every agent in LangSmith is built from four core components that work together:</p><ul><li><strong>Prompt: </strong>This is the brain of your agent containing the logic to describe what the agent should do. With LangSmith agents, all the complexity of the agent is pushed into the prompt (rather than into a complex visual workflow). Writing good prompts is hard but really important, which is why we&apos;ve built tools to make it easier (learn more in the next section). </li><li><strong>Tools:</strong> In order to interact with the world, agents need to call tools. LangSmith uses MCP to connect your agent to external services and data. We provide built-in tools, but you can also easily bring your own MCP servers. With LangSmith&#x2019;s new Agent Authorization functionality, you can securely connect to tools your team has approved such as Gmail, Slack, LinkedIn, or Linear &#x2013; all within the agent building flow.</li><li><strong>Triggers: </strong>Agents don&apos;t just respond to chat messages &#x2013; they can also act automatically on background events. Set up triggers to launch your agent when you receive an email, get a Slack message in a particular channel, or on a time-based schedule.</li><li><strong>Subagents: </strong>We recommend starting out by putting most complexity in the prompt. But as complexity grows, you may want to keep the system manageable by creating smaller, more focused subagents for specific tasks.</li></ul><h2 id="how-we-make-it-easier-to-build-your-agent">How we make it easier to build your agent</h2><p>We&apos;ve consistently seen that the hardest part of building agents is <strong>writing effective prompts</strong>. Two challenges make this difficult: </p><ol><li>Good prompts require detail and specificity, but most people lack prompt engineering experience.</li><li>Prompts need to&#xA0;evolve or be updated as you discover edge cases and new requirements.</li></ol><p>We&apos;ve set out to make these things easier:</p><ul><li><strong>Start with a conversation</strong> <strong>instead of a blank canvas</strong>. First, start with your request and describe what you want your agent to do in plain language. The system then asks you follow up questions to get the details right, auto-generates your agent&apos;s system prompt, connects tools, and sets triggers based on your answers. This guided conversation makes it easy to create detailed, effective prompts without prompt engineering expertise.</li><li><strong>Have your agent remember over time.</strong> LangSmith agents have built-in memory for not only their prompt but also the tools that they (and any subagents) have access to. At any point, the agent can update its memory. If you correct the agent, it will now remember that correction so you don&apos;t have to prompt it to do so again in the future.</li></ul><p>LangSmith Agent Builder is great for internal productivity use cases like email, chat, and Salesforce assistants. For instance, you can build an agent to send you a summary of your schedule with meeting prep every day. You could build an email agent that dynamically creates next steps based on the message, from creating Linear tickets, to drafting responses, or sending a Slack message. And, you can make sure to approve any messages before they get sent. </p><p>We&apos;ll continue to expand what&apos;s possible with Agent Builder based on community feedback &#x2014; <a href="http://langchain.com/langsmith-agent-builder-waitlist?ref=blog.langchain.com" rel="noreferrer">join the waitlist</a> to help shape what comes next.</p><h2 id="under-the-hood">Under the hood</h2><p>We&#x2019;ve incorporated learnings from the last three years building open source agent frameworks LangChain and LangGraph, as well as our early iteration of this product Open Agent Platform, to inform our design decisions.</p><p>Today, LangSmith Agent Builder is built on top of our <code>deepagents</code> package. Deep Agents gives your agents access to planning capabilities, persistent memory, and the ability to break down complex tasks into manageable subtasks. This means your agent can handle complex, multi-step workflows without you needing to map out every possible scenario; they problem-solve in real time.</p><p>For folks already using the LangChain ecosystem of tools, here&apos;s a table with some tips on when to use LangSmith Agent Builder vs. our open source frameworks.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-28-at-6.49.38---PM-1.png" class="kg-image" alt="Introducing LangSmith&#x2019;s No Code Agent Builder" loading="lazy" width="1420" height="804" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Screenshot-2025-10-28-at-6.49.38---PM-1.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/Screenshot-2025-10-28-at-6.49.38---PM-1.png 1000w, https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-28-at-6.49.38---PM-1.png 1420w" sizes="(min-width: 720px) 720px"></figure><h2 id="sign-up-for-the-agent-builder-waitlist">Sign up for the Agent Builder waitlist</h2><p>If you&#x2019;re interested in checking out the new experience, <a href="http://langchain.com/langsmith-agent-builder-waitlist?ref=blog.langchain.com">sign up for our private preview waitlist</a> today! We can&#x2019;t wait to hear input from the community to continue to improve the experience for everyone.</p>]]></content:encoded></item><item><title><![CDATA[Doubling down on DeepAgents]]></title><description><![CDATA[<p>Two months ago <a href="https://blog.langchain.com/deep-agents/">we wrote about Deep Agents</a> - a term we coined for agents that are able to do complex, open ended tasks over longer time horizons. We hypothesized that there were four key elements to those agents: a planning tool, access to a filesystem, subagents, and detailed prompts.</p>]]></description><link>https://blog.langchain.com/doubling-down-on-deepagents/</link><guid isPermaLink="false">68fd1e03eab7880001538d59</guid><dc:creator><![CDATA[LangChain Accounts]]></dc:creator><pubDate>Tue, 28 Oct 2025 17:02:22 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Doubling-down-on-DeepAgents.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Doubling-down-on-DeepAgents.png" alt="Doubling down on DeepAgents"><p>Two months ago <a href="https://blog.langchain.com/deep-agents/">we wrote about Deep Agents</a> - a term we coined for agents that are able to do complex, open ended tasks over longer time horizons. We hypothesized that there were four key elements to those agents: a planning tool, access to a filesystem, subagents, and detailed prompts.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Visual-1-2.png" class="kg-image" alt="Doubling down on DeepAgents" loading="lazy" width="1771" height="723" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Visual-1-2.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/Visual-1-2.png 1000w, https://blog.langchain.com/content/images/size/w1600/2025/10/Visual-1-2.png 1600w, https://blog.langchain.com/content/images/2025/10/Visual-1-2.png 1771w" sizes="(min-width: 720px) 720px"></figure><p>We launched <a href="https://github.com/hwchase17/deepagents?ref=blog.langchain.com"><code>deepagents</code></a> as an Python package that had a base of all these elements, so that you would only have to bring your custom tools and a custom prompt and you could build a Deep Agent easily.</p><p>We&apos;ve seen strong interest and adoption, and today we&apos;re excited to double down with a 0.2 release. In this blog we want to talk about whats new in 0.2 release compared to the launch, as well as when to use <a href="https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com"><code>deepagents</code></a> (vs <a href="https://docs.langchain.com/oss/python/langchain/overview?ref=blog.langchain.com"><code>langchain</code></a> or <a href="https://docs.langchain.com/oss/python/langgraph/overview?ref=blog.langchain.com"><code>langgraph</code></a>)</p><h2 id="pluggable-backends"><strong>Pluggable Backends</strong></h2><p>The main new addition in 0.2 release comes in the form of pluggable backends. Previously, the &quot;filesystem&quot; that <code>deepagents</code> had access to was a &quot;virtual filesystem&quot;. It would use LangGraph state to store files.</p><p>In 0.2, we have a new <code>Backend</code> abstraction, which allows you to plug in anything as the &quot;filesystem&quot;. Built in implementations include:</p><ul><li>LangGraph State</li><li>LangGraph Store (cross thread persistence)</li><li>The actual local filesystem</li></ul><p>We&apos;ve also introduced the idea of a &quot;composite backend&quot;. This allows you to have a base backend (eg local filesystem) but then map on top of it other backends at certain subdirectories. An example use case of this is to empower long term memory. You could have a local filesystem as a base backend, but then map all file operations in <code>/memories/</code> directory to an s3 backed &quot;virtual filesystem&quot;, allowing your agent to add things there and have them persist beyond your computer.</p><p>You can write your own backend to create a &quot;virtual filesystem&quot; over any database or any data store you want.</p><p>You can also subclass an existing backend and add in guardrails around which files can be written to, format checking for these files, etc.</p><h2 id="other-things-in-02">Other things in 0.2</h2><p>We also added a number of other improvements making their way to <code>deepagents</code> in the 0.2 release:</p><ul><li><a href="https://docs.langchain.com/oss/python/deepagents/harness?ref=blog.langchain.com#large-tool-result-eviction">Large tool result eviction</a>: automatically dump large tool results to the filesystem when they exceed a certain token limit.</li><li><a href="https://docs.langchain.com/oss/python/deepagents/harness?ref=blog.langchain.com#conversation-history-summarization">Conversation history summarization</a>: automatically compress old conversation history when token usage becomes large.</li><li><a href="https://docs.langchain.com/oss/python/deepagents/harness?ref=blog.langchain.com#dangling-tool-call-repair">Dangling tool call repair</a>: fix message history when tool calls are interrupted or cancelled before execution.</li></ul><h2 id="when-to-use-deepagents-vs-langchain-langgraph">When to use deepagents vs LangChain, LangGraph</h2><p>This is now our third open source library we are investing in, but we believe that all three serve different purposes. In order to distinguish these purposes, we will likely refer <code>deepagents</code> as an &quot;agent harness&quot;, <code>langchain</code> as an &quot;agent framework&quot;, and <code>langgraph</code> as an agent runtime.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Visual-2.png" class="kg-image" alt="Doubling down on DeepAgents" loading="lazy" width="2000" height="959" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Visual-2.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/Visual-2.png 1000w, https://blog.langchain.com/content/images/size/w1600/2025/10/Visual-2.png 1600w, https://blog.langchain.com/content/images/2025/10/Visual-2.png 2172w" sizes="(min-width: 720px) 720px"></figure><p>LangGraph is great if you want to build things that are combinations of workflows and agents.</p><p>LangChain is great if you want to use the core agent loop without anything built in, and built all prompts/tools from scratch.</p><p>DeepAgents is great for building more autonomous, long running agents where you want to take advantage of built in things like planning tools, filesystem, etc.</p><p>They built on top of each other - <code>deepagents</code> is built on top of <code>langchain</code>&apos;s agent abstraction, which is turn is built on top of <code>langgraph</code>&apos;s agent runtime.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Visual-3-5.png" class="kg-image" alt="Doubling down on DeepAgents" loading="lazy" width="1750" height="1156" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Visual-3-5.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/Visual-3-5.png 1000w, https://blog.langchain.com/content/images/size/w1600/2025/10/Visual-3-5.png 1600w, https://blog.langchain.com/content/images/2025/10/Visual-3-5.png 1750w" sizes="(min-width: 720px) 720px"></figure>]]></content:encoded></item><item><title><![CDATA[Agent Frameworks, Runtimes, and Harnesses- oh my!]]></title><description><![CDATA[<p>There are few different open source packages we maintain: <a href="https://docs.langchain.com/oss/python/langchain/quickstart?ref=blog.langchain.com">LangChain</a> and <a href="https://docs.langchain.com/oss/python/langgraph/overview?ref=blog.langchain.com">LangGraph</a> being the biggest ones, but <a href="https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com">DeepAgents</a> being an increasingly popular one. I&#x2019;ve started using different terms to describe them: LangChain is an agent framework, LangGraph is an agent runtime, DeepAgents is an <a href="https://www.vtrivedy.com/posts/claude-code-sdk-haas-harness-as-a-service?ref=blog.langchain.com">agent harness</a>. Other folks</p>]]></description><link>https://blog.langchain.com/agent-frameworks-runtimes-and-harnesses-oh-my/</link><guid isPermaLink="false">68fcf4a3eab7880001538d0c</guid><category><![CDATA[In the Loop]]></category><dc:creator><![CDATA[LangChain Accounts]]></dc:creator><pubDate>Sat, 25 Oct 2025 16:14:35 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-25-at-9.08.30---AM-1.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-25-at-9.08.30---AM-1.png" alt="Agent Frameworks, Runtimes, and Harnesses- oh my!"><p>There are few different open source packages we maintain: <a href="https://docs.langchain.com/oss/python/langchain/quickstart?ref=blog.langchain.com">LangChain</a> and <a href="https://docs.langchain.com/oss/python/langgraph/overview?ref=blog.langchain.com">LangGraph</a> being the biggest ones, but <a href="https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com">DeepAgents</a> being an increasingly popular one. I&#x2019;ve started using different terms to describe them: LangChain is an agent framework, LangGraph is an agent runtime, DeepAgents is an <a href="https://www.vtrivedy.com/posts/claude-code-sdk-haas-harness-as-a-service?ref=blog.langchain.com">agent harness</a>. Other folks are using these terms as well - but I don&#x2019;t think there is a clear definition of framework vs runtime vs harness. This is my attempt to do try to define things. I will readily admit that there is still murkiness and overlap so I would love any feedback!</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-25-at-9.08.30---AM.png" class="kg-image" alt="Agent Frameworks, Runtimes, and Harnesses- oh my!" loading="lazy" width="912" height="492" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Screenshot-2025-10-25-at-9.08.30---AM.png 600w, https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-25-at-9.08.30---AM.png 912w" sizes="(min-width: 720px) 720px"></figure><h2 id="agent-frameworks-langchain">Agent Frameworks (LangChain)</h2><p>Most packages out there that help build with LLMs I would classify as agent frameworks. The main value add they provide is abstractions. These abstractions represent a mental model of the world. These abstractions should ideally make it easier to get started. They also provide a standard way to build applications which makes it easy for developers to onboard and jump between projects. Complaints against abstractions are that if done poorly they can obfuscate the inner workings of things and not provide the flexibility needed for advanced use cases.</p><p>We think of <a href="https://docs.langchain.com/oss/python/langchain/overview?ref=blog.langchain.com">LangChain</a> as an agent framework. As part of the 1.0 we spent a lot of time thinking about the abstractions - for structured content blocks, for the agent loop, for middleware (which we think adds flexibility to the standard agent loop). Other examples of what I would consider agent frameworks are Vercel&#x2019;s AI SDK, CrewAI, OpenAI Agents SDK, Google ADK, LlamaIndex, and lot more.</p><h2 id="agent-runtimes-langgraph">Agent Runtimes (LangGraph)</h2><p>When you need to run agents in production, you will want some sort of runtime for agents. This runtime should provide more infrastructure level considerations. The main one that comes to mind is <a href="https://docs.langchain.com/oss/python/langgraph/durable-execution?ref=blog.langchain.com">durable execution</a>, but I would also put considerations like support for streaming, <a href="https://docs.langchain.com/oss/python/langgraph/interrupts?ref=blog.langchain.com">human-in-the-loop support</a>, thread level persistence and <a href="https://docs.langchain.com/oss/python/langgraph/add-memory?ref=blog.langchain.com">cross-thread persistence</a> here.</p><p>When we build <a href="https://docs.langchain.com/oss/python/langgraph/overview?ref=blog.langchain.com">LangGraph</a>, we wanted to build in a production ready agent runtime from scratch. You can read more about our thought process behind building LangGraph <a href="https://blog.langchain.com/building-langgraph/">here</a>. The other projects we think are closest to this are Temporal, Inngest, and other durable execution engines.</p><p>Agent runtimes are generally lower level than agent frameworks and can power agent frameworks. For example, LangChain 1.0 is built on top of LangGraph to take advantage of the agent runtime it provides.</p><h2 id="agent-harnesses-deepagents">Agent Harnesses (DeepAgents)</h2><p><a href="https://docs.langchain.com/oss/python/deepagents/overview?ref=blog.langchain.com">DeepAgents</a> is the newest project we&#x2019;re working on. It is higher level than agent frameworks - it builds on top of LangChain. It adds in default prompts, opinionated handling for tool calls, tools for planning, has access to a filesystem, and more. It&#x2019;s more than a framework - it comes with batteries included.</p><p>Another way that we&#x2019;ve used to describe DeepAgents is as a &#x201C;general purpose version of Claude Code&#x201D;. To be fair, Claude Code is also trying to be an agent harness - they&#x2019;ve released things like Claude Agent SDK as a step in that direction. Besides Claude Agent SDK, I don&#x2019;t think there are many other general purpose agent harnesses out there today. One could argue, however, that ALL the coding CLI&apos;s are in a way agent harnesses, and may be general purpose.</p><h2 id="when-to-use-each-one">When to use each one</h2><p>Let&#x2019;s summarize the differences and talk about when to each one:</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-25-at-9.05.40---AM.png" class="kg-image" alt="Agent Frameworks, Runtimes, and Harnesses- oh my!" loading="lazy" width="1786" height="332" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Screenshot-2025-10-25-at-9.05.40---AM.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/Screenshot-2025-10-25-at-9.05.40---AM.png 1000w, https://blog.langchain.com/content/images/size/w1600/2025/10/Screenshot-2025-10-25-at-9.05.40---AM.png 1600w, https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-25-at-9.05.40---AM.png 1786w" sizes="(min-width: 720px) 720px"></figure><p>Now, I will readily admit that the lines are blurry. LangGraph is probably best described as both a runtime and a framework, for example. &#x201C;Agent Harness&#x201D; is a term I&#x2019;m just starting to see be used more (<a href="https://www.vtrivedy.com/posts/claude-code-sdk-haas-harness-as-a-service?ref=blog.langchain.com">I didn&#x2019;t come up with it</a>). I don&#x2019;t think there is yet a super clear definition of any of these.</p><p>Part of the fun of developing in an early space is coming up with the mental models for how to talk about things. We know LangChain is different from LangGraph, and DeepAgents is different from both of them. We think describing them as a framework, runtime, and harness respectively is a helpful distinction - but as always, we would love your feedback!</p>]]></content:encoded></item><item><title><![CDATA[Improve agent quality with Insights Agent and Multi-turn Evals, now in LangSmith]]></title><description><![CDATA[LangSmith's new Insights Agent and Multi-turn Evals help you understand what your agents are doing in production and whether they're accomplishing user goals.]]></description><link>https://blog.langchain.com/insights-agent-multiturn-evals-langsmith/</link><guid isPermaLink="false">68f2aa54eab7880001538304</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Thu, 23 Oct 2025 14:23:55 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Blog-02.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Blog-02.png" alt="Improve agent quality with Insights Agent and Multi-turn Evals, now in LangSmith"><p><strong>TL;DR:</strong> We&#x2019;re releasing new capabilities in <strong>LangSmith</strong> to help monitor agents in production. We&#x2019;re making the concept of &#x201C;threads&#x201D; - representing a multi-turn agent interaction - a first-party concept, and we&#x2019;re adding two new tools to monitor threads: <strong>Insights Agent</strong> for automatically categorizing agent usage patterns, and <strong>Multi-turn Evals</strong> for scoring complete agent conversations.</p><hr><p>More and more agents are moving to production. As they do so, AI teams find themselves needing better visibility into what&#x2019;s happening across all user interactions. But, traditional observability and testing that focus on uptime can&apos;t tell whether your agent is actually accomplishing users&#x2019; goals. And testing your agent before it goes into production (what we call offline evals) only covers what you had in mind to start.</p><p>Today, we&#x2019;re releasing new features to help you understand what&#x2019;s happening inside your agent <em>while it&#x2019;s in production</em>, so you can prioritize improvements:</p><ul><li><strong>Insight Agent</strong>: automatically categorizes agent behavior patterns</li><li><strong>Multi-turn Evals</strong>: helps you evaluate the complete agent trajectory in each conversation</li></ul><h2 id="discover-patterns-in-production-traces-with-the-insights-agent"><strong>Discover patterns in production traces with the Insights Agent</strong></h2><p>Today&apos;s popular agents produce millions of traces per day&#x2014;soon to be billions. These traces contain valuable signal about an agent&apos;s capabilities and how real users engage with it. If you could review each interaction, you would gain deep insight into how to improve your agent. Manual review is time-consuming and impossible at scale, so how can we automate this insight generation process?</p><p><strong>Insights Agent</strong> is our first step towards helping LangSmith users find signal in their production traces. Insights Agent analyzes traces to discover and surface common usage patterns, agent behaviors, and failure modes.</p><p>In agent engineering, you need to iterate rapidly to build reliable experiences. This new feature helps you answer questions like &#x201C;What are users asking my agent?&#x201D;, so you can determine where to focus your next set of tests based on real interactions your agent is having.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/9aX8ETgSp0w?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Get Started with Insights Agent in LangSmith"></iframe></figure><p>Once you <a href="https://docs.langchain.com/langsmith/observability-quickstart?ref=blog.langchain.com">trace your data</a> to LangSmith, you have a few options for how to categorize usage insights.</p><ul><li><strong>Group by usage patterns:</strong> Cluster based on common usage patterns. This helps you understand how users are actually using your agent. When you put a chatbot in front of people, they can ask it anything. Now you can find out what they are asking.</li><li><strong>Group by poor interactions:</strong> Cluster based on how your agent is messing up. We will look for signals in each conversation that indicate a negative interaction (user getting frustrated, etc), and then group the root causes. This helps you understand common ways your agent fails, so you can prioritize improvements.</li><li><strong>Customize configurations:</strong> Insights Agent is highly configurable. You can specify which categories it should group by, filter on existing attributes (like traces from a particular time period or keywords in a chat), define new attributes, and save configs for future use.</li></ul><p>Generating insights can take up to 15 minutes depending on how much data the agent is crunching. Once the report is ready, you&#x2019;ll see traces organized into categories and subcategories based on your initial request. You can click into any category to explore the underlying traces and add them to datasets or annotation queues. You can also see other LangSmith metrics split by category, like latency, number of runs, and any evals you have set up.</p><p>Our goal in building this feature was to help you kick off exploration and ideas for improvements as quickly as possible.</p><p><strong>Insights Agent is now generally available</strong> for LangSmith Plus and Enterprise cloud customers. <a href="https://smith.langchain.com/?ref=blog.langchain.com">Sign up for LangSmith</a> and <a href="https://docs.langchain.com/langsmith/insights?ref=blog.langchain.com">check out our docs</a> to get started.</p><h2 id="evaluate-end-to-end-agent-interactions-with-multi-turn-evals">Evaluate end-to-end agent interactions with Multi-turn Evals</h2><p>Once you have a good sense of the top usage patterns your agent is handling, you can start to drill into how each complete conversation is performing. Until now, that&#x2019;s been tricky &#x2014; most other evaluation platforms only focus on individual traces or steps, making it hard to understand whether the overall interaction achieved the user&#x2019;s goal.</p><p>Today, we&apos;re launching <strong>Multi-turn Evals</strong> to help you measure whether your agent accomplished the user&#x2019;s goal across an <em>entire</em> interaction. You can do still evaluate at the trace level in LangSmith, but now you can also but also evaluate the whole interaction.</p><figure class="kg-card kg-embed-card"><iframe width="200" height="113" src="https://www.youtube.com/embed/sC0KhJHJTP0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen title="Get Started with LangSmith Multi-turn Evaluations"></iframe></figure><p>Multi-turn evals are online evaluations that let you measure things like:</p><ul><li><strong>Semantic intent</strong>: What the user was actually trying to do.</li><li><strong>Semantic outcomes:</strong> Whether the task was completed (and if not, why).</li><li><strong>Agent trajectory:</strong> How the interaction unfolded, including tool calls and decisions made along the way.</li></ul><p>In LangSmith, we represent these multi-turn exchanges between users and agents as <a href="https://docs.langchain.com/langsmith/threads?ref=blog.langchain.com"><strong>threads</strong></a>. If you&#x2019;re already using threads, getting started is simple. Multi-turn evals run automatically once a conversation is complete, and you define the LLM-as-a-judge prompt to guide scoring.</p><p>Insights Agent and Multi-turn evals are the first of several thread-level features we&#x2019;re working on. Stay tuned for thread-level metrics and dashboards, automations to add threads to an annotation queue and datasets, and SDK support so you can programmatically pull and analyze threads.</p><p><strong>Multi-turn evals are live today for all LangSmith users.</strong> <a href="https://docs.langchain.com/langsmith/online-evaluations?ref=blog.langchain.com#configure-multi-turn-online-evaluators">Visit our docs</a> to get started.</p><h2 id="iterate-faster-with-langsmith"><strong>Iterate faster with LangSmith</strong></h2><p>Our latest LangSmith updates work together to address tough challenges when engineering reliable agents. Now, you can understand what&apos;s happening in production (Insights Agent) and measure whether agents accomplish user goals (Multi-turn Evals). These features provide new levels of visibility to help you figure out what&#x2019;s the best next step to improving your agent.</p><p>Ready to ship reliable agents? Get started with <a href="https://smith.langchain.com/?ref=blog.langchain.com">LangSmith</a> today.</p>]]></content:encoded></item><item><title><![CDATA[LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones]]></title><description><![CDATA[<p><em>By Sydney Runkle and the LangChain OSS team </em></p><p>We&apos;re releasing LangChain 1.0 and LangGraph 1.0 &#x2014; our first major versions of our open source frameworks! After years of feedback, we&apos;ve updated <code>langchain</code> to focus on the core agent loop, provide flexibility with a new</p>]]></description><link>https://blog.langchain.com/langchain-langgraph-1dot0/</link><guid isPermaLink="false">68f50b74eab78800015383f5</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Wed, 22 Oct 2025 14:58:46 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Blog-03.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Blog-03.png" alt="LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones"><p><em>By Sydney Runkle and the LangChain OSS team </em></p><p>We&apos;re releasing LangChain 1.0 and LangGraph 1.0 &#x2014; our first major versions of our open source frameworks! After years of feedback, we&apos;ve updated <code>langchain</code> to focus on the core agent loop, provide flexibility with a new concept of middleware, and upgrade model integrations with the latest content types.</p><p>These two frameworks serve different purposes:</p><ul><li><strong>LangChain</strong> is the fastest way to build an AI agent &#x2014; with a standard tool calling architecture, provider agnostic design, and middleware for customization.</li><li><strong>LangGraph</strong> is a lower level framework and runtime, useful for highly custom and controllable agents, designed to support production-grade, long running agents</li></ul><p>These 1.0 releases mark our commitment to stability for our open source libraries and no breaking changes until 2.0. Alongside these releases, we&apos;re launching a completely redesigned <a href="https://docs.langchain.com/oss/python/langchain/overview?ref=blog.langchain.com">docs site</a>.</p><p>Learn more about the changes below, and check our <a href="https://youtu.be/r5Z_gYZb4Ns?ref=blog.langchain.com" rel="noopener noreferrer">behind-the-scenes</a><a href="https://youtu.be/r5Z_gYZb4Ns?ref=blog.langchain.com" rel="noopener noreferrer"> conversation</a> with our engineers for more commentary.</p><h2 id="langchain-10">LangChain 1.0</h2><p>LangChain has always offered high-level interfaces for interacting with LLMs and building agents. With standardized model abstractions and prebuilt agent patterns, it helps developers ship AI features fast and build sophisticated applications without vendor lock-in. This is essential in a space where the best model for any given task changes regularly.</p><p><strong>We&apos;ve been listening.</strong> Over the past three years, we&apos;ve heard consistent feedback: LangChain&apos;s abstractions were sometimes too heavy, the package surface area had grown unwieldy, and developers wanted more control over the agent loop without dropping down to raw LLM calls. Some struggled with customization when their use cases diverged from our prebuilt patterns. We took this feedback seriously. LangChain 1.0 is our response&#x2014; a thoughtful refinement that preserves what works while fixing what didn&apos;t.</p><blockquote>&quot;We rely heavily on the durable runtime that LangGraph provides under the hood to support our agent developments, and the new agent prebuilt and middleware in LangChain 1.0 makes it far more flexible than before. We&apos;re excited about 1.0 and are already building with the new features at Rippling.&quot; &#x2013; <strong>Ankur Bhatt, Head of AI at Rippling</strong></blockquote><p>We&#x2019;re leaning hard into three things for LangChain 1.0:</p><ol><li><strong>Our new <code>create_agent</code> abstraction:</strong> the fastest way to build an agent with any model provider<ol><li>Built on the LangGraph runtime, helping to power reliable agents</li><li>Prebuilt and user defined middleware enable step by step control and customization</li></ol></li><li><strong>Standard content blocks:</strong> a provider agnostic spec for model outputs.</li><li><strong>Streamlined surface area:</strong> we&#x2019;re trimming down our namespace to focus on what developers use to build agents.</li></ol><h3 id="1-createagent">1. <code>create_agent</code></h3><p>The <code>create_agent</code> abstraction is built around the core agent loop, making it easy to get started quickly. Here&apos;s how the loop works:</p><p><strong>Setup:</strong> select a model and give it some tools and a prompt.</p><p><strong>Execution:</strong></p><ol><li>Send a request to the model</li><li>The model responds with either:<ol><li>Tool calls &#x2192; execute the tool and add results to the conversation</li><li>Final answer &#x2192; return the result</li></ol></li><li>Repeat from step 1</li></ol><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-08-at-5.15.25---PM--1-.png" class="kg-image" alt="LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones" loading="lazy" width="868" height="774" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Screenshot-2025-10-08-at-5.15.25---PM--1-.png 600w, https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-08-at-5.15.25---PM--1-.png 868w" sizes="(min-width: 720px) 720px"></figure><p>The new <code>create_agent</code> function uses LangGraph under the hood to run this loop. It has a very similar feel to the <code>create_react_agent</code> function from <code>langgraph.prebuilts</code>, which has been used in production for a year.</p><p>Getting started with an agent in <code>langchain</code> is easy:</p><pre><code class="language-python">from langchain.agents import create_agent

weather_agent = create_agent(
    model=&quot;openai:gpt-5&quot;,
    tools=[get_weather],
    system_prompt=&quot;Help the user by fetching the weather in their city.&quot;,
)

result = agent.invoke({&quot;role&quot;: &quot;user&quot;, &quot;what&apos;s the weather in SF?&quot;})
</code></pre><p>Most agent builders are highly restrictive in that they don&#x2019;t permit customization outside of this core loop. That&#x2019;s where <code>create_agent</code> stands out with our introduction of <code>middleware</code>.</p><p><strong>Middleware:</strong></p><p>Middleware defines a set of hooks that allow you to customize behavior in the agent loop, enabling fine grained control at every step an agent takes.</p><p>We&#x2019;re including a few built-in middlewares for common use cases:</p><ul><li><strong>Human-in-the-loop:</strong> Pause agent execution to let users approve, edit, or reject tool calls before they execute. This is essential for agents that interact with external systems, send communications, or make sensitive transactions.</li><li><strong>Summarization:</strong> Condense message history when it approaches context limits, keeping recent messages intact while summarizing older context. This prevents token overflow errors and keeps long-running agent sessions performant.</li><li><strong>PII redaction:</strong> Use pattern matching to identify and redact sensitive information like email addresses, phone numbers, and social security numbers before content is passed to the model. This helps maintain compliance with privacy regulations and prevents accidental exposure of user data.</li></ul><p>LangChain also supports <strong>custom</strong> <strong>middleware</strong> that hook into various of points in the agent loop. The following diagram showcases these hooks:</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/middleware_final--2-.png" class="kg-image" alt="LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones" loading="lazy" width="500" height="560"></figure><p><strong>Structured Output Generation:</strong></p><p>We&#x2019;ve also improved structured output generation in the agent loop by incorporating it into the main model &lt;&#x2013;&gt; tools loop. This reduces both latency and cost by eliminating an extra LLM call that used to happen in addition to the main loop.</p><p>Developers now have fine grained control over how structured output is generated, either via tool calling or provider-native structured output.</p><pre><code class="language-python">from langchain.agents import create_agent
from langchain.agents.structured_output import ToolStrategy

from pydantic import BaseModel

class WeatherReport(BaseModel):
    temperature: float    
    condition: str

agent = create_agent(
    &quot;openai:gpt-4o-mini&quot;,
    tools=[weather_tool],
    response_format=ToolStrategy(WeatherReport),
    prompt=&quot;Help the user by fetching the weather in their city.&quot;,
)
</code></pre><h3 id="standard-content-blocks">Standard Content Blocks</h3><p>LangChain&#x2019;s hundreds of provider integrations (OpenAI, Anthropic, etc.) are largely unchanged in 1.0. The interfaces used by these abstractions live in <code>langchain-core</code>, which we&#x2019;re promoting to 1.0 with one key addition: <strong>standardized content blocks</strong>.</p><p>Much of LangChain&#x2019;s value comes from its provider-agnostic interfaces, allowing developers to use a common protocol across multiple providers in a single application. Without standard content blocks, switching models or providers often breaks streams, UIs and frontends, and memory stores. The new <code>.content_blocks</code> property on messages provides:</p><ul><li>Consistent content types across providers</li><li>Support for reasoning traces, citations, and tool calls &#x2013; including server-side tool calls</li><li>Typed interfaces for complex response structures</li><li>Full backward compatibility</li></ul><p>This keeps LangChain&#x2019;s abstractions current with modern LLM capabilities like reasoning, citations, and server side tool execution, while minimizing breaking changes.</p><h3 id="simplifying-the-package">Simplifying the package</h3><p>LangChain 1.0 reduces package scope to essential abstractions. Legacy functionality moves to <code>langchain-classic</code> for backwards compatibility. As the framework has matured, we&apos;ve learned what patterns matter most. This streamlined package cuts through years of accumulated features to make LangChain simple <em>and</em> powerful.</p><p><strong>Key Changes:</strong></p><ul><li><code>create_agent</code> introduced in LangChain, with <code>create_react_agent</code> deprecated in <code>langgraph.prebuilt</code></li><li>Python 3.9 support dropped due to October 2025 EOL, v1.0 requires Python 3.10+<ul><li>Python 3.14 support is coming soon!</li></ul></li><li>Package surface area reduced to focus on core abstractions with old functionality moved to <code>langchain-classic</code> </li></ul><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-10-at-11.16.22---PM--1--1.png" class="kg-image" alt="LangChain and LangGraph Agent Frameworks Reach v1.0 Milestones" loading="lazy" width="1536" height="440" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/Screenshot-2025-10-10-at-11.16.22---PM--1--1.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/Screenshot-2025-10-10-at-11.16.22---PM--1--1.png 1000w, https://blog.langchain.com/content/images/2025/10/Screenshot-2025-10-10-at-11.16.22---PM--1--1.png 1536w" sizes="(min-width: 720px) 720px"></figure><h3 id="installation">Installation</h3><pre><code class="language-bash"># Python
uv pip install --upgrade langchain
uv pip install langchain-classic

# JavaScript
npm install @langchain/langchain@latest
npm install @langchain/langchain-classic
</code></pre><h3 id="migration">Migration</h3><p>If you&apos;re upgrading from a previous version of LangChain, we&apos;ve created detailed resources to guide you through the changes.</p><p><strong>Release overviews:</strong> <a href="https://docs.langchain.com/oss/python/releases/langchain-v1?ref=blog.langchain.com">Python</a>, <a href="https://docs.langchain.com/oss/javascript/releases/langchain-v1?ref=blog.langchain.com">JavaScript</a></p><p><strong>Migration guides</strong>: <a href="https://docs.langchain.com/oss/python/migrate/langchain-v1?ref=blog.langchain.com">Python</a>, <a href="https://docs.langchain.com/oss/javascript/migrate/langchain-v1?ref=blog.langchain.com">JavaScript</a></p><h2 id="langgraph-10">LangGraph 1.0</h2><p>AI agents are moving from prototype to production, but core features like persistence, observability, and human-in-the-loop control have remained underserved.</p><p>LangGraph 1.0 addresses these gaps with a powerful graph-based execution model, and it provides production-ready features for reliable agentic systems:</p><ul><li><strong>Durable state</strong> - Your agent&apos;s execution state persists automatically, so if your server restarts mid-conversation or a long-running workflow gets interrupted, it picks up exactly where it left off without losing context or forcing users to start over.</li><li><strong>Built-in persistence</strong> - Save and resume agent workflows at any point without writing custom database logic, enabling use cases like multi-day approval processes or background jobs that run across multiple sessions.</li><li><strong>Human-in-the-loop patterns</strong> - Pause agent execution for human review, modification, or approval with first-class API support, making it trivial to build systems where humans stay in control of high-stakes decisions.</li></ul><p>For a deeper dive into our design philosophy, check out our <a href="https://blog.langchain.com/building-langgraph/">blog post</a> on building LangGraph from first principles.</p><p>This is the first stable major release in the durable agent framework space &#x2014; a major milestone for production-ready AI systems. After more than a year of iteration and widespread adoption by companies like Uber, LinkedIn, and Klarna, LangGraph is officially v1.</p><h3 id="breaking-changes-migration">Breaking Changes &amp; Migration</h3><p>The only notable change is deprecation of the <code>langgraph.prebuilt</code> module, with enhanced functionality moved to <code>langchain.agents</code>.</p><p>LangGraph 1.0 maintains full backward compatibility.</p><h3 id="installation-1">Installation</h3><pre><code class="language-bash"># Python
uv pip install --upgrade langgraph

# JavaScript
npm install @langchain/langgraph@latest
</code></pre><h2 id="when-to-use-each-framework">When to Use Each Framework</h2><p>LangChain lets you build and ship agents fast with high-level abstractions for common patterns, while LangGraph gives you fine-grained control for complex workflows that require customization.</p><p>The best part? LangChain agents are built on LangGraph, so you&apos;re not locked in. Start with LangChain&apos;s high-level APIs and seamlessly drop down to LangGraph when you need more control. Since graphs are composable, you can mix both approaches&#x2014;using agents created with <code>create_agent</code> inside custom LangGraph workflows as your needs evolve.</p><h3 id="choose-langchain-10-for">Choose LangChain 1.0 for:</h3><ul><li>Shipping quickly with standard agent patterns</li><li>Agents that fit the default loop (model &#x2192; tools &#x2192; response)</li><li>Middleware-based customization</li><li>Higher-level abstractions over low-level control</li></ul><h3 id="choose-langgraph-10-for">Choose LangGraph 1.0 for:</h3><ul><li>Workflows with a mixture of deterministic and agentic components</li><li>Long running business process automation</li><li>Sensitive workflows which necessitate more oversight / human in the loop</li><li>Highly custom or complex workflows</li><li>Applications where latency and / or cost need to be carefully controlled</li></ul><h2 id="documentation-resources">Documentation &amp; Resources</h2><p>We&apos;re launching a much improved documentation site at <a href="https://docs.langchain.com/?ref=blog.langchain.com">docs.langchain.com</a>. For the first time, all LangChain and LangGraph docs&#x2014;across Python and JavaScript&#x2014;live in one unified site with parallel examples, shared conceptual guides, and consolidated API references.</p><p>The new docs feature more intuitive navigation, thoughtful guides, and in depth tutorials for common agent architectures.</p><h2 id="thank-you-feedback">Thank You &amp; Feedback</h2><p>We hope you love these 1.0 releases. We are incredibly grateful for the community that has pressure tested LangChain and LangGraph over the years to make them what they are today. With 90M monthly downloads and powering production applications at Uber, JP Morgan, Blackrock, Cisco, and more, we have a duty to you all to keep innovating but also be the most dependable framework for building agents. </p><p>While this is a major milestone, we are still at the beginning of a major change in software. We want to hear from you: <a href="https://forum.langchain.com/t/launch-week-is-here-oss-1-0s-insights-agent-and-no-code-agent-builder/1890?ref=blog.langchain.com" rel="noopener noreferrer">post on the LangChain Forum </a>and tell us what you think of our 1.0 release and what you&apos;re building.</p>]]></content:encoded></item><item><title><![CDATA[LangChain raises $125M to build the platform for agent engineering]]></title><description><![CDATA[We raised $125M at a $1.25B valuation to build the platform for agent engineering.]]></description><link>https://blog.langchain.com/series-b/</link><guid isPermaLink="false">68f179b9eab7880001538274</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Mon, 20 Oct 2025 14:36:50 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Blog-01-1.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Blog-01-1.png" alt="LangChain raises $125M to build the platform for agent engineering"><p>Today, we&#x2019;re announcing we&#x2019;ve raised $125M at a $1.25B valuation to build the <strong>platform for agent engineering.</strong> We&#x2019;re also releasing new capabilities to accelerate the path to reliable agents, including LangChain and LangGraph 1.0 releases, a new Insights Agent, and a no code agent builder. IVP led the round alongside existing investors Sequoia, Benchmark, and Amplify, as well as new investors CapitalG and Sapphire Ventures.</p><p>From AI-native startups to global enterprises, builders trust LangChain&apos;s products to engineer reliable agents. Today, we&#x2019;re grateful to power AI teams at Replit, Clay, Harvey, Rippling, Cloudflare, Workday, Cisco, and more.&#xA0;</p><p>The core ideas we had when we made the first commit to the <code>langchain</code> package three years ago still hold true today: LLMs will change what applications can do, but the real power comes from turning LLM applications into <strong>agents</strong> with access to data and APIs. Agents will function as complex systems that require new tooling and infrastructure to harness the power of generative AI.</p><p>Today&#x2019;s reality is that agents are easy to prototype but hard to ship to production. That&#x2019;s because any input or change to an agent can create a host of unknown outcomes. Building reliable agents requires a new approach, one that combines product, engineering, and data science thinking. We call this discipline <strong>agent engineering</strong> - the iterative process of refining non-deterministic LLM systems into reliable experiences.</p><p><strong>We are building the platform for agent engineering.</strong></p><p>We&#x2019;ve evolved our offerings from the original <code>langchain</code> library based on feedback from millions of developers and thousands of customers in our community. We&#x2019;ve always let you choose the best model for the job, no matter the vendor. Today, we are launching an expanded platform for the complete lifecycle of agent engineering.&#xA0;&#xA0;</p><p>The LangChain community can build agents with our <strong>open source frameworks &#x2013; LangChain and LangGraph</strong>.</p><ul><li><strong>LangChain</strong> helps you get started building agents quickly with any model provider of your choice. We&#x2019;ve completely rewritten <code>langchain</code> in its 1.0 release to be opinionated, focused, and powered by <code>langgraph</code>&#x2019;s runtime.&#xA0;</li><li><strong>LangGraph </strong>allows you to control every step of your custom agent with low-level orchestration, memory, and human-in-the-loop support. You can manage long-running tasks with durable execution.&#xA0;</li></ul><p>Previously, LangSmith helped you understand and test your agent. Now, <strong>LangSmith</strong> is a comprehensive platform for agent engineering that helps AI teams use live production data for continuous testing and improvement. LangSmith provides:</p><ul><li><strong>Observability</strong> to see exactly how your agent thinks and acts with detailed tracing and aggregate trend metrics.</li><li><strong>Evaluation</strong> to test and score agent behavior on production data and offline datasets for continuous improvement.</li><li><strong>Deployment</strong> (formerly LangGraph Platform) to ship your agent in one click, using scalable infrastructure built for long-running tasks.</li><li><strong>Agent Builder </strong>(now in private preview) to reduce the barrier to building agents with a no code text-to-agent experience.</li></ul><p>Open is part of our ethos, so you can use LangSmith whether you build your agent with our open source frameworks or not. If you do use our stack together, you&#x2019;ll be able to iterate faster towards reliable agents.</p><p>The space evolves rapidly, and so do we. Today we&#x2019;re announcing:</p><ul><li><a href="https://docs.langchain.com/oss/python/langchain/overview?ref=blog.langchain.com" rel="noreferrer"><strong>Major 1.0 releases</strong></a><strong> of LangChain and LangGraph</strong> marking stability, with a completely revamped <code>langchain</code> package focused on pre-built architectures for common agent patterns, improved model integrations, and no breaking changes until 2.0. Plus, new docs!</li><li><a href="https://youtu.be/9aX8ETgSp0w?ref=blog.langchain.com" rel="noreferrer"><strong>Insights Agent</strong></a>, a new agent in LangSmith Observability that automatically categorizes agent behavior patterns.</li><li><a href="http://langchain.com/langsmith-agent-builder-waitlist?ref=blog.langchain.com" rel="noreferrer"><strong>Agent Builder</strong></a><strong> (in private preview) </strong>to lower the barrier to entry for building agents with a no code text-to-agent builder experience for business users.&#xA0;</li></ul><p>The momentum we&#x2019;ve seen is just the beginning. Today, <code>langchain</code> and <code>langgraph</code> have a combined 90M monthly downloads, and 35 percent of the Fortune 500 use our services. Monthly trace volume for our commercial LangSmith platform has 12x&#x2019;d year over year.&#xA0;</p><p>We&#x2019;d love you to be a part of the story. Head on over to the <a href="http://docs.langchain.com/?ref=blog.langchain.com"><u>docs</u></a> to see what&#x2019;s available, stay tuned on <a href="https://blog.langchain.com/"><u>our blog</u></a> for deep dives on every launch this week and next, take a <a href="http://academy.langchain.com/?ref=blog.langchain.com"><u>course</u></a> to uplevel your skills, and if building the future of agent engineering sounds fun, come join us. <a href="http://langchain.com/careers?ref=blog.langchain.com" rel="noreferrer">We&apos;re hiring.</a></p><p><em>Thank you to our new investors, many of whom are already customers or partners, that help make this journey possible &#x2013; ServiceNow Ventures, Workday Ventures, Cisco Investments, Datadog Ventures, Databricks Ventures, and Frontline.</em></p>]]></content:encoded></item><item><title><![CDATA[Reflections on Three Years of Building LangChain]]></title><description><![CDATA[<p><em>by Harrison Chase</em></p><p>Almost exactly 3 years ago, I pushed the first lines of code to <code>langchain</code> as an open source package. There was no company at the time, and no grand plan for what the project would become.</p><p>A month later, ChatGPT launched, and everything for <code>langchain</code> changed. It</p>]]></description><link>https://blog.langchain.com/three-years-langchain/</link><guid isPermaLink="false">68f45df6eab788000153839c</guid><category><![CDATA[In the Loop]]></category><dc:creator><![CDATA[Harrison Chase]]></dc:creator><pubDate>Mon, 20 Oct 2025 14:34:32 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/3-year-reflection-thumbnail.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/3-year-reflection-thumbnail.png" alt="Reflections on Three Years of Building LangChain"><p><em>by Harrison Chase</em></p><p>Almost exactly 3 years ago, I pushed the first lines of code to <code>langchain</code> as an open source package. There was no company at the time, and no grand plan for what the project would become.</p><p>A month later, ChatGPT launched, and everything for <code>langchain</code> changed. It quickly gained steam as the default way to build your own LLM-powered apps. Over the past three years the industry has matured past prototyping chatbots toward productionizing agents that do things, and <code>langchain</code> has evolved into LangChain, the company.</p><p>Our product offerings have expanded, too: from a single Python open source package to a multi-language agent ecosystem consisting of multiple popular open source packages and a separate commercial platform (LangSmith). Our technologies power leading companies&apos; agents like Rippling, Vanta, Cloudflare, Replit, Harvey, and thousands more.</p><p>Today, we&#x2019;re announcing a $125 million funding round at a $1.25 billion valuation to continue that trajectory, expand LangSmith, the platform for agent engineering, and grow our open source contributions. We wrote more about our vision for LangSmith and what else we&#x2019;re launching today in our <a href="https://blog.langchain.com/series-b" rel="noreferrer">announcement blog</a>.</p><p>With such a large funding announcement (and on the eve of the third anniversary of the initial <code>langchain</code> launch), I also want to take the time to share my perspective on how agents have evolved over the past three years, how we&#x2019;ve kept pace, worked to address fair feedback on the original <code>langchain</code>, and where the company is headed.&#xA0;</p><h2 id="starting-as-a-side-project"><strong>Starting as a side project</strong></h2><p><code>langchain</code> was launched as a single (800 line long?) python package in fall of 2022 out of my personal github <code>hwchase17</code>. It was a side project. I was inspired by going to meetups and running into a few folks on the bleeding edge, building some experimental stuff with language models. I was instantly fascinated by the technology but cannot claim to have had any idea how big LLMs would become. I saw a few common patterns in terms of how people were building and put those patterns into <code>langchain</code>.&#xA0;</p><p>After the initial launch, I kept on iterating on it, adding mainly two things: (1) more integrations to various LLMs, vector DBs, etc; (2) more high-level &#x201C;templates&#x201D; for getting started with RAG, SQL question answering, extraction, etc in 5 lines of code. A lot of <code>langchain</code> in the early days was experimenting with prompting techniques, and we were figuring things out alongside everyone else building in the space.&#xA0;</p><p>In addition to needing lots of integrations, it was clear from the beginning that there would be lots of options for LLMs. Especially in a dynamic industry, helping users pick a model and later change that decision was incredibly important. Model neutrality still remains one the main benefits of our products.</p><h2 id="forming-a-company"><strong>Forming a company</strong></h2><p>As the space (and <code>langchain</code>) exploded, I started working more closely with Ankush, my cofounder (and a much better engineer than me). We started to get the inklings of what would drive us to start a company and that early inspiration is still what we&apos;re focused on today:</p><p>LLMs are this great, transformational new technology. They are even more powerful when connected to external data and APIs. We call these systems agents. And it turns out building <em>reliable</em> agents is quite hard! When there is so much promise, but it&#x2019;s difficult to realize the vision, there&apos;s a massive opportunity to help. We were (and still are) determined to build the best tools to help others build reliable agents. We know what some of the needed tools are, and we don&#x2019;t yet know what others will be. Our goal is to figure out what the agents of the future look like, and then build tools to help make them real.</p><p>We started the company in February 2023 knowing that <code>langchain</code> was just the first tool we would build.</p><h2 id="launching-langsmith"><strong>Launching LangSmith</strong></h2><p>The biggest problem we saw facing developers was that these LLM systems had quality problems. LLM calls kept on messing up, largely because they had the wrong context. In order to make them more reliable, you needed observability into the context going into the LLMs, and a way to test that once you modified that context it actually led to improvements.</p><p>LangSmith was our answer to this problem &#x2013; observability and evals for LLM systems, and we went live with a beta in summer of 2023. Notably, we made LangSmith completely separate from <code>langchain</code>. We recognized that the space was very early and that a tool like LangSmith was much needed, so we committed to building LangSmith to be best-in-class, regardless of the framework (or lack of framework) that a developer used. LangSmith is neutral to the LLM and neutral to the underlying framework, adding to our open and composable philosophy of tooling.</p><h2 id="launching-langgraph"><strong>Launching LangGraph</strong></h2><p>Around the summer of 2023, we started to get a lot of negative feedback about <code>langchain</code>. Some problems we could fix: like preventing breaking changes, making hidden prompts explicit, package bloat, dependency conflicts, outdated documentation. But one piece of feedback was harder to address &#x2013; people wanted more control. While <code>langchain</code> was the fastest place to get started, we traded power for ease of use. The same high level interfaces in <code>langchain</code> that made it easy to get started were now getting in the way when people tried to customize them to go to production.</p><p>We started developing LangGraph that summer, and launched it in early 2024. There were two main pillars we focused on:</p><ol><li>Controllability: no hidden prompts, no hidden context engineering. You had full control over your system - whether it was a workflow or agent or anything in between.</li><li>Runtime: we took everything we learned about what was needed for a production runtime (streaming, statefulness, human-in-the-loop, durable execution) and built it into LangGraph in a first-party way.</li></ol><p>LangGraph was inspired by the limitations of the initial <code>langchain</code>. The production validation from companies like LinkedIn, Uber, J.P. Morgan, and BlackRock gave us confidence we were building in the right direction.</p><h2 id="revisiting-langchain"><strong>Revisiting LangChain</strong></h2><p>A few months ago, we decided to revisit <code>langchain</code> from the ground up. While we were seeing tremendous adoption of LangGraph, it did have a higher learning curve, and the incredible, persistent enthusiasm for <code>langchain</code> encouraged us that there was still a need in the industry that <code>langchain</code> was fulfilling. We had three goals for reimagined <code>langchain</code>:</p><ol><li>Make it as easy as possible to get started building agents</li><li>Allow for more customization than we had previously</li><li>Give it a production-ready runtime</li></ol><p>We knew this approach would require massive breaking changes to <code>langchain</code>. We decided it would be best to do this in 1.0 release. We accomplished our goals by:</p><ol><li>Focusing on the core tool-calling loop that is now synonymous with &quot;agents&quot;.</li><li>Adding in a new concept of middleware, which is uniquely designed to give developers control over the &#x201C;context engineering&#x201D; lifecycle exactly where they need it.</li><li>Building upon LangGraph, a runtime that supported streaming, durable execution, human-in-the loop, and more.</li></ol><p>We believe <code>langchain</code> 1.0, released today, solves the goals we had for it, and importantly gives the community of over a million developers a clearer view of what we stand behind. The best patterns for an agent architecture are far better understood today than when we started the project, and 1.0 is far more curated than anything you&#x2019;ve seen from our team before. Plus, we shipped a <a href="https://docs.langchain.com/?ref=blog.langchain.com" rel="noreferrer">new centralized docs site</a> which has been a long time coming! We hear you.</p><p>For the millions of developers (80 million monthly downloads!) using <code>langchain</code> today, we&#x2019;re also keeping around <code>langchain</code> 0.x as <code>langchain-classic</code>, and are committed to supporting it for an extended period of time.</p><h2 id="evolving-langsmith-into-the-agent-engineering-platform"><strong>Evolving LangSmith into the Agent Engineering Platform</strong></h2><p>The bread and butter of LangSmith has been observability and evaluations, but that&#x2019;s not the only tooling needed to build reliable agents. We started experimenting with bringing more functionality into the platform with &#x201C;LangGraph Platform,&#x201D; which was focused on deployments. As we look to the future, we see a number of new ways that we can help customers, and we want to make LangSmith a single place where you can get most of your tooling to build reliable agents. Today we&#x2019;re bringing deployments into LangSmith, and are setting LangSmith up to be the comprehensive agent engineering platform. We will add other product lines in LangSmith in the future and aim to make each new product independent of the existing ones but well integrated into the platform.</p><h2 id="agents-of-the-future"><strong>Agents of the future</strong></h2><p>Our goal is to figure out what the agents of the future look like and build tools to facilitate that. We know what some of those pieces are (an agent runtime like LangGraph, observability, evals). We have some hunches about what the other pieces are that we are actively exploring. We also fully expect that there will be other components that, at this moment in time, we can&apos;t imagine what they&apos;ll look like &#x2013; which makes this journey incredibly fun and rewarding for what we expect to be a long time.</p><p>If you have feedback on how our tools can adapt to better build the agents of the future, <a href="https://x.com/hwchase17?ref=blog.langchain.com" rel="noreferrer">let me know on X</a>. I appreciate every piece of feedback because we know our products will have to evolve.</p><p>If you need a partner when building the agents of the future - <a href="https://www.langchain.com/contact-sales?ref=blog.langchain.com"><u>get in touch</u></a>. We are lucky enough to work with wonderful companies like Vanta, Rippling, Replit, Clay, Cisco, Workday, and many more, and would love to work with more teams pushing what&apos;s possible.</p><p>If you want to help us on our mission in building the agents of the future - <a href="http://langchain.com/careers?ref=blog.langchain.com" rel="noreferrer"><u>we&#x2019;re hiring</u></a> for basically all roles.</p>]]></content:encoded></item><item><title><![CDATA[Securing your agents with authentication and authorization]]></title><description><![CDATA[Agents can take action which makes proper authentication and authorization critical. Read on for how to implement and evolve agent auth.]]></description><link>https://blog.langchain.com/agent-authorization-explainer/</link><guid isPermaLink="false">68e9a604eab7880001537cfb</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Mon, 13 Oct 2025 21:12:15 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Agent-Auth.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Agent-Auth.png" alt="Securing your agents with authentication and authorization"><p>Lately, every company has been rushing to build agents. And unlike the AI applications of years before, agents aren&#x2019;t limited to chat. Agents are notable because they can take action; they can fetch files, send messages, call tools and update records &#x2014; which makes the stakes higher and warrants a more thoughtful approach to securing them.</p><h3 id="access-control-primer">Access Control Primer</h3><p>To access sensitive data and use tools, agents need to be authenticated and authorized. While often used interchangeably, the two terms have distinct meanings:</p><ul><li>Authentication (AuthN): verifies&#xA0;<em>who</em>&#xA0;you are. When accessing data, your agent needs to have a distinct identity from all the other users or applications that also want access.</li><li>Authorization (AuthZ): determines&#xA0;<em>what you can do</em>. Your agent should have limits on what data it can access or what actions it can take.</li></ul><p>Authentication and authorization (collectively referred to as &#x201C;auth&#x201D;) are relevant to all types of applications, not just agents. To that end, there are existing frameworks like OAuth 2.0 to facilitate AuthN/Z. Many identity providers today have built extensive services on top of OAuth 2.0 to allow developers to implement access control in their applications. However, compared to the applications served by existing solutions, agents have some unique attributes that make it useful to create additional constructs for access.</p><h3 id="what-makes-agents-different">What Makes Agents Different?</h3><p>The biggest distinctions between agents and traditional applications are:</p><ol><li>Compared to most applications, agents will need to access an extremely large number of services and tools.</li><li>Agents are dynamic, and have significantly more fluid access needs.</li><li>Agents are more complex to audit than traditional applications.</li></ol><p>Each of these new attributes comes with new considerations for agent authentication and authorization. We break them down below.</p><p><strong>1. Agents will need to access an extremely large number of services and tools:</strong></p><ul><li>Common constructs will be useful to standardize tool access from agents</li><li>A standardized interface abstracting common OAuth 2.0 flows will simplify giving agents access to the data they need</li></ul><p><strong>2. Agents having significantly more fluid access needs:</strong></p><ul><li>Traditional applications have structured access needs, where the scope of the application&#x2019;s behavior is well defined. This means access controls can afford to be simpler, mainly checking if a user is allowed to consent to whatever permissions the app is requesting.</li><li>Agent behavior is nondeterministic, not well-defined. The correct level of access may be heavily context dependent, which can make it useful to set rules like &#x201C;Agent A is never allowed to request consent for permission A&#x201D; or &#x201C;Agent B must request consent each time permission C is needed&#x201D;</li></ul><p><strong>3. Agents are more complex to audit than traditional applications:</strong></p><ul><li>Due to the number of services agents can access, audit logs may be spread across many providers</li><li>Each call to an agent may involve many services and actions, which makes individual access trajectories more difficult to interpret</li><li>Agents benefit more from a centralized location to track audit events and analyze access patterns</li></ul><p>Taken together, these considerations form the shape of a centralized framework to manage agent authentication and authorization. It should consolidate auditable events and allow flexible rule configurations to match the dynamic access needs of agents. In essence, an auth server for agents.</p><h3 id="an-agent-auth-server">An Agent Auth Server</h3><p>What might such an auth server look like? We could draw inspiration from existing paradigms for human access, such as Role Based Access Control (RBAC) or Just in Time (JIT) access.</p><p>RBAC is an access control mechanism that grants humans access to resources based on their role. Instead of tying permissions to a particular user&#x2019;s identity, the permission is tied to the role the user holds (i.e. administrator). Roles can be granted and removed from users to dynamically adjust their access based on changing conditions, which can help fulfill the fluid access needs of agents.</p><p>JIT access is a security principle where users are granted temporary, privileged access to systems or resources only when needed, for a limited time. For agents, JIT access could be an effective method to allow agents to do powerful things while minimizing potential security risks.</p><p>By consolidating agent auth through a single service, access to tools and resources can be centralized and standardized. The server could consolidate disparate audit events, and organize them for easier review.</p><p>While some of these components are still being built, that doesn&#x2019;t mean you, as a developer, cannot build authentication and authorization into your agents today. The foundational frameworks of auth, like OAuth 2.0, can still be used to secure your individual agentic applications.</p><h3 id="agent-authn-and-authz-today">Agent AuthN and AuthZ Today</h3><p>Though agents bring new challenges, at a high level they share many similarities with traditional applications. At their core, they&#x2019;re pieces of software that want access to resources. Most modern applications today use the OAuth 2.0 framework for authorization and the OIDC framework built on top of OAuth 2.0 for authentication. Agents can also effectively use these standards.</p><p>However, OAuth 2.0 covers a lot of ground, and not all flows will be relevant for the agents you build. Access patterns can be broadly broken into two categories: Delegated Access and Direct Access</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th></th>
<th>Delegated Access</th>
<th>Direct Access</th>
</tr>
</thead>
<tbody>
<tr>
<td>Definition</td>
<td>The agent needs to access a resource on behalf of a user</td>
<td>The agent needs to access a resource without user involvement</td>
</tr>
<tr>
<td>Agent Types</td>
<td>Useful for agents dedicated to fulfilling human requests OR agents reliant on human oversight</td>
<td>Useful for ambient agents, which can trigger off events, or agents conducting autonomous processes</td>
</tr>
<tr>
<td>Benefits</td>
<td>Delegated access allows you to limit your agent&#x2019;s permissions to what the human is allowed to do. It also lets you associate agent actions with human approvers</td>
<td>Direct Access access allows your agents to operate independently of humans, and identify when agents are conducting fully autonomous flows</td>
</tr>
<tr>
<td>Examples</td>
<td>An email assistant needing access to your emails would need you to delegate access to read your emails</td>
<td>A security agent triaging large amounts of incidents might need access to system logs independent of a human</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<p>In practice, most agents will have some tasks where they need delegated access, and some where they want direct access. Most of these access scenarios can be covered by a few particular OAuth flows, which we&#x2019;ll break down in this next section.</p><h3 id="delegated-access">Delegated Access</h3><p>Let&#x2019;s list some common requirements for tasks in which agents need delegated access.</p><ol><li>The agent needs to fulfill human requests, and is available to users as a service</li><li>Users should not be able to view the requests of other users without explicit permission. This means you need to&#x2026;<ol><li>Identify who the user accessing your agent is &#x2014; meaning you need to authenticate users</li><li>Control whether users have access to view a particular request to your agent &#x2014; meaning you need to authorize your users</li></ol></li><li>The Agent needs to access data across several platforms (Microsoft, Slack, Jira, Google, Datadog, etc.) to do useful work. This means&#x2026;<ol><li>Your agent needs to obtain access to other services &#x2014; meaning your agent needs authorization from these other services</li><li>While handling user requests, your agent should be limited to what the user is allowed to do. If the user can&#x2019;t view a top secret Microsoft document, the agent shouldn&#x2019;t use that document when answering their question.</li></ol></li></ol><p>The most common OAuth 2.0 flow used to fulfill Requirement 2 is <a href="https://auth0.com/docs/get-started/authentication-and-authorization-flow/authorization-code-flow?ref=blog.langchain.com"><strong>Auth Code Flow</strong></a><strong>.</strong></p><p>The OAuth 2.0 flow used to fulfill Requirement 3 is the <a href="https://learn.microsoft.com/en-us/entra/identity-platform/v2-oauth2-on-behalf-of-flow?ref=blog.langchain.com"><strong>OBO (On-Behalf-Of) Token Flow.</strong></a></p><p><strong>In most delegated access scenarios, Auth Code Flow and OBO Token Flow are all you need for your agent.</strong></p><h3 id="direct-access">Direct Access</h3><p>We can take the same approach for Direct access, and list some requirements:</p><ol><li>Your agent needs to access one or more services without human involvement. This means&#x2026;<ol><li>Other services need to be able to identify your agent and distinguish it from other applications &#x2014; meaning your agent needs to be authenticated to these services</li><li>Your agent needs access to other services &#x2014; these services need to authorize your agent to control what it has access to</li></ol></li></ol><p><strong>The OAuth flow used to accomplish the Direct Access scenario above is the </strong><a href="https://auth0.com/docs/get-started/authentication-and-authorization-flow/client-credentials-flow?ref=blog.langchain.com"><strong>Client Credentials Flow</strong></a></p><ul><li>Client Credentials flow requires that your agent is running in a private environment where its source code is not exposed to third parties - so no mobile apps or Single Page Apps (SPAs)</li><li>In production, it&#x2019;s good practice to use a credential management mechanism to avoid long-lived credentials (which are vulnerable to compromise).</li></ul><p>To recap, if you&#x2019;re looking to set up access for your agent, there&#x2019;s likely 3 flows you&#x2019;ll need:</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th>Type of Access</th>
<th>OAuth 2.0 Flows</th>
</tr>
</thead>
<tbody>
<tr>
<td>Delegated Access</td>
<td>1. Auth Code Flow                          2. OBO Token Flow</td>
</tr>
<tr>
<td>Direct Access</td>
<td>3. Client Credentials Flow</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<h3 id="conclusion">Conclusion</h3><p>As agents become more capable, more autonomous, and more useful, the need for a good authentication and authorization story increases.</p><p>Part of that story is a continuation of what&#x2019;s already been built: the existing standards of OAuth 2.0 and OIDC. If you need to implement auth for your agent, you&#x2019;ll likely find yourself implementing Auth Code Flow, OBO Token Flow, or Client Credentials Flow.</p><p>However, agents <em>do</em> bring new challenges to the table. Agents will routinely span dozens of services, request access in fluid ways, and trigger chains of actions that are harder to audit. We believe there&#x2019;ll be a need for new tooling to centralize control and standardize agent access.</p><p>We&#x2019;ve written about <a href="https://blog.arcade.dev/agent-authorization-langgraph-guide?ref=blog.langchain.com">agent access control</a> before with our friends at <a href="https://www.arcade.dev/?ref=blog.langchain.com">Arcade</a>, in case you&#x2019;re interested in diving deeper.</p>]]></content:encoded></item><item><title><![CDATA[Not Another Workflow Builder]]></title><description><![CDATA[<p><em>By Harrison Chase</em></p><p>One of the most common requests we&#x2019;ve gotten from day zero of LangChain has been a visual workflow builder. We never pursued it and instead let others (LangFlow, Flowise, n8n) build on top of us. With OpenAI launching a <a href="https://openai.com/index/introducing-agentkit/?ref=blog.langchain.com">workflow builder</a> at Dev Day yesterday,</p>]]></description><link>https://blog.langchain.com/not-another-workflow-builder/</link><guid isPermaLink="false">68e51ba99024b70001afe265</guid><category><![CDATA[In the Loop]]></category><dc:creator><![CDATA[Harrison Chase]]></dc:creator><pubDate>Tue, 07 Oct 2025 16:38:16 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/10/Visual__Agent_Builder_Template_Assets.webp" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/10/Visual__Agent_Builder_Template_Assets.webp" alt="Not Another Workflow Builder"><p><em>By Harrison Chase</em></p><p>One of the most common requests we&#x2019;ve gotten from day zero of LangChain has been a visual workflow builder. We never pursued it and instead let others (LangFlow, Flowise, n8n) build on top of us. With OpenAI launching a <a href="https://openai.com/index/introducing-agentkit/?ref=blog.langchain.com">workflow builder</a> at Dev Day yesterday, I thought it would be interesting to write about why we haven&#x2019;t built one to date, and what different (but related) directions we are more interested in.</p><h2 id="the-problem-statement">The problem statement</h2><p>First of all, it&#x2019;s worth aligning on the problem statement these no-code workflow builders solve. The main motivation is to allow non-technical users to build agents. There&#x2019;s two main reasons people are interested in this:</p><ol><li>Many companies are more resource constrained on engineering talent than others</li><li>Non-technical users are the ones who know what agents to build / what they should do</li></ol><p>We occasionally see other motivations, like allowing technical users to quickly prototype agents that will get ported into code later. But for the purpose of this blog let&#x2019;s assume that the motivation is to enable everyone in an organization to build their own apps and widgets without support from engineering.</p><h2 id="workflows-vs-agents">Workflows vs agents</h2><p>Two words which I&#x2019;ve used intentionally above are &#x201C;workflows&#x201D; and &#x201C;agents&#x201D;. We&#x2019;ve written about this before - actually in a blog post <a href="https://blog.langchain.com/how-to-think-about-agent-frameworks/">arguing for workflows</a> (ironically, in response to an OpenAI article arguing against workflows).</p><p>The developer community has largely settled on the <a href="https://simonwillison.net/2025/Sep/18/agents/?ref=blog.langchain.com">following definition of an agent</a>:</p><div class="kg-card kg-callout-card kg-callout-card-blue"><div class="kg-callout-emoji">&#x1F4A1;</div><div class="kg-callout-text">An LLM agent runs tools in a loop to achieve a goal.</div></div><p>Workflows give you more predictability at the expense of autonomy, while agents give you more autonomy at the expense of predictability. <strong>Notably, when building agentic systems we are in pursuit of <em>reliably good</em> outcomes, which neither predictability or autonomy alone guarantee.</strong></p><p>Workflows are often complicated - branching logic, parallel edges, many different paths. This complexity is represented in the &#x201C;graph&#x201D; of the workflow, which is represented in some DSL.</p><p>Agents can also contain complicated logic, but by contrast all that logic is abstracted away into natural language, which goes into the prompt. So the overall structure of an agent is simple (just a prompt + tools), though that &#x201C;prompt&#x201D; can often times be pretty complex.</p><p>OpenAI&#x2019;s AgentKit - and n8n, Flowise, LangFlow - are all visual <strong>workflow</strong> builders - not <em>agent</em> builders.</p><h2 id="the-issue-with-visual-workflow-builders">The issue with visual workflow builders</h2><p>So, with all that context, what is the problem with workflow builders:</p><p><strong>1.Visual workflow builders are not &#x201C;low&#x201D; barrier to entry.</strong></p><p>Despite being built for a mass audience, it is still not easy for the average non-technical user to use them.</p><p><strong>2.Complex tasks quickly get too complicated to manage in a visual builder.</strong></p><p>As soon as they pass a certain level of complexity (which happens pretty quickly) you end up with a mess of nodes and edges that you need to manage in the UI.</p><h2 id="other-alternatives">Other alternatives</h2><p>The goal is to create LLM powered systems (whether workflows or agents) that are <em>reliably good</em>. There are different types of problems that people may want to solve with LLM powered systems - ranging anywhere from low complexity to high complexity. The best alternative may depend on the level of complexity.</p><p><strong>High Complexity: Workflows in Code</strong></p><p>For high complexity problems, we&#x2019;ve found that in order to achieve a certain level of reliability the systems are not just pure agents, but rather involve some aspect of a workflow. These high complexity problems often require complex workflows. In these scenarios, where you want lots of branching, parallelism and modularity, code is the best option (<a href="https://github.com/langchain-ai/langgraph?ref=blog.langchain.com">LangGraph</a> is designed for this).</p><p>Traditionally this would mean that these types of problems just aren&#x2019;t actually solvable by a non-technical builder. As the cost of code generation goes to zero, however, we expect that more and builders will find themselves capable of building these solutions.</p><p><strong>Low Complexity: No-Code Agents</strong></p><p>For lower complexity use cases, I would assert that simple agents (prompt + tools) are getting reliably good enough to solve these use cases. Building these agents in a no-code way should be simpler than building a workflow in a no-code way.</p><p>As models get better and better, I would expect the ceiling of the type of problems these agents can solve to get higher and higher.</p><h2 id="the-squeeze">The squeeze</h2><p>The issue with no code workflow builders are that I think they are getting squeezed from both directions.</p>
<!--kg-card-begin: html-->
<table>
<thead>
<tr>
<th>Complexity Level</th>
<th>Best Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td>Low</td>
<td>No-Code Agent</td>
</tr>
<tr>
<td>Medium</td>
<td>No-Code Workflow</td>
</tr>
<tr>
<td>High</td>
<td>Workflow in Code</td>
</tr>
</tbody>
</table>
<!--kg-card-end: html-->
<p>I think agents (prompt + tools) should be strictly easier to create in a no-code way than workflows. I expect models, agent harnesses, and our interfaces for creating, modifying, and <em>teaching</em> these agents to get better. This means that these agents will be <em>reliably good</em> at more and more tasks.</p><p>In the other direction, visual workflow builders become unmanageable for a certain level of complexity. The only real alternative to that is code. Writing code has historically been limited to a small set of people, with the barrier to entry being pretty high. As models get better and better at code generation, and the cost of code generation goes to zero, I expect the decision to go to code becomes easier and easier.</p><h2 id="the-interesting-problems">The interesting problems</h2><p>To be very clear - there are companies that have done a fantastic job at democratizing LLM powered workflow builders (n8n, Flowise, LangFlow, Gumloop, etc). Many of them have found product-market fit - they solve a real problem that exists today and empower non-technical users to build fantastic things.</p><p>I do not think the world needs yet another workflow builder. Rather, I think the interesting problems to solve next are:</p><ul><li>How can we make it easier to create <em>reliably good</em> agents in a no-code way. These should be agents! Not low code workflows.</li><li>How can we make code generation models better at writing LLM powered workflows/agents</li></ul>]]></content:encoded></item><item><title><![CDATA[How to turn Claude Code into a domain specific coding agent]]></title><description><![CDATA[<p>Authored by: <a href="https://www.linkedin.com/in/aliyan-ishfaq/?ref=blog.langchain.com">Aliyan Ishfaq</a></p><p>Coding agents are great at writing code that uses popular libraries on which LLMs have been heavily trained on. But point them to a custom library, a new version of a library, an internal API, or a niche framework &#x2013; and they&#x2019;re not so</p>]]></description><link>https://blog.langchain.com/how-to-turn-claude-code-into-a-domain-specific-coding-agent/</link><guid isPermaLink="false">68bf37c0c3c55900012a78cd</guid><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Thu, 11 Sep 2025 16:54:37 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/09/data-src-image-b697b2db-65af-4c18-bc16-acf5abf0738b-1.png" medium="image"/><content:encoded><![CDATA[<img src="https://blog.langchain.com/content/images/2025/09/data-src-image-b697b2db-65af-4c18-bc16-acf5abf0738b-1.png" alt="How to turn Claude Code into a domain specific coding agent"><p>Authored by: <a href="https://www.linkedin.com/in/aliyan-ishfaq/?ref=blog.langchain.com">Aliyan Ishfaq</a></p><p>Coding agents are great at writing code that uses popular libraries on which LLMs have been heavily trained on. But point them to a custom library, a new version of a library, an internal API, or a niche framework &#x2013; and they&#x2019;re not so great. That&#x2019;s a problem for teams working with domain specific libraries or enterprise code. </p><p>As developers of libraries (LangGraph, LangChain) we are really interested in how to get these coding agents to be really good at writing LangGraph and LangChain code. We tried a bunch of context engineering techniques. Some worked, some didn&#x2019;t. In this blog post we will share the experiments we ran and learnings we had. Our biggest takeaway:&#xA0;</p><p><strong>High quality, condensed information combined with tools to access more details as needed produced the best results</strong></p><p>Giving the agent raw documentation access didn&#x2019;t improve performance as much as we hoped. In fact, the context window filled up faster. A concise, structured guide in the form of <code>Claude.md</code> always outperformed simply wiring in documentation tools. The best results came from combining the two, where the agent has some base knowledge (via <code>Claude.md</code>) but can also access specific parts of the docs if it needs more info.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-b697b2db-65af-4c18-bc16-acf5abf0738b-2.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1585" height="1081" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-b697b2db-65af-4c18-bc16-acf5abf0738b-2.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-b697b2db-65af-4c18-bc16-acf5abf0738b-2.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-b697b2db-65af-4c18-bc16-acf5abf0738b-2.png 1585w" sizes="(min-width: 720px) 720px"></figure><p>In this post, we&#x2019;ll share:</p><ul><li>The different Claude Code configurations we tested</li><li>The evaluation framework we used to to assess the generated code (a template you can reuse for your own libraries)</li><li>Results and key takeaways</li></ul><h2 id="claude-code-setups"><strong>Claude Code Setups</strong></h2><p>We tested four different configurations, using Claude 4 Sonnet as the model for consistency:</p><p><strong>Claude Vanilla:</strong> Out-of-the-box Claude Code with no modifications.</p><p><strong>Claude + MCP:</strong> Claude Code connected to our <a href="https://github.com/langchain-ai/mcpdoc?ref=blog.langchain.com"><u>MCPDoc</u></a> server for documentation access.</p><p><strong>Claude + Claude.md:</strong> Claude Code with a detailed <code>Claude.md</code> file containing LangGraph-specific guidance.</p><p><strong>Claude + MCP + Claude.md:</strong> Claude with access to detailed <code>Claude.md</code> and MCPDoc server.</p><h3 id="mcp-tool-for-documentation">MCP tool for documentation</h3><p>We built the MCPDoc server because we wanted to provide coding agents with access to any library&#x2019;s documentation. It is an open-source MCP server that exposes two tools: <code>list_doc_sources</code> and <code>fetch_docs</code>. The first shares the URLs of available <code>llms.txt</code> files, and the latter reads a specific <code>llms.txt</code> file. In our setup, we provided access to LangGraph and LangChain Python and JavaScript documentation. You can easily adapt this for your use case by passing in the URLs of your library&apos;s <code>llms.txt</code> files in the MCP config.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-9697d322-41ec-4727-ac9f-156632ed0156.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1562" height="829" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-9697d322-41ec-4727-ac9f-156632ed0156.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-9697d322-41ec-4727-ac9f-156632ed0156.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-9697d322-41ec-4727-ac9f-156632ed0156.png 1562w" sizes="(min-width: 720px) 720px"></figure><h3 id="claudemd">Claude.md</h3><p>For <code>Claude.md</code>, we created a LangGraph library guide. It included detailed instructions for common LangGraph project structure requirements, like mandatory codebase searching before creating files, proper export patterns, and deployment best practices. It included sample code for primitives required for building both single and multi-agent systems, things like <code>create_react_agent</code>, supervisor patterns, and swarm patterns for dynamic handoffs. There were certain implementations that LLMs were struggling with like streaming and human-in-the-loop for user-facing agents. We added extensive guidelines for these.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-09e78c9b-265a-41cf-83a3-504c43bf9ca8.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1000" height="1591" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-09e78c9b-265a-41cf-83a3-504c43bf9ca8.png 600w, https://blog.langchain.com/content/images/2025/09/data-src-image-09e78c9b-265a-41cf-83a3-504c43bf9ca8.png 1000w" sizes="(min-width: 720px) 720px"></figure><p>We found it particularly valuable to include comprehensive sections on common pitfalls and anti-patterns. This covered common mistakes like incorrect <code>interrupt()</code> usage, wrong state update patterns, type assumption errors, and overly complex implementations. These were mistakes we frequently saw LLMs make, either due to deprecated libraries or confusion with patterns from other frameworks.</p><p>We also included LangGraph-specific coding standards like structured output validation, proper message handling, and other framework integration debugging patterns. Since Claude has access to web tools, we added specific documentation URLs at the end of each section for further reference and navigation guidelines.</p><p>The way this file differs from <code>llms.txt</code> is that the former is a plain text file of all the content of a page with URLs while this includes condensed information that is most important when starting from scratch. As we&apos;ll see in the results, when <code>llms.txt</code> is passed alone, it is not most effective as it sometimes confuses LLMs with more context and no instructions on how to navigate and discern what&apos;s important.</p><p>Before going into how our Claude Code configurations performed across different tasks, we want to share our evaluation framework that we used to determine task fulfillment and code quality.&#xA0;</p><h2 id="evaluations"><strong>Evaluations</strong></h2><p>Our goal was to measure what contributes most to code quality, not just functionality. Popular metrics like Pass@k capture functionality and not best practices, which varies by context.</p><p>We built a task-specific evaluation harness that checks both technical requirements and subjective aspects such as code quality, design choices, and adherence to preferred methods.</p><p>We define three categories for our evaluation:</p><p><strong>Smoke Tests</strong></p><p>These verify basic functionality. Tests confirm that the code compiles, exposes the <code>.invoke()</code> method, handles expected input states, and returns expected output structures like <code>AIMessage</code> objects with required state properties.</p><p>We calculate scores using weighted summation:</p><p>Score = &#x3A3;&#x1D62; w&#x1D62; &#xD7; c&#x1D62;</p><p>&#xA0;where <em>wi</em> is the weight of of test <em>i </em>and <em>ci</em> is the binary result of a test.</p><p><strong>Task Requirement Tests</strong></p><p>These verify task specific functionality. Tests include validation of deployment configuration files, verification of HTTP requests to external APIs such as web search or LLM providers, and unit tests specific to each coding task. Scoring is done through weighted summation of each test result, same as smoke tests.&#xA0;&#xA0;</p><p><strong>Code Quality &amp; Implementation Evaluation</strong></p><p>For this category, we use LLM-as-a-Judge to capture what binary tests miss. Implementations that follow better approaches should score higher than those that simply compile and run. Code quality, design choices, and use of LangGraph abstractions all require nuanced evaluation.</p><p>We reviewed expert written code for each task and built task specific rubrics. Using Claude Sonnet 4 (<code>claude-sonnet-4-20250514</code>) at temperature 0, we evaluated generated code against these rubrics, using expert-written code as the reference and human annotations to log compilation and runtime errors.</p><p>Our rubric had two types of criteria:</p><p><strong>Objective Checks: </strong>These are binary facts about the code (e.g. presence of specific nodes, correct graph structure, module separation, absence of test files). The LLM judge returned a boolean response for each check and we used weighted summation, same as smoke tests, to get a score for objective checks.</p><p><strong>Subjective Assessment: </strong>This is qualitative evaluation of the code using expert-written code as reference and human annotation for passing in logs of compilation and runtime errors. LLM judge identified issues and categorized them by severity (critical, major, minor) across two dimensions: correctness violations and quality concerns.</p><p>We use penalty-based scoring for this:</p><p>Score = Score&#x2098;&#x2090;&#x2093; - &#x3A3;&#x209B; (n&#x209B; &#xD7; p&#x209B;)</p><p>where Score<em>max</em> is the maximum possible score, <em>ns</em> is the number of violations at severity <em>s</em> and <em>ps</em> is the penalty weight for that severity.&#xA0;</p><p>The overall score, combining both objective and subjective results, is given as:</p><p>Score = &#x3A3;&#x1D62; w&#x1D62; &#xD7; c&#x1D62; + &#x3A3;&#x209B; (Score&#x2098;&#x2090;&#x2093;,&#x209B; - &#x3A3;&#x209B; (n&#x209B; &#xD7; p&#x209B;))</p><p>where the first term represents objective checks and the second term represents assessments across all subjective categories.</p><p>We ran each Claude Code configuration three times per task to account for variance. For consistency, all scores are reported as percentages of total possible points and then averaged across tasks.</p><p>You can replicate this approach for your own libraries using the <a href="https://www.langchain.com/langsmith?ref=blog.langchain.com"><u>LangSmith </u></a>platform to compare coding agent configurations.</p><h2 id="results"><strong>Results</strong></h2><p>We average scores across three different LangGraph tasks to compare Claude Code configurations. The chart below shows overall scores:</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-df74c028-52d3-4ec5-967c-f7fbbe4ec761.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1585" height="1081" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-df74c028-52d3-4ec5-967c-f7fbbe4ec761.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-df74c028-52d3-4ec5-967c-f7fbbe4ec761.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-df74c028-52d3-4ec5-967c-f7fbbe4ec761.png 1585w" sizes="(min-width: 720px) 720px"></figure><p>The most interesting finding for us is that Claude + <code>Claude.md</code> outperformed Claude + MCP, even though <code>Claude.md</code> only included a subset of what the MCP server could provide. Traces explained why: Claude didn&#x2019;t invoke MCP tools as much as we&#x2019;d expected. Even when a task required following two or three linked pages, it typically called MCP once and stopped at the main page,&#xA0; which only gave surface-level descriptions, not the details needed.</p><p>By contrast, Claude + <code>Claude.md</code> + MCP used the docs more effectively. We observed in traces that it called MCP tools more frequently and even triggered web search tool when required. This behavior was driven by <code>Claude.md</code> that included reference URLs at the end of each section to look for further information.</p><p>This doesn&#x2019;t mean MCP tools didn&#x2019;t help on their own. They improved scores by ~10 percentage points, mainly by grounding the agent in basic syntax and concepts. But for task completion and code quality, <code>Claude.md</code> was more important. The guide included pitfalls to avoid and principles to follow, which helped Claude Code think better and explore different parts of the library rather than stopping at high-level descriptions.</p><p>These results point to a few broader lessons for anyone configuring coding agents.</p><h2 id="key-takeaways"><strong>Key Takeaways</strong></h2><p>The results leave us with a few takeaways. If you&#x2019;re thinking about customizing coding agents for your own libraries, the following can be useful:</p><p><strong>Context Overload: </strong>Dumping large <code>llms.txt</code> files from documentation can crowd the context window. This can lead to poor performance and higher cost. Our MCP server has a naive implementation of fetching page contents completely. Even invoking it once flagged Claude Code warnings of context window filling up. If your documentation is extensive enough that you need tooling to retrieve specific docs, it&#x2019;s worth building smarter retrieval tooling that pulls only the relevant snippets.</p><p><strong>Claude.md has the highest payoff: </strong>It&#x2019;s easier to set up than an MCP server or specific tooling and cheaper to run. On task #2, Claude + <code>Claude.md</code> was ~2.5x cheaper than Claude MCP and Claude + <code>Claude.md</code> + MCP. It&#x2019;s cheaper than Claude MCP and performs better. This is a great starting point when thinking of customizing Claude Code and may just be good enough for some use cases.</p><p><strong>Write good instructions</strong>.&#xA0; A <code>Claude.md</code> (or <code>Agents.md</code>) should highlight core concepts, unique functionality, and common primitives in your library. Review failed runs manually to find recurring pitfalls and add guidance for them. For us, that meant covering async tasks in LangGraph with Streamlit, where agents often failed on <code>asyncio</code> integration. We also added debugging steps for spinning up dev servers, which fixed import errors and let Claude Code send requests to the server to verify outputs. Popular code-gen tools often use long system prompts (7&#x2013;10k tokens). Putting effort into instructions pays off pretty well.</p><p><strong>Claude + </strong><a href="http://claude.md/?ref=blog.langchain.com"><strong><u>Claude.md</u></strong></a><strong> + MCP wins</strong>: While <code>Claude.md</code> provides the most mileage per token, the strongest results came from pairing it with an MCP server that allows it to read documentation in detail. The guide provided orientation with concepts and the docs helped go in-depth. Together, they can produce best results on domain specific libraries.</p><p>In the Appendix, we include per-task results and category-level graphs for readers who want to dig into per task performance.</p><h2 id="appendix"><strong>Appendix</strong></h2><p><strong>Task #1: Text-to-SQL Agent</strong></p><p>We asked each configuration to build a LangGraph-based text-to-SQL agent that could generate SQL query from natural language, execute it against a database, and return a natural language response. This task required fetching the Chinook SQLite database from a remote URL and setting up an in-memory database. You can read the prompt that we passed to Claude Code instances <a href="https://github.com/langchain-ai/claude-code-evals/blob/main/task_1/input_prompt.py?ref=blog.langchain.com"><u>here</u></a>.</p><p>For this task, our smoke tests verified basic LangGraph functionality. Task requirements checked database setup; SQL query handling for simple queries, join queries, date range queries; and LLM-as-a-Judge evaluated code design choices such as remote URL fetching, separate nodes for SQL generation, execution, and response. The LLM-as-a-Judge prompt is available <a href="https://github.com/langchain-ai/claude-code-evals/blob/main/task_1/llm_as_a_judge.py?ref=blog.langchain.com"><u>here</u></a>.&#xA0;</p><p>The results show performance difference across Claude Code configurations and categories:</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-315dba51-fde9-42f1-b588-1f3d377ca357.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1600" height="872" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-315dba51-fde9-42f1-b588-1f3d377ca357.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-315dba51-fde9-42f1-b588-1f3d377ca357.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-315dba51-fde9-42f1-b588-1f3d377ca357.png 1600w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-e7f3c295-b9ec-4010-9153-df0569c822c3.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1600" height="872" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-e7f3c295-b9ec-4010-9153-df0569c822c3.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-e7f3c295-b9ec-4010-9153-df0569c822c3.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-e7f3c295-b9ec-4010-9153-df0569c822c3.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>Poor implementations typically struggled with connecting in-memory database across threads, downloaded and hardcoded schemas in LLM prompts instead of using remote URLs with runtime schema reading, and failed to properly parse LLM output for SQL execution (breaking when LLM would generate slightly different formatted results).</p><p><strong>Task #2: Company Researcher</strong></p><p>For this task, we asked each Claude configuration to build a multi-node LangGraph agent that researches companies using web search through <a href="https://www.tavily.com/?ref=blog.langchain.com"><u>Tavily API</u></a>. The agent needed to handle structured data collection, implement parallel search execution, and add a reflection step that ensures all requested information is gathered. You can read the prompt <a href="https://github.com/langchain-ai/claude-code-evals/blob/main/task_2/input_prompt.py?ref=blog.langchain.com"><u>here</u></a>.</p><p>Our tests verified basic functionality, Tavily API integration, and presence of all requested properties in the structured object class. <a href="https://github.com/langchain-ai/claude-code-evals/blob/main/task_2/llm_as_a_judge.py?ref=blog.langchain.com"><u>LLM-as-a-Judge</u></a> checked for implementation of features like reflection logic, minimum search query limits, and parallel web search execution.</p><p>&#xA0;The following are the results for this task:</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-ce1e445e-7ce6-4107-bcb2-9fe290c7bc38.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1600" height="869" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-ce1e445e-7ce6-4107-bcb2-9fe290c7bc38.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-ce1e445e-7ce6-4107-bcb2-9fe290c7bc38.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-ce1e445e-7ce6-4107-bcb2-9fe290c7bc38.png 1600w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-50ad8813-7225-48f1-8d60-ccc8108b7ad8.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1600" height="858" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-50ad8813-7225-48f1-8d60-ccc8108b7ad8.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-50ad8813-7225-48f1-8d60-ccc8108b7ad8.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-50ad8813-7225-48f1-8d60-ccc8108b7ad8.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>Most implementation failures were related to structuring information in an object in state and reflection step. Poor implementations either didn&#x2019;t have functional reflection nodes or failed to trigger additional searches.</p><p><strong>Task #3: Categories of Memories</strong></p><p>This was an editing task where we provided each Claude Code configuration with an existing memory agent as base code. We asked them to extend the memory storage method to categorize memory by type (personal, professional, other) in addition to user ID, implement selective memory retrieval based on message category instead of just user ID, and add human in the loop confirmation step before saving memories. We deliberately added syntax errors as well. The full prompt is available <a href="https://github.com/langchain-ai/claude-code-evals/blob/main/task_3/input_prompt.py?ref=blog.langchain.com"><u>here</u></a>.</p><p>With tests we verified that implementations correctly added the interrupt functionality before memory storage, implemented category-wise storage and retrieval, used three specific categories (personal, professional, other), and maintained functional interrupt logic that saves memories only when users accept. <a href="https://github.com/langchain-ai/claude-code-evals/blob/main/task_3/llm_as_a_judge.py?ref=blog.langchain.com"><u>LLM-as-a-Judge</u></a> evaluated whether implementations used LLM-based categorization rather than brittle keyword matching and unnecessary files.</p><p>For an editing task, we see following results:</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-1f834f44-13e8-4e8f-babe-dd628059697c.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1600" height="889" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-1f834f44-13e8-4e8f-babe-dd628059697c.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-1f834f44-13e8-4e8f-babe-dd628059697c.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-1f834f44-13e8-4e8f-babe-dd628059697c.png 1600w" sizes="(min-width: 720px) 720px"></figure><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-ac38b764-fa34-4d87-bafe-193b8a4725a0.png" class="kg-image" alt="How to turn Claude Code into a domain specific coding agent" loading="lazy" width="1600" height="853" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-ac38b764-fa34-4d87-bafe-193b8a4725a0.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-ac38b764-fa34-4d87-bafe-193b8a4725a0.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-ac38b764-fa34-4d87-bafe-193b8a4725a0.png 1600w" sizes="(min-width: 720px) 720px"></figure><p>Most implementations struggled with correctly implementing interrupt functionality. Wrong implementations either added simple <code>input()</code> calls to get terminal input or overcomplicated the solution by creating separate nodes instead of using a few lines of proper interrupt logic. Poor implementations also relied on keyword matching for categorization instead of LLM-based classification, and almost all failed to catch the deliberate syntax errors we included.</p>]]></content:encoded></item><item><title><![CDATA[Monte Carlo: Building Data + AI Observability Agents with LangGraph and LangSmith]]></title><description><![CDATA[See how Monte Carlo built its AI Troubleshooting Agent on LangGraph and debugged with LangSmith to help data teams resolve issues faster]]></description><link>https://blog.langchain.com/customers-monte-carlo/</link><guid isPermaLink="false">68c1959f2cb313000119b048</guid><category><![CDATA[Case Studies]]></category><dc:creator><![CDATA[LangChain]]></dc:creator><pubDate>Thu, 11 Sep 2025 04:30:49 GMT</pubDate><media:content url="https://blog.langchain.com/content/images/2025/09/Monte-Carlo-case-study.png" medium="image"/><content:encoded><![CDATA[<figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-dd30ebdc-8c0a-4c5a-9060-1e2d8ccbf975.png" class="kg-image" alt="Monte Carlo: Building Data + AI Observability Agents with LangGraph and LangSmith" loading="lazy" width="1600" height="1085" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-dd30ebdc-8c0a-4c5a-9060-1e2d8ccbf975.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-dd30ebdc-8c0a-4c5a-9060-1e2d8ccbf975.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-dd30ebdc-8c0a-4c5a-9060-1e2d8ccbf975.png 1600w" sizes="(min-width: 720px) 720px"><figcaption><span style="white-space: pre-wrap;">A high-level overview of Monte Carlo&#x2019;s </span><a href="https://www.montecarlodata.com/platform/observability-agents?ref=blog.langchain.com"><u><span class="underline" style="white-space: pre-wrap;">Troubleshooting Agent</span></u></a><span style="white-space: pre-wrap;"> architecture</span></figcaption></figure><img src="https://blog.langchain.com/content/images/2025/09/Monte-Carlo-case-study.png" alt="Monte Carlo: Building Data + AI Observability Agents with LangGraph and LangSmith"><p><a href="https://www.montecarlodata.com/?ref=blog.langchain.com"><strong><u>Monte Carlo</u></strong></a> is a leading data + AI observability platform for enterprises, helping organizations monitor data and AI reliability issues, and trace them back to their root causes. After years of building sophisticated data monitoring and troubleshooting tools, Monte Carlo realized they had been unknowingly building the foundation for what would become their flagship AI agent&#x2014; a system that can launch hundreds of sub-agents to investigate data issues and accelerate root cause analysis in a compelling, actionable way.</p><h2 id="automating-data-pipeline-troubleshooting-at-enterprise-scale"><strong>Automating data pipeline troubleshooting at enterprise scale</strong></h2><p>Data engineers at enterprise organizations spend countless hours manually troubleshooting data alerts&#x2014;investigating failed jobs, tracking down code changes, and determining whether issues require immediate resolution or can be deprioritized. This manual process forces engineers to follow single investigation paths sequentially, often missing parallel issues or taking too long to identify root causes in complex, interconnected data systems.</p><p>Monte Carlo&apos;s customers are primarily large enterprises where data drives significant revenue. For these customers, <strong>data that remains incorrect or unavailable can affect millions of dollars of business</strong>. While Monte Carlo had built comprehensive troubleshooting tools, they identified an opportunity to further reduce this &#x201C;data downtime:&#x201D; have AI agents process and reason through hundreds of hypotheses concurrently to accelerate data + AI team&#x2019;s ability to quickly spot and fix the root cause behind specific data quality incidents.&#xA0;</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/09/data-src-image-5f2b6d8f-dd02-4bc0-af6b-242a7289c03d.png" class="kg-image" alt="Monte Carlo: Building Data + AI Observability Agents with LangGraph and LangSmith" loading="lazy" width="1600" height="900" srcset="https://blog.langchain.com/content/images/size/w600/2025/09/data-src-image-5f2b6d8f-dd02-4bc0-af6b-242a7289c03d.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/09/data-src-image-5f2b6d8f-dd02-4bc0-af6b-242a7289c03d.png 1000w, https://blog.langchain.com/content/images/2025/09/data-src-image-5f2b6d8f-dd02-4bc0-af6b-242a7289c03d.png 1600w" sizes="(min-width: 720px) 720px"></figure><h2 id="troubleshooting-multi-paths-with-langgraph"><strong>Troubleshooting multi-paths with LangGraph</strong></h2><p>Monte Carlo chose <strong>LangGraph</strong> as the foundation for their AI Troubleshooting Agent because their investigation process naturally mapped to a graph-based decision-making flow. When an alert is triggered, their system follows a structured troubleshooting methodology that mirrors how experienced data engineers approach problems, but at scale.</p><p>Alert &#x2192; Check Code Changes &#x2192; Analyze Timeline &#x2192; Investigate Dependencies &#x2192; Report Findings</p><p>Their LangGraph implementation starts with an alert and creates a dynamic graph of investigation nodes. Each node can spawn sub-nodes based on findings, allowing the agent to:</p><ul><li>Check for code changes in the past 7 days</li><li>Narrow down to changes affecting the specific data pipeline</li><li>Look at events occurring hours before the issue</li><li>Investigate multiple potential root causes simultaneously</li></ul><p><strong>The key advantage</strong>: While human troubleshooters follow one path at a time, Monte Carlo&apos;s agent can explore multiple investigation branches in parallel, checking significantly more scenarios than any individual data engineer could handle manually.</p><p>Monte Carlo&apos;s Product Manager, Bryce Heltzel, notes that LangGraph&apos;s value was in achieving speed to market. With a tight 4-week deadline ahead of major industry summits, the team felt confident demonstrating their agent to customers&#x2014; something that wouldn&apos;t have been possible with a custom-built solution.</p><h2 id="debugging-with-langsmith"><strong>Debugging with LangSmith</strong></h2><p>Monte Carlo started debugging using LangSmith on day one of development. As Heltzel explains, &quot;LangSmith was a natural choice as we started building our agent in LangGraph. We wanted LangSmith to visualize what we were developing for our graph-based workflows.&quot;</p><p>As a product manager, Heltzel is very involved in the process of prompt engineering for their agents. With his deep context about customer use cases, he can now iterate quickly on prompts directly rather than going through engineering cycles.&#xA0;</p><p>The Monte Carlo team has been able to focus on agent logic and solving data issues for customers rather than tooling setup due to the minimal configuration LangSmith required to get up and running.</p><h2 id="monte-carlos-architecture"><strong>Monte Carlo&apos;s architecture</strong></h2><p>This architecture leverages several AWS services to build a scalable, secure, and decoupled system that connects Monte Carlo&#x2019;s existing monolithic platform with its new AI Agent stack. We use&#xA0;<strong>Amazon Bedrock</strong>&#xA0;to empower our agents with the latest foundational models without the need to manage any infrastructure. The&#xA0;<strong>Auth Gateway Lambda</strong>&#xA0;handles authentication as a lightweight, serverless entry point, ensuring secure access without maintaining dedicated servers. The&#xA0;<strong>Monolith Service&#xA0;</strong>continues to serve core APIs (GraphQL and REST) and persists application data in&#xA0;<strong>Amazon RDS</strong>, a managed relational database that provides reliability and automated maintenance. </p><p>On the AI side, the&#xA0;<strong>AI Agent Service</strong>&#xA0;runs on&#xA0;<strong>Amazon ECS Fargate</strong>, which enables containerized microservices to scale automatically without managing underlying infrastructure. Incoming traffic to the AI Agent Service is distributed through a network load balancer (NLB), providing high-performance, low-latency routing across Fargate tasks. Together, these AWS components create a robust system where the legacy monolith and modern AI microservices interoperate efficiently, with secure authentication, resilient data storage, and elastic compute scaling.</p><figure class="kg-card kg-image-card"><img src="https://blog.langchain.com/content/images/2025/10/monte-carlo-aws.png" class="kg-image" alt="Monte Carlo: Building Data + AI Observability Agents with LangGraph and LangSmith" loading="lazy" width="1046" height="961" srcset="https://blog.langchain.com/content/images/size/w600/2025/10/monte-carlo-aws.png 600w, https://blog.langchain.com/content/images/size/w1000/2025/10/monte-carlo-aws.png 1000w, https://blog.langchain.com/content/images/2025/10/monte-carlo-aws.png 1046w" sizes="(min-width: 720px) 720px"></figure><h2 id="whats-next"><strong>What&apos;s next&#xA0;</strong></h2><p>Monte Carlo is currently focused on visibility and validation &#x2014; understanding where bugs occur in their traces and building robust feedback mechanisms to ensure their agent consistently delivers value to customers. They&apos;re working on validation scenarios to measure whether the agent successfully identifies root causes in each investigation.</p><p>Looking ahead, Monte Carlo plans to expand their agent&apos;s capabilities while maintaining the core value proposition: <strong>enabling data teams to resolve issues faster and more comprehensively than ever before</strong>. Their head start in building data + AI observability tools, combined with LangGraph&apos;s flexible architecture and LangSmith&apos;s debugging capabilities, positions them to continue leading the data + AI observability space.</p>]]></content:encoded></item></channel></rss>