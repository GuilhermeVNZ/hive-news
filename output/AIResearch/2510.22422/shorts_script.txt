[VOICEOVER 0:00-0:05] Did you know AI agents working together can create biases that don't exist when they operate alone?
[VISUAL DIRECTION] [Animated text: "AI TEAMS CREATE BIASES" with shocking red alert symbol]
[VOICEOVER 0:05-0:20] As AI rapidly expands into defense, energy management, and media - projected to grow from $47.1 billion in 2024 - understanding group behavior becomes critical.
[VISUAL DIRECTION] [Show rapid montage: defense systems, energy grids, social media platforms with AI icons]
[VOICEOVER 0:20-0:40] Researchers asked: what happens when multiple AI agents interact in naming conventions like {man, woman}, {straight, gay}, {American, Mexican}?
[VISUAL DIRECTION] [Animated word pairs flashing with question marks between them]
[VOICEOVER 0:40-1:00] The discovery: AI not only amplified existing biases but created new ones that didn't exist before, sometimes even reversing their own preferences.
[VISUAL DIRECTION] [Show graph with bias amplification curves, zoom on unexpected preference reversals]
[VOICEOVER 1:00-1:30] Using four LLM models in coordination games, they found this misalignment emerges specifically from interactions between AI, not individual programming. With 100+ agents, behavior becomes deterministic and unpredictable.
[VISUAL DIRECTION] [Animated network diagram showing AI agents connecting, with bias levels increasing as connections multiply]
[VOICEOVER 1:30-1:50] The International AI Safety Report 2025 already warns about systemic failures in multi-agent systems. Current evaluation practices test individual AI, missing these group dynamics.
[VISUAL DIRECTION] [Show warning symbols and report cover, then transition to real-world deployment scenarios]
[VOICEOVER 1:50-2:00] As AI teams become ubiquitous, we must develop frameworks to predict and control these complex interactions before deployment.
[VISUAL DIRECTION] [Final screen: "AI TEAMWORK = UNEXPECTED BIASES" with paper citation]