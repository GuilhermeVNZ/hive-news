As mobile data demand grows exponentially, network operators face a dual challenge: expanding capacity while reducing environmental impact. A new AI approach tackles this by intelligently managing solar-powered small cells, achieving significant energy savings without compromising service. This breakthrough could help make 5G networks more sustainable and cost-effective.

Researchers developed a distributed deep reinforcement learning (DDRL) system that coordinates virtualized small cells (vSCs) powered by solar energy and batteries. These cells can opportunistically offload baseband processing to a grid-connected server depending on their energy availability. The AI agents learn to minimize both grid energy consumption and dropped traffic by dynamically selecting among three operational modes: switching off, running locally with minimal processing, or handling more functions locally.

The method uses a multi-agent reinforcement learning framework where each vSC acts as an independent AI agent. These agents share specific local information—like battery levels and traffic loads—to coordinate their decisions. Unlike previous approaches that relied on limited shared signals, this exchange of detailed state information helps reduce conflicting behaviors and improves overall system performance. The AI agents employ deep neural networks to approximate Q-values, enabling them to handle large state spaces efficiently without the need for impractical lookup tables.

Numerical results from year-long simulations show that the proposed DDRL controller reduces annual grid energy consumption by up to 61% compared to grid-only powered systems. It also achieves performance close to the optimal offline solution, with only 1–4% higher energy use in residential scenarios and 3–8% in office scenarios. The system maintains low traffic drop rates, often below 1%, ensuring reliable service. Additionally, the AI policies adapt to seasonal changes—selecting more energy-intensive local processing in summer when solar harvest is high and conserving energy in winter.

This AI-driven energy management has direct real-world implications for mobile network operators striving to meet sustainability goals. By leveraging renewable energy and intelligent coordination, networks can lower operational expenditures—saving up to 39% over 10 years—and reduce carbon footprints. The approach is particularly relevant for urban deployments where small cells are densely installed in offices or residential areas, balancing energy use with fluctuating data demands.

The study acknowledges that the proposed solution's effectiveness depends on the number of active vSCs, and adding or removing cells may require retraining agents. Future work could explore methods to make the system more robust to such changes and investigate multi-objective optimizations, like minimizing latency alongside energy and drop rate.