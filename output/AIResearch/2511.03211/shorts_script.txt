[VOICEOVER 0:00-0:05] What if you could challenge unfair algorithms using laws written before they even existed?
[VISUAL DIRECTION] Animated text: "CHALLENGE UNFAIR ALGORITHMS" with question mark pulsing

[VOICEOVER 0:05-0:20] Automated decision-making systems increasingly shape our lives—from welfare fraud detection to predictive policing—yet operate with little accountability.
[VISUAL DIRECTION] Quick cuts: computer screens with algorithmic diagrams, then transition to newspaper headlines about automated systems

[VOICEOVER 0:20-0:40] Researchers asked: How can we hold these systems accountable when regulations lag behind technology?
[VISUAL DIRECTION] Zoom in on legal documents with "ACCOUNTABILITY GAP" highlighted in red

[VOICEOVER 0:40-1:00] They discovered litigators are creatively retrofitting existing legal doctrines—like negligence and confidence—to technological contexts.
[VISUAL DIRECTION] Animated flowchart showing legal doctrines connecting to technology icons

[VOICEOVER 1:00-1:30] This approach forced policymakers to confront real harms. In Australia's Robodebt scandal, the system wrongly accused welfare recipients, leading to a $751 million settlement.
[VISUAL DIRECTION] Show $751,000,000 number growing on screen, then cut to protest footage

[VOICEOVER 1:30-1:50] The research shows this method succeeds where traditional anti-discrimination laws struggle, since algorithms can perpetuate bias without explicit malice.
[VISUAL DIRECTION] Side-by-side comparison: traditional discrimination laws vs algorithmic bias

[VOICEOVER 1:50-2:00] The takeaway? We don't need to wait for new regulations—existing laws can be powerful tools for algorithmic justice now.
[VISUAL DIRECTION] Final screen: "JUSTICE NOW" with paper title "Public -making" appearing below