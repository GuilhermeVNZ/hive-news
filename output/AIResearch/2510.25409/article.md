Large language models struggle with India's most important cultural domains, scoring as low as 34% on traditional medicine questions while excelling in Western-focused benchmarks. This performance gap reveals a critical blind spot in artificial intelligence systems that could limit their real-world utility for billions of people.

The researchers created BhashaBench V1, a comprehensive benchmark testing AI systems across four fundamental pillars of Indian society: agriculture, finance, law, and Ayurveda. The benchmark contains 74,166 question-answer pairs sourced from authentic government and professional examinations, with 29.2% in Hindi and 70.8% in English. This represents the first systematic evaluation of how well AI understands the nuanced cultural and domain-specific knowledge that underpins daily life across the subcontinent.

To build the benchmark, the team developed sophisticated processing pipelines that could handle the complex formatting of examination materials. They used Surya OCR technology, which achieved 98.1% accuracy on English content and 98.9% on Hindi, significantly outperforming alternatives like Tesseract (88.0%) and Google Vision API (96.7%). The questions span 90 subdomains and more than 500 specific topics, covering everything from crop science and financial regulations to traditional medical practices and constitutional law.

When tested across 28 different language models, the results revealed dramatic performance disparities. While GPT-4o achieved 76.49% overall accuracy, it scored only 59.74% in Ayurveda, the traditional Indian medical system. The models showed particular weakness in specialized areas like Panchakarma therapy and agricultural biotechnology. Even the top-performing model, Qwen3-235B-A22B-Instruct, achieved just 34.28% in some Ayurvedic subdomains despite scoring above 80% in business law and financial technology.

The performance gap matters because these AI systems are increasingly deployed in real-world applications affecting millions of people. In agriculture alone, over 100 million Indians rely on farming-related activities, and AI-powered platforms like Krishi Sathi already provide crop advisory services. Similarly, India's legal system processes millions of cases annually, while the healthcare sector serves patients who depend on Ayurvedic practitioners' understanding of ancient texts and treatment protocols.

The benchmark also revealed that model size alone doesn't guarantee cultural competence. While larger models generally performed better, architectural choices and training methodologies significantly influenced domain-specific capabilities. Smaller models optimized for Indian contexts sometimes outperformed larger general-purpose models in specific areas, suggesting that targeted optimization could yield substantial improvements.

However, the study acknowledges limitations in coverage. While the benchmark includes Hindi content, it doesn't capture India's full linguistic diversity across hundreds of dialects. The current version also focuses on formal examination content, which may underrepresent grassroots practices and emerging developments. Future work will need to expand coverage to include regional governance systems, indigenous engineering practices, and vernacular traditions.

For regular readers, these findings highlight that the AI systems powering everything from search engines to virtual assistants may lack crucial cultural understanding. When asking about crop rotation patterns suited to local soil conditions or traditional remedies for common ailments, current AI may provide incomplete or inaccurate information based on Western-centric training data. As AI becomes more integrated into daily life, ensuring it understands local context becomes increasingly critical for reliable performance.