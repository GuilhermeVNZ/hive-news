[VOICEOVER 0:00-0:05] What if emergency drones could explain their life-or-death decisions to human operators in plain language?
[VISUAL DIRECTION] [Animated text: "EMERGENCY DRONE DECISIONS" with question mark pulsing]

[VOICEOVER 0:05-0:20] Current autonomous drones often fail in unpredictable environments because their vision systems can't justify choices—a major safety barrier for certification.
[VISUAL DIRECTION] [Show drone footage struggling with cluttered environment, red X over confused AI decision pathways]

[VOICEOVER 0:20-0:40] Researchers asked: Can we create drones that not only navigate better but also explain their reasoning?
[VISUAL DIRECTION] [Zoom on researcher at computer, animated thought bubbles showing "WHY?" and "HOW?" questions]

[VOICEOVER 0:40-1:00] The breakthrough: EURO SYM AND—a dual-pipeline neuro-symbolic framework that blends AI reasoning with human-readable justifications.
[VISUAL DIRECTION] [Show Figure 2 pipeline diagram with highlighted dual pathways, animated arrows flowing between perception and reasoning modules]

[VOICEOVER 1:00-1:30] Here's how it works: One pipeline processes terrain data using quantized SegFormer-B0, while another applies probabilistic reasoning in Scallop to evaluate options against mission priorities—all while generating explanations.
[VISUAL DIRECTION] [Fast cuts between semantic segmentation visuals, probabilistic scoring animations, and text overlays showing decision justifications forming]

[VOICEOVER 1:30-1:50] Results: 15% increase in minimum obstacle distance, 20% reduction in touchdown error—meaning safer landings with transparent reasoning for emergency responders.
[VISUAL DIRECTION] [Hold on key statistics: "+15% SAFETY" and "-20% ERROR" with comparison graphs from paper]

[VOICEOVER 1:50-2:00] The future of autonomous systems isn't just about better decisions—it's about decisions we can trust and understand.
[VISUAL DIRECTION] [Final shot of drone successfully navigating complex environment with clear decision explanations displayed]