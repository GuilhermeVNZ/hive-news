Artificial intelligence systems designed to monitor wildlife are making critical mistakes that could undermine conservation efforts, according to new research. Scientists found that AI models trained to detect harbor seals in drone imagery frequently confuse the animals with dark rocks and ice patches, raising serious questions about whether these automated systems can be trusted for high-stakes environmental decisions.

The key discovery reveals that even highly accurate AI detectors—achieving 95% precision in identifying seals—rely on superficial visual patterns rather than biological features. When researchers analyzed how these systems make decisions, they found the AI focuses on dark shapes and textures that happen to resemble seals, rather than recognizing actual animal characteristics. This means the technology can be fooled by environmental features that look similar to seals from above.

Researchers used three different explanation methods to understand the AI's decision-making process. They employed gradient-based activation mapping, which creates heatmaps showing where the AI is looking in images; model-agnostic explanations that test how the system responds to modified images; and perturbation-based approaches that systematically remove or alter parts of images to see what changes the AI's confidence. These techniques allowed scientists to literally see what the AI was paying attention to when making its seal identifications.

The data shows concerning patterns. When researchers tested the system on 132 seal detections, they found that masking critical areas—essentially blacking out the parts the AI considered most important—caused detection confidence to drop by 97% in successful cases. However, simply blurring these same areas only reduced confidence by 21%, suggesting the AI relies heavily on coarse visual patterns rather than detailed biological features. In one telling example, the system identified a patch of black ice as a seal with 58% confidence, demonstrating how easily it can be misled by environmental features.

This matters because conservation decisions based on faulty AI detections could have real-world consequences. Overestimating seal populations might divert limited conservation resources away from species truly at risk, while underestimating populations could hide early signs of decline and delay crucial protective actions. The research was conducted in Glacier Bay National Park, where accurate seal monitoring helps scientists understand how climate change affects marine ecosystems.

The study identified several limitations in current AI systems. The models struggle to distinguish seals from dark rock outcrops, particularly when animals are partially obscured or appear in unusual poses. The research also revealed that current explanation methods have their own limitations—they're approximations of the AI's reasoning rather than perfect representations, and different explanation techniques can produce varying results. This means conservation teams still need human oversight to validate AI detections, especially in challenging environmental conditions.

By pairing AI detection with explanation methods, researchers have created a path toward more auditable conservation tools. The findings suggest that future wildlife monitoring systems should incorporate multiple explanation techniques to cross-verify AI decisions and identify when the technology is relying on unreliable shortcuts. This approach moves conservation AI from black-box predictions toward transparent decision-support tools that scientists can understand and trust.