[VOICEOVER 0:00-0:05] Did you know AI bias mitigation techniques fail when transferring from large to small models? This could make your hiring algorithms more unfair.
[VISUAL DIRECTION] Animated text: "AI BIAS INCREASES 12.5%" with red arrow pointing up
[VOICEOVER 0:05-0:20] As AI systems become critical in sensitive areas like hiring and healthcare, ensuring they're fair is essential. But new research reveals a hidden danger in how we make AI models smaller.
[VISUAL DIRECTION] Show split screen: left side "HIRING AI", right side "HEALTHCARE AI" with question marks
[VOICEOVER 0:20-0:40] Researchers investigated whether bias mitigation capabilities—techniques that reduce AI's reliance on spurious correlations—can survive the distillation process where smaller models learn from larger ones.
[VISUAL DIRECTION] Animated diagram showing large "teacher" model transferring to small "student" model with fairness metrics degrading
[VOICEOVER 0:40-1:00] The findings are concerning: overall, bias mitigation capability is undermined during distillation. In language inference and classification tasks, smaller models showed increased susceptibility to biases.
[VISUAL DIRECTION] Show Figure 2 from paper with zoom on performance gaps between teacher and student models
[VOICEOVER 1:00-1:30] Using BERT, T5, ResNet and ViT models, the team found that while accuracy transferred effectively, bias mitigation frequently failed. Internal mechanism analyses showed activation patterns diverged between teachers and students.
[VISUAL DIRECTION] Fast cuts between different model architectures with Centered Kernel Alignment visualizations
[VOICEOVER 1:30-1:50] This matters because we're deploying AI systems in critical applications where fairness is non-negotiable. If bias mitigation doesn't transfer, we risk amplifying discrimination.
[VISUAL DIRECTION] Show real-world application icons: hiring platform, medical diagnosis, loan approval with warning symbols
[VOICEOVER 1:50-2:00] The takeaway: Making AI smaller shouldn't make it more biased. We need new approaches to ensure fairness scales with efficiency.
[VISUAL DIRECTION] Final screen: "FAIR AI AT EVERY SIZE" with Nature/Science journal logos