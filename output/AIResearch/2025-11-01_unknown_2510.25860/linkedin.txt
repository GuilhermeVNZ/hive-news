AI evaluators often miss the nuanced thinking human experts apply. New research reveals how 'thinking traces'—inferring internal reasoning steps—can align AI judgments with human raters, improving consistency in tasks like essay scoring and content moderation. This breakthrough enhances fairness and reliability in automated assessment systems. Read the Nature/Science study to explore how transparent AI reasoning could transform educational and content evaluation.