Optimizing complex systems, from drug discovery to climate modeling, often relies on costly experiments where each test can take days or consume significant resources. Traditional methods require extensive tuning by experts, limiting their accessibility and efficiency. A new study introduces GPTOpt, a method that fine-tunes large language models (LLMs) to tackle these optimization challenges autonomously, showing promise for accelerating scientific and engineering breakthroughs without the need for manual adjustments.

The researchers developed GPTOpt, which equips LLMs with the ability to optimize continuous black-box functions—problems where the relationship between inputs and outputs is unknown and derivatives are unavailable. In tests, GPTOpt outperformed established optimizers like Bayesian optimization (BO) and evolutionary strategies on various benchmarks, achieving better results with fewer evaluations. For instance, on synthetic 5D spaces, it demonstrated superior performance in normalized regret scores, indicating more efficient minimization of objective functions compared to traditional methods.

To train GPTOpt, the team generated a massive dataset of synthetic optimization trajectories using diverse function classes, such as Gaussian processes, random networks, and ordinary differential equations. These functions mimic real-world scenarios with smooth landscapes, nonlinear surfaces, and dynamic behaviors. The data included trajectories from BO variants like LogEI, UCB, and PI, covering dimensions from 2D to 10D. By converting these into text prompts, the researchers fine-tuned a Llama 3B model using low-rank adaptation (LoRA), enabling it to learn from expert-like optimization sequences without real-world data.

Results from the paper show that GPTOpt excels in both in-distribution and out-of-distribution tests. On holdout training data, it consistently surpassed classical optimizers, as illustrated in Figure 2, which plots mean performance over steps. In benchmarks like BBOB and VLSE—standard suites for black-box optimization—GPTOpt maintained robust performance across dimensions from 2D to 10D, outperforming methods such as CMA-ES and PSO in progression curves (Figures 3 and 4). Ablation studies revealed that using top-k trajectories and a temperature of 1.5 during inference optimized results, highlighting the model's adaptability.

This advancement matters because it reduces the reliance on human expertise for tuning optimization parameters, making high-performance optimization accessible in fields like materials science and clinical prognosis where experiments are expensive. For example, in drug development, GPTOpt could streamline the search for molecular compounds by efficiently navigating complex parameter spaces, potentially cutting down research time and costs.

However, the study notes limitations: GPTOpt is currently restricted to continuous, single-objective problems under 10 dimensions, and its performance may degrade on functions far outside its training distribution. Future work could extend it to combinatorial or multi-objective scenarios, and incorporating semantic information might enhance generalizability. Despite these constraints, the method opens avenues for applying LLMs in data-driven decision-making without the overhead of traditional optimization setups.