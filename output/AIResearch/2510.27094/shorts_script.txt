[VOICEOVER 0:00-0:05] Did you know AI's math skills drop sharply when faced with diagrams and tables? [VISUAL DIRECTION] Animated text: 'AI accuracy drops 14-16% with images' flashes on screen with a graph icon.
[VOICEOVER 0:05-0:20] This isn't just a tech quirk—it affects automated tutoring and scientific analysis where visual reasoning is key. [VISUAL DIRECTION] Show quick cuts of students using AI tutors and researchers analyzing data, with text overlay: 'Why it matters: Education & Science'.
[VOICEOVER 0:20-0:40] Researchers asked: How well can AI handle complex math problems with graphs and grids? [VISUAL DIRECTION] Display sample problems from CombiGraph-Vis benchmark, zooming in on combinatorial objects and diagrams.
[VOICEOVER 0:40-1:00] They found AI models scored 75-78% on text-only problems but plummeted on image-based ones, struggling with 35% of tasks involving visuals. [VISUAL DIRECTION] Show a side-by-side comparison: text problem with high score vs. image problem with low score, highlighting the 14-16 point drop.
[VOICEOVER 1:00-1:30] The science: CombiGraph-Vis uses 1,135 rigorous math problems from Olympiad contests, verified for consistency. AI often picks plausible wrong answers, showing superficial pattern recognition. [VISUAL DIRECTION] Animate the two-phase verification workflow, with arrows pointing to 'critic check' and 'error resolution' steps.
[VOICEOVER 1:30-1:50] Implications: For educators, this means AI tools could mislead students; for developers, it's a roadmap to fix reasoning gaps. [VISUAL DIRECTION] Show icons for education (book), development (code), and policy (document), with text: 'Action needed in high-stakes environments'.
[VOICEOVER 1:50-2:00] Remember: AI's visual reasoning flaws are a major bottleneck—addressing them is critical for reliable AI in science and learning. [VISUAL DIRECTION] End with bold text: 'Fix AI's diagram dilemma' and a final zoom on a complex graph from the study.