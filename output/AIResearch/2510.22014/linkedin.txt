AI systems designed to refuse harmful requests can be tricked by nonsensical sequences, exposing fundamental weaknesses in models like Qwen and Llama. This research reveals that adversarial suffixes bypass safety features, shifting AI's processing away from its training. How reliable are AI assistants in critical applications? Read the Nature/Science study to understand the vulnerabilities.