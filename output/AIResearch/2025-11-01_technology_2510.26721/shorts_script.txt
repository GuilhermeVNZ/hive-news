[VOICEOVER 0:00-0:05] Did you know AI systems have a hidden bias, favoring text over images in their decision-making? [VISUAL DIRECTION] Animated text: 'AI Prefers Text Over Images' with bold question mark.
[VOICEOVER 0:05-0:20] This isn't just a quirk—it affects real-world applications like medical diagnostics and autonomous driving, where accurate visual processing is crucial. [VISUAL DIRECTION] Fast cuts of medical scans and self-driving car footage, with overlays highlighting potential errors.
[VOICEOVER 0:20-0:40] Researchers asked: Why do multimodal AIs struggle to integrate text and images effectively? They suspected an architectural flaw. [VISUAL DIRECTION] Zoom on abstract neural network diagram, emphasizing separation points.
[VOICEOVER 0:40-1:00] They discovered that AI's internal representations for text and images remain separate, leading to under-utilization of visual data. [VISUAL DIRECTION] Show Figure 2 from the paper, zooming in on peak distribution of cross-modality divergence metrics.
[VOICEOVER 1:00-1:30] Using models like LLaVA1.5-7B, they found text-image divergence far exceeds text-text variation, proving bias isn't from data but system design. [VISUAL DIRECTION] Animated graphs with overlays: 'Jensen-Shannon Divergence: 0.25 for text-image vs. 0.05 for text-text'.
[VOICEOVER 1:30-1:50] Implications are serious: in security or healthcare, AI might miss visual clues, leading to incorrect judgments. [VISUAL DIRECTION] Hold on split-screen: one side showing correct analysis, the other biased outcome.
[VOICEOVER 1:50-2:00] This study unveils a core AI weakness—demand systems that truly see and read together for safer technology. [VISUAL DIRECTION] Final animated text: 'Fix the Bias, Build Better AI' with paper title overlay.