Understanding why artificial intelligence models make specific decisions has become increasingly crucial as these systems grow more complex and influential. A new approach makes this process significantly more efficient, reducing computational costs by up to 42% while maintaining accuracy. This breakthrough addresses a fundamental challenge in AI transparency: how to explain model behavior without prohibitive resource requirements.

Researchers have developed advanced sampling techniques that enable faster computation of influence functions, which measure how individual training data points affect model predictions. The key finding demonstrates that carefully selected data subsets can provide accurate estimates of these influence values while dramatically reducing computational demands. The logit-based sampling method emerged as particularly effective, achieving comparable accuracy to traditional approaches while requiring substantially fewer resources.

The methodology centers on improving how influence functions estimate the effect of training data on model parameters. Traditional approaches require computing Hessian matrices and gradients across entire datasets, which becomes computationally intensive for large models. The new techniques employ two types of samplers: feature-based methods that select representative data points using clustering and distance metrics, and logit-based methods that use the model's output probabilities to guide selection. These approaches optimize the convergence of the LiSSA algorithm, which approximates the inverse-Hessian-vector products needed for influence calculations.

Experimental results show compelling performance improvements across multiple metrics. The logit-based sampler reduced computation time by 30.1% and memory usage by 42.2% compared to random sampling baselines, while improving F1-score by 2.5%. In tests using Vision Transformer and VGG11 models on CIFAR-10 and MNIST datasets, the method maintained comparable accuracy to traditional approaches while achieving superior consistency, as measured by lower standard deviations across multiple runs. The distance-weighted sampling method also performed well, though slightly less efficiently than the logit-based approach.

This efficiency gain matters because influence functions serve as foundational tools for multiple AI applications. They enable researchers to understand which training examples most affect model behavior, help identify potential biases, support data selection for model improvement, and facilitate responsible AI development. As models grow larger and more complex, the ability to efficiently analyze their inner workings becomes essential for ensuring they align with human values and ethical standards.

The approach does have limitations. The experimental validation focused primarily on computer vision tasks and influence function applications, leaving other potential uses unexplored. The method's performance across different model architectures and domains requires further investigation. Additionally, while the sampling techniques improve efficiency, they still rely on approximations that may not capture all nuances of data influence in extremely complex scenarios.

Future work aims to extend these sampling methods to other computational tasks and develop more effective update rules for the iterative approximation process. The researchers also plan to explore theoretical foundations for the observed performance improvements and validate the approach across a wider range of AI applications. This direction represents an important step toward making AI systems more transparent and interpretable without sacrificing practical utility.