A new method for training artificial intelligence models improves performance by selectively discarding unimportant information, leading to more accurate and efficient learning across language and vision tasks. Researchers from Singapore Management University have developed IBNorm, a technique inspired by the Information Bottleneck principle, which enhances how AI systems process data without adding complexity.

IBNorm outperforms standard normalization methods like BatchNorm and LayerNorm in large language models such as LLaMA and GPT-2, as well as in vision models like ResNet and ViT. For instance, when integrated into LLaMA-1B, it achieved a token-level information bottleneck value of 0.3199 on the LLM Leaderboard I, surpassing LayerNorm by 1.27% and RMSNorm by 9.51%. In image classification, ResNet-50 with IBNorm showed a 3.98% improvement on ImageNet top-1 accuracy compared to BatchNorm.

The approach modifies the normalization step in neural networks by introducing compression operations that reduce variability in activations—the intermediate data representations—while preserving essential information. Unlike existing methods that focus solely on stabilizing variance, IBNorm uses functions like linear, logarithmic, or hyperbolic tangent transforms to suppress task-irrelevant details. This process, controlled by a parameter λ (set to 4 in optimal cases), compresses data toward the mean, increasing sparsity and focusing on predictive features.

Extensive experiments validated IBNorm's effectiveness. In language modeling, it consistently boosted scores on benchmarks, with LLaMA-350M reaching an average score of 0.2140 on LLM Leaderboard II. For vision tasks, ViT models with IBNorm achieved up to 5.29% higher top-1 accuracy on ImageNet. Theoretical analysis confirmed that IBNorm provides tighter generalization bounds, meaning models generalize better to new data by balancing information retention and compression.

This advancement matters because it makes AI training more efficient and robust, potentially reducing computational costs and improving reliability in applications like automated content generation and image recognition. By focusing on relevant data, models become less prone to overfitting and more adaptable, benefiting industries reliant on accurate AI predictions.

Limitations include that the study was conducted on medium-scale models due to computational constraints, and further research is needed to evaluate IBNorm on larger foundation models. The paper does not address potential biases in training data or long-term ethical implications, focusing solely on methodological improvements.