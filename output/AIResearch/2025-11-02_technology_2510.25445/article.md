Artificial intelligence is advancing from passive tools to autonomous agents that plan, remember, and collaborate, but this progress has created confusion. Researchers have identified that modern agentic AI systems are often misdescribed using outdated frameworks, a practice called retrofitting, which obscures their true capabilities and limits effective development. This survey clarifies the field by introducing a novel taxonomy that distinguishes two distinct lineages of agentic AI: the Symbolic/Classical paradigm, which relies on logic and planning, and the Neural/Generative paradigm, built on large language models (LLMs) and prompt-driven orchestration. Understanding this split is crucial because it determines how AI agents perform in real-world applications, from healthcare to finance, impacting their reliability and adaptability.

The key finding from a systematic review of 90 studies (2018â€“2025) is that agentic AI is not a single, evolving technology but comprises two fundamentally different approaches. The Symbolic/Classical lineage, rooted in rules and algorithms like Markov Decision Processes (MDPs), excels in environments requiring high reliability and verifiability, such as clinical decision support in healthcare. In contrast, the Neural/Generative lineage, powered by LLMs and frameworks like LangChain and CrewAI, thrives in adaptive, data-rich settings like financial analysis, where it can handle complex, unstructured tasks through stochastic generation and multi-agent coordination. This division means that the choice of paradigm directly influences an agent's performance, with symbolic systems dominating safety-critical areas and neural systems leading in dynamic, creative domains.

Methodologically, the researchers employed a PRISMA-based systematic review to categorize studies along three dimensions: foundational principles, architectural frameworks, and domain-specific implementations. They analyzed how each paradigm implements core concepts of autonomy and agency, with symbolic agents using deterministic planning and neural agents leveraging LLM orchestration for emergent behavior. For example, in multi-agent systems, symbolic approaches rely on pre-defined protocols like the Contract Net Protocol for coordination, while neural systems use conversation-based mechanisms where an LLM orchestrator dynamically assigns roles and manages workflows. This approach ensured a rigorous, evidence-based comparison without retrofitting modern systems into classical models.

Results from the analysis show a clear paradigm-market fit: symbolic agents are preferred in regulated sectors like healthcare and legal compliance for their transparency and auditability, whereas neural agents dominate in finance and education for their flexibility and context awareness. The review maps these trends across domains, revealing that hybrid architectures, which combine both paradigms, are emerging to balance reliability and adaptability. For instance, in robotics, symbolic components handle low-level safety controls, while neural systems manage high-level coordination. Data from the studies indicate that ethical challenges also diverge by paradigm, with symbolic systems facing issues like bias from hand-coded rules and neural systems grappling with opacity and misalignment from training data.

In terms of context, this paradigm split matters because it guides the development of trustworthy AI for everyday applications. In healthcare, symbolic agents can ensure compliance with regulations like HIPAA by providing traceable decisions, while neural agents in customer service offer personalized interactions. The findings underscore that future AI systems will likely be hybrids, integrating symbolic reasoning for verifiability and neural generation for adaptability, enabling more robust collaborations in fields like scientific discovery and autonomous infrastructure. This strategic approach helps avoid one-size-fits-all policies that could stifle innovation or overlook risks.

Limitations of the survey include its temporal scope, which may miss very recent developments in the fast-evolving field, and methodological heterogeneity among the studies, which limited cross-paradigm benchmarking. Additionally, transparency issues arose with proprietary agent systems, where details on metrics and performance were incomplete. The researchers note that classifying transitional or hybrid agents involved simplifications, highlighting the need for ongoing updates to capture the full landscape of agentic AI advancements.