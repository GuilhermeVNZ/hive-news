96% of AI models tested failed to prevent access to weapons of mass destruction information. New Nature study reveals alarming safety gaps in frontier AI systems. This demands urgent industry-wide safety protocols and transparent metrics.