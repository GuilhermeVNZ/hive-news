As artificial intelligence increasingly governs financial markets, a critical question arises: do AI systems naturally collude to manipulate prices, or can they compete fairly? A new study tackles this by simulating high-frequency trading with diverse AI agents, revealing that competition can thrive without illicit coordination, offering insights for regulators and market stability.

The researchers discovered that AI market makers, when designed with distinct goals, do not inherently collude but instead engage in predictable competitive behaviors. In their experiments, a competitive agent (Agent B2) aggressively captured market share by offering tighter spreads, improving liquidity but reducing overall profitability for others. Meanwhile, a self-interested agent (Agent B1) focused on profit maximization without suppressing rivals, and a hybrid agent (Agent B★) balanced these approaches, securing dominance with less disruption. Key findings show that Agent B2 achieved over 75% market share in zero-sum scenarios, while Agent B★ maintained stable returns without severe adversarial impacts, highlighting that flexible incentives support sustainable coexistence in heterogeneous markets.

To explore these dynamics, the team developed a hierarchical multi-agent system using reinforcement learning, where agents interact in a simulated electronic market. The environment included a top-layer adversary that introduced uncertainty by adjusting order flow and price volatility, a mid-layer market maker (Agent A) trained for robustness, and bottom-layer competitors with varied objectives: profit-seeking (B1), opponent-suppressing (B2), and adaptive (B★). Agents were trained using proximal policy optimization, with the hybrid B★ employing a learnable parameter to modulate between self-interest and suppression, ensuring adaptability without overfitting to local strategies.

Experimental results, detailed in tables and metrics from the paper, demonstrate clear behavioral patterns. For instance, in Agent A–B2 pairings, B2's aggressive quoting led to a 16.2% market share for A versus 83.6% for B2, with B2's average spread at 1.482 compared to A's 2.524. This resulted in a combined PnL of 342.429, lower than A's solo performance of 506.490, indicating that adversarial interactions can degrade overall value. Conversely, in A–B★ interactions, B★ achieved a mean PnL of 285.461 versus A's 172.469, with a market share of 67.0%, showing that adaptive strategies can dominate without extreme suppression. Metrics like joint drawdown ratios and inventory divergence further confirmed that agents operated independently, with low herding and fill overlap, underscoring a lack of collusive behavior.

This research matters because it addresses real-world concerns about AI-driven markets, where unchecked collusion could lead to price manipulation and systemic risks. By showing that AI agents can compete transparently under structured incentives, the study offers a framework for designing ethical algorithmic systems in finance. For everyday investors, this means potential for fairer, more efficient markets where AI enhances liquidity without secret coordination. Regulators could use these interaction-level metrics, such as quote distances and fill overlaps, to monitor for emergent collusion, promoting trust in automated trading environments.

Limitations of the study, as noted in the paper, include the absence of emergent coordination or imitation among agents in the current simulations. The hybrid agent's modulation parameter is tightly coupled to training, which may not generalize to all market conditions. Future work could explore meta-learning for dynamic incentive adaptation, improving robustness across diverse scenarios. Overall, the findings provide a foundational step toward understanding AI behavior in competitive settings, emphasizing that with careful design, markets can benefit from AI without falling into collusive traps.