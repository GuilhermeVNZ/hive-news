[VOICEOVER 0:00-0:05] Did you know only a tiny fraction of AI models actually changes during fine-tuning? We're wasting massive resources on redundant computations.
[VISUAL DIRECTION] Animated text: "95% WASTE?" with exploding server graphics

[VOICEOVER 0:05-0:20] As AI models explode in size, deploying them becomes impossible for smartphones and IoT devices. The energy costs are unsustainable.
[VISUAL DIRECTION] Show smartphone with "AI DENIED" overlay, then transition to power grid straining

[VOICEOVER 0:20-0:40] Researchers asked: Can we compress AI without sacrificing accuracy? The answer lies in the sparse, low-rank nature of fine-tuning updates.
[VISUAL DIRECTION] Zoom on neural network diagram highlighting sparse connections

[VOICEOVER 0:40-1:00] They discovered Optimal Singular Damage - combining low-rank approximation with strategic sparsification to preserve only critical components.
[VISUAL DIRECTION] Show Figure 2 with zoom on performance distribution, highlight OSD peak

[VOICEOVER 1:00-1:30] Two-step process: truncated SVD approximation followed by gradient-based sparsification. OSD dynamically adjusts parameters for optimal trade-offs.
[VISUAL DIRECTION] Animated flowchart showing SVD → Sparsification → Optimization loop

[VOICEOVER 1:30-1:50] Results: OSD outperforms baselines by 9.12% average on RobertaLarge and OPT-1.3b. Enables AI deployment where it was impossible before.
[VISUAL DIRECTION] Bar chart comparison: OSD vs TruncSVD vs MagTruncSVD, highlight performance gap

[VOICEOVER 1:50-2:00] The future of AI isn't bigger models - it's smarter compression. Advanced AI is now sustainable for everyday devices.
[VISUAL DIRECTION] Final shot: smartphone running complex AI with "SUSTAINABLE AI" overlay