[VOICEOVER 0:00-0:05] Did you know AI fails 98.5% of the time when analyzing entire datasets? [VISUAL DIRECTION] Animated text: 'AI FAILS 98.5%' with a red X overlay, fast zoom on a graph showing low accuracy percentages. [VOICEOVER 0:05-0:20] This isn't about simple facts—it's about complex questions like 'Who published the most on AI?' that require sifting through thousands of documents. [VISUAL DIRECTION] Show a rapid montage of documents and data points swirling, with text: 'Complex Queries' highlighted. [VOICEOVER 0:20-0:40] Researchers asked: Why do AI systems stumble on global tasks involving entities, extremes, and rankings? [VISUAL DIRECTION] Display Figure 2 from the paper, zooming in on the distribution of task types like extremum and extraction, with arrows pointing to low scores. [VOICEOVER 0:40-1:00] They found that current RAG methods, including StandardRAG, achieve only 1.51% accuracy on the GlobalQA benchmark. [VISUAL DIRECTION] Animated bar chart comparing 1.51% to a higher target, with text overlays: 'Baseline: 1.51%'. [VOICEOVER 1:00-1:30] The problem? Fixed chunking disrupts document integrity, and retrievers bring noise. Their solution, GlobalRAG, uses document-level retrieval and specialized tools to boost scores by over 5 points. [VISUAL DIRECTION] Split-screen: left shows fragmented documents, right shows integrated retrieval with arrows indicating improvement; include text: 'GlobalRAG: +5.12 points'. [VOICEOVER 1:30-1:50] This means AI could soon handle real-world scientific tasks, like analyzing research papers efficiently, but inconsistencies remain. [VISUAL DIRECTION] Show a scientist at a desk with piles of papers, then a clean digital interface with text: 'Future Research'. [VOICEOVER 1:50-2:00] AI's big weakness is global data analysis—discover how we're fixing it in the Nature/Science paper 'Towards Global Retrieval Augmented Generation: Benchmark'. [VISUAL DIRECTION] End with the paper title in bold text, slow fade to black.