Artificial intelligence systems that process both images and text often struggle to update their knowledge without forgetting or distorting previous information. This limitation becomes critical in real-world applications, such as correcting misidentified public figures or outdated facts, where accuracy and timeliness are essential. A new study introduces a method that mimics the brain's ability to handle continuous updates across different types of data, offering a more reliable way to keep AI models current.

The researchers developed MemEIC, a framework that enables large vision-language models to edit both visual and textual knowledge sequentially and compositionally. They found that MemEIC significantly improves the model's ability to integrate new information while preserving prior knowledge, achieving up to 99% reliability in complex reasoning tasks. For example, in tests involving edits like changing an image label from Boris Johnson to Donald Trump and updating associated textual facts, MemEIC maintained high accuracy across multiple updates, whereas existing methods showed declines of nearly 30% in reliability.

MemEIC uses a hybrid approach combining external memory retrieval with internal parameter editing. It decomposes input queries into visual and textual components, processes them through separate pathways inspired by brain lateralizationâ€”where the left hemisphere handles language and the right processes spatial information. A connector module, analogous to the corpus callosum in the human brain, selectively integrates these pathways only when needed for compositional reasoning. This design prevents interference between modalities and avoids catastrophic forgetting, a common issue in sequential updates.

Results from the Continual and Compositional Knowledge Editing Benchmark (CCKEB) show that MemEIC outperforms baseline methods, with an average reliability of 98.93% on LLaVA-1.5 models and 92.48% on MiniGPT-4. The system's dual-LoRA adapters and brain-inspired connector enable it to handle up to 100 sequential edits with minimal performance drop, addressing real-world needs for incremental updates in areas like news correction and educational tools.

This advancement matters because it enhances the practicality of AI in dynamic environments, such as social media moderation or automated fact-checking, where information evolves rapidly. By ensuring models remain accurate over time without retraining, MemEIC reduces computational costs and improves trust in AI outputs. However, the study notes limitations, including its focus on recognition tasks and untested scalability to larger models, leaving open questions about generalization to generative AI applications.

Broader impacts include potential benefits for misinformation prevention but also risks of misuse for spreading disinformation. The researchers emphasize the need for ethical safeguards and monitoring to mitigate these dangers, ensuring the technology supports reliable and responsible AI deployments.