Artificial intelligence is evolving from passive tools into active partners that can plan, remember, and adapt—but this rapid progress has created confusion about what truly makes an AI "agentic." A new comprehensive survey reveals that agentic AI isn't a single technology but rather two fundamentally different lineages with incompatible approaches to achieving autonomy.

The researchers found that agentic AI divides into two distinct paradigms: Symbolic/Classical systems that rely on logical planning and persistent state, and Neural/Generative systems that leverage stochastic generation and prompt-driven orchestration. This distinction resolves the widespread practice of "retrofitting"—misapplying classical frameworks to describe modern systems built on large language models (LLMs), which operate on completely different principles.

Through a systematic PRISMA-based review of 90 studies from 2018 to 2025, the researchers established a novel dual-paradigm taxonomy that clearly distinguishes these lineages. The methodology involved rigorous database searches across computer science, psychology, and ethics literature, with careful screening to ensure only high-quality, relevant studies were included. The framework organizes agentic AI along two independent dimensions: architectural paradigm and degree of agency coordination.

The analysis reveals a clear strategic division: symbolic systems dominate safety-critical domains like healthcare, where reliability and verifiability are paramount, while neural systems prevail in adaptive, data-rich environments like finance. The survey shows that symbolic agents excel at tasks requiring deterministic behavior and logical soundness, whereas neural agents demonstrate superior performance in contexts requiring flexibility and pattern recognition. This pattern holds across healthcare, finance, robotics, and scientific discovery applications.

The practical implications are significant for how organizations select and deploy AI systems. In healthcare, deterministic symbolic systems handle clinical decision support with predictable outcomes, while in finance, neural orchestration frameworks like CrewAI enable complex market risk modeling through role-based workflows. The choice between paradigms isn't arbitrary but dictated by the specific constraints and requirements of each application domain.

The survey identifies several limitations in current agentic AI development, including a significant deficit in ethical frameworks for neural systems and pressing needs for better evaluation benchmarks. Symbolic systems struggle with brittleness when faced with unanticipated scenarios, while neural systems face challenges with transparency and reliability. Both paradigms require paradigm-specific approaches to safety, security, and human-AI interaction.

Looking forward, the researchers propose that the future lies not in the dominance of one paradigm but in intentional hybridization that creates systems both adaptable and reliable. The most promising direction involves neuro-symbolic integration that couples neural networks' perception capabilities with symbolic engines' reasoning and constraint checking. This approach could overcome the brittleness of pure symbolism while mitigating the opacity of pure neural approaches.