A new artificial intelligence system can play a wide range of video games with human-like skill and adaptability, using the same keyboard and mouse inputs that people do. Game-TARS, developed by researchers at ByteDance, represents a significant step toward creating general-purpose AI agents that can operate across diverse digital environments without specialized programming for each task.

The key finding is that Game-TARS achieves approximately twice the success rate of previous state-of-the-art models on complex tasks in Minecraft and performs competitively with human players on unseen web games. The system demonstrates near-human generalization capabilities, outperforming leading models like GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet on first-person shooter benchmarks and various simulation environments.

The methodology centers on a fundamental shift in how AI agents interact with computers. Instead of relying on application-specific interfaces or high-level commands, Game-TARS uses a unified action space grounded in basic human-computer interaction: mouse movements, mouse clicks, and keyboard presses. This human-native approach allows the system to operate any graphical interface without modification. The researchers trained the model on an unprecedented scale of dataâ€”500 billion tokens from 20,000 hours of computer-use trajectories across gaming, coding, and other domains. A critical innovation is the 'sparse thinking' strategy, where the AI reasons selectively at decision points rather than at every step, balancing depth with computational efficiency.

Results from extensive testing show compelling evidence of the system's capabilities. In open-world Minecraft evaluation, Game-TARS achieved 72% success rates on exploration tasks and 66% on combat scenarios, substantially outperforming specialized Minecraft agents. When tested on completely unseen web games from the Poki platform, the AI demonstrated competitive performance against human players who had no prior experience with those games. The model also excelled in fast-paced first-person shooter environments like Vizdoom, showing advanced behaviors such as corner-peeking and evasive maneuvers.

The context of this research matters because it moves beyond specialized game-playing AI toward general computer-use agents. The same underlying technology could eventually power AI assistants that help people with everyday computer tasks, from software development to data analysis. The human-native interaction paradigm means such systems could work with existing software without requiring special APIs or modifications.

Limitations noted in the research include the computational demands of the current system and the challenge of maintaining performance across all scenarios. The model requires careful balancing between reasoning depth and response speed, and while it generalizes well to new games, there remain environments where its performance doesn't match specialized human players. The research also acknowledges that scaling such systems requires massive computational resources and diverse training data.