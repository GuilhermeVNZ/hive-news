[VOICEOVER 0:00-0:05] What if AI could see inside your body in 3D using just two simple images? [VISUAL DIRECTION] [Animated text: '3D FROM 2 VIEWS?' with rotating 3D medical scan visualization] [VOICEOVER 0:05-0:20] Right now, accurate cancer treatment monitoring requires lengthy, expensive scans that take hours and specialized equipment. [VISUAL DIRECTION] [Show Figure 2 from paper - comparison of traditional vs AI reconstruction, zoom on accuracy metrics] [VOICEOVER 0:20-0:40] Researchers asked: Could AI reconstruct complete 3D radiation distribution from the simple anterior-posterior views typically collected? [VISUAL DIRECTION] [Animated diagram showing 2D projections transforming into 3D volume] [VOICEOVER 0:40-1:00] They developed two AI approaches - supervised 3DResUnet and unsupervised diffusion models - that achieved 0.89 correlation with ground truth in training. [VISUAL DIRECTION] [Split screen showing both AI methods, highlight correlation coefficient 0.89] [VOICEOVER 1:00-1:30] The AI was trained on simulated radiotracer patterns across different anatomies and rotations, learning to generate accurate 3D maps from limited 2D data that traditional methods couldn't reconstruct. [VISUAL DIRECTION] [Show Figure 3 pointing to lesions - zoom on improved boundary definition in AI reconstructions] [VOICEOVER 1:30-1:50] This means hospitals could eliminate hour-long SPECT scans, reducing costs while maintaining accuracy. Patients get shorter scan times and potentially more frequent therapy monitoring. [VISUAL DIRECTION] [Fast cuts: hospital equipment → cost savings graphic → patient benefit icon] [VOICEOVER 1:50-2:00] AI is transforming medical imaging - making precision cancer treatment monitoring faster, cheaper, and more accessible. [VISUAL DIRECTION] [Final text overlay: '5% BETTER ACCURACY' with rotating 3D medical scan]