Large language models (LLMs) are transforming video games by enabling dynamic, conversational interactions with non-player characters (NPCs), but they often fail to follow essential procedural rules, risking player trust and game integrity. A new study introduces Autoregressive State-Tracking Prompting (ASTP), a method that ensures LLMs adhere to structured workflows, such as in-game trading sequences, without sacrificing natural dialogue. This advancement addresses a critical gap in deploying AI for real-world applications where compliance and creativity must coexist.

Researchers discovered that ASTP achieves over 99% compliance with procedural rules in simulated trading scenarios, a significant improvement from baseline methods that only reached 78.1%. The key finding is that by explicitly requiring the AI to identify and report its current state at each step, the model reliably follows predefined sequences like browse, offer, review, and confirm, preventing errors such as skipping mandatory confirmation steps.

The methodology centers on a Prime–Guide–Enforce workflow integrated into the AI's prompt. Instead of relying on implicit reasoning, the LLM must first infer the previous dialogue state, then determine the next state based on user input, and finally generate a response that includes the identified state. This makes the AI's decision-making transparent and verifiable. Additionally, a placeholder-based post-processing system ensures accurate numerical calculations, such as pricing in trades, by replacing placeholders with computed values only in specific states, boosting calculation precision from 84.3% to 99.3%.

Analysis of the results shows that ASTP not only enhances rule adherence but also improves efficiency. In tests, a smaller AI model (Gemini-2.5-Flash) matched the performance of a larger one (Gemini-2.5-Pro) while reducing response times from 21.2 seconds to 2.4 seconds. This efficiency gain, combined with high compliance rates, demonstrates the method's practicality for real-time applications like commercial games, where speed and reliability are crucial.

The implications extend beyond gaming to any domain requiring strict procedural adherence, such as customer service or medical consultations, where AI must balance natural interaction with rule-based constraints. For everyday readers, this means more trustworthy AI assistants in digital environments, reducing frustrations from unintended actions and enhancing user confidence.

Limitations noted in the study include challenges with highly ambiguous user inputs, where multi-intent utterances can lead to state misinterpretations and calculation errors. Future work will explore scaling the approach to handle more complex rules and scenarios, ensuring robustness across diverse applications.