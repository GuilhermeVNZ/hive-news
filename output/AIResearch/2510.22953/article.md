Scientists have developed a new method that measures how artificial intelligence systems process information more reliably than current techniques. This breakthrough could help researchers better understand how AI networks learn and represent data, similar to how neuroscientists study brain activity.

The key finding from MIT researchers is that their Manifold-approximated Kernel Alignment (MKA) method provides more consistent measurements of how AI systems represent information. Unlike the popular Centered Kernel Alignment (CKA) method used since 2010, MKA accounts for the underlying structure of data, making it less sensitive to variations in data size and shape. The researchers demonstrated that their approach captures the true relationships between different AI representations more accurately.

The methodology builds on the concept of manifold approximation, which recognizes that complex data like medical images or language patterns often lie on simpler curved surfaces within high-dimensional spaces. The team used k-nearest neighbor graphs to model these underlying structures, creating a kernel that focuses on local relationships between data points rather than global patterns. This approach mirrors techniques used in dimensionality reduction methods like t-SNE and UMAP, but applies them to comparing AI representations.

Results from extensive testing showed MKA's superiority across multiple scenarios. In experiments with synthetic datasets mimicking real-world conditions, MKA maintained consistent performance when the number of data samples increased from 100 to 1000 and when dimensionality grew from 10 to 1000 features. The method correctly identified equivalent structures - like recognizing that a Swiss-roll shape and S-curve are topologically similar - while CKA often failed this basic test. When tested on the Representation Similarity (ReSi) benchmark across vision, natural language, and graph tasks, MKA achieved the best performance in computer vision applications and competitive results in other domains.

The real-world implications are significant for both AI development and neuroscience research. For AI engineers, this provides a more reliable tool to compare different neural networks, understand how they process information, and identify when systems are learning similar representations. In neuroscience, it could help researchers more accurately compare brain activity patterns across different subjects or conditions. The method's robustness means scientists can trust their measurements even when working with limited data or complex datasets.

However, the approach has limitations. Like other kernel-based methods, MKA has computational complexity that grows with data size, making it challenging for extremely large datasets. The method also relies on choosing the number of neighbors to consider, though the researchers showed it's less sensitive to this parameter than alternatives. Future work could explore different neighborhood functions and additional debiasing techniques to further improve performance.

The research demonstrates that by considering the underlying geometry of data, we can develop more reliable tools for understanding how AI systems work - a crucial step toward building more transparent and trustworthy artificial intelligence.