A new method for training artificial intelligence models improves their ability to learn by selectively compressing irrelevant information, leading to better performance across language and vision tasks without increasing computational costs. This approach, called IBNorm, rethinks a fundamental component of deep learning—normalization—by applying principles from information theory to enhance how models process data.

The researchers discovered that IBNorm outperforms standard normalization techniques like BatchNorm and LayerNorm in large-scale models. For instance, when integrated into LLaMA models, IBNorm achieved up to an 8.75% improvement on the LLM Leaderboard benchmarks. In vision tasks, it boosted ImageNet accuracy by 3.98% for ResNet-50 and up to 8.17% for Vision Transformers, demonstrating broad applicability across different AI domains.

Methodologically, the team designed IBNorm by decomposing normalization into steps and introducing a compression operation that reduces variability in activations—the intermediate outputs of neural networks. This operation, controlled by a parameter λ, pushes activations toward their mean, suppressing noise while preserving task-relevant information. The process is drop-in compatible with existing architectures, requiring no major changes to model structures.

Analysis of the results shows that IBNorm increases the information bottleneck value, a measure of how well models balance retaining useful information and discarding redundancies. Experiments on datasets like C4 and OpenWebText confirmed that models with IBNorm maintain higher mutual information with target labels while reducing irrelevant data, explaining the performance gains. For example, in GPT-2 models, IBNorm variants consistently scored higher on tasks like mathematical reasoning and language understanding compared to baseline methods.

In practical terms, this advancement means AI systems could become more efficient and accurate in real-world applications such as automated content generation, image recognition, and data analysis. By focusing on essential information, models may require less data to achieve similar results, potentially reducing training time and resource usage. This could benefit industries relying on AI for tasks like customer service chatbots or medical image diagnostics, where precision is critical.

Limitations noted in the paper include that evaluations were conducted on medium-scale models due to computational constraints. The researchers highlight the need for future work to test IBNorm on larger foundation models to fully assess its scalability and impact in more complex scenarios.