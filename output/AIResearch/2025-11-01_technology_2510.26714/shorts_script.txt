[VOICEOVER 0:00-0:05] What if your AI's memory wipe is a total lie? [VISUAL DIRECTION] Animated text: 'AI FORGET BUTTON BROKEN?' with glitch effects. [VOICEOVER 0:05-0:20] Machine unlearning aims to delete specific data from AI without full retraining—key for privacy laws like GDPR. [VISUAL DIRECTION] Show GDPR logo and data deletion icon, fast cut to AI model diagram. [VOICEOVER 0:20-0:40] But researchers asked: does standard testing hide the truth? [VISUAL DIRECTION] Zoom in on 'single seed' text with question mark, transition to lab setup. [VOICEOVER 0:40-1:00] They found relying on one seed overestimates or underestimates performance, proven in CIFAR-100 experiments. [VISUAL DIRECTION] Display Figure 2 boxplots, pan across retain-set accuracy variances. [VOICEOVER 1:00-1:30] How? Multiple seeds capture real variability; single seed skews metrics like forget-quality and retain-accuracy. [VISUAL DIRECTION] Animate seed icons multiplying, overlay with 2-Wasserstein distance graph. [VOICEOVER 1:30-1:50] Implications: flawed tests risk deploying biased AI in sensitive tasks—from healthcare to finance. [VISUAL DIRECTION] Show real-world scenes (e.g., hospital, bank) with 'RISK' text overlay. [VOICEOVER 1:50-2:00] Bottom line: Trust AI only with rigorous, multi-seed evaluation. [VISUAL DIRECTION] End with bold text: 'TEST SMARTER, DEPLOY SAFER.'