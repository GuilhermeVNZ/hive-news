[VOICEOVER 0:00-0:05] What if your self-driving car failed in the exact moment you needed it most—like swerving around a fallen scooter? [VISUAL DIRECTION] Animated text: '0.03% FAILURE RATE' with a red flash; fast cut to a car braking abruptly on a busy street.
[VOICEOVER 0:05-0:20] Autonomous vehicles are safer overall, but they falter in rare, unpredictable situations—think sudden road closures or pedestrian interactions. [VISUAL DIRECTION] Show Figure 2 from the paper, zooming in on the distribution of high-risk events; overlay text: 'RARE BUT CRITICAL'.
[VOICEOVER 0:20-0:40] Researchers asked: Why do AI systems miss these edge cases, and how can we measure true safety beyond simple metrics? [VISUAL DIRECTION] Transition to a split screen: left shows a car following a path (low error), right highlights it ignoring an obstacle; animated arrows point to the disparity.
[VOICEOVER 0:40-1:00] They discovered that traditional metrics like Average Displacement Error are inadequate—cars can track paths perfectly but make unsafe decisions. [VISUAL DIRECTION] Pan across a graph comparing ADE and Rater-Following Score; highlight the gap with bold text: 'SAFETY GAP EXPOSED'.
[VOICEOVER 1:00-1:30] The solution? WOD-E2E uses end-to-end systems and human annotations to evaluate scenarios based on safety, legality, and efficiency—not just distance. [VISUAL DIRECTION] Show clips from the dataset: 360-degree views of intersections, debris on roads; fast cuts with text overlays like 'HUMAN JUDGMENT KEY'.
[VOICEOVER 1:30-1:50] This means future AVs could better handle emergencies, reducing accidents in unpredictable conditions for everyday drivers. [VISUAL DIRECTION] Animated sequence: car safely navigating construction zones and pedestrian cut-ins; hold on a smiling passenger.
[VOICEOVER 1:50-2:00] Remember: True autonomy hinges on mastering the rare 0.03%—because that's where safety is tested. [VISUAL DIRECTION] Fade to the paper's title 'WOD-E2E: Waymo Open Dataset for End-to-End Driving'; end with a slow zoom on the logo.