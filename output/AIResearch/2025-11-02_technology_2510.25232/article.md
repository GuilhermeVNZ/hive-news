Mental health disorders affect millions globally, with comorbidity—the co-occurrence of multiple conditions—complicating diagnosis and treatment. Current datasets often focus on single disorders, limiting the development of reliable AI tools for complex clinical scenarios. Researchers from Shanghai Jiao Tong University and collaborating institutions have created PsyCoTalk, a large-scale dataset of simulated psychiatric dialogues that mimics real doctor-patient interactions, offering a resource to improve diagnostic accuracy and training in mental healthcare.

The key finding is that PsyCoTalk enables AI models to perform multi-disorder screening in a single conversational pass, achieving higher accuracy than baseline methods. For instance, the hierarchical diagnostic state machine (HDSM) framework improved exact-match diagnostic accuracy from 0.22 to 0.31 on a subset of cases, with per-label F1 scores reaching 0.92 for depression and 0.81 for anxiety. This demonstrates the system's ability to handle the intricacies of comorbid conditions like depression, anxiety, bipolar disorder, and ADHD.

Methodology involved a two-stage process grounded in clinical standards. First, the team developed PsyCoProfile by converting social media posts from the PsySym corpus into structured electronic medical records (EMRs) for 502 synthetic patients, ensuring diversity across common psychiatric combinations. Second, they built a multi-agent framework where AI agents—simulating a doctor, patient, and diagnostic tool—interact using the HDSM and dynamic context tree (DCT). The HDSM adheres to the SCID-5-RV interview protocol, organizing questions into hierarchical states to guide step-by-step reasoning, while the DCT adds depth by dynamically incorporating patient history and experiences.

Results analysis shows that PsyCoTalk contains 5,000 validated dialogues, with an average of 45.9 turns per conversation—over twice that of comparable datasets. In human evaluations by licensed psychiatrists, it scored highest in communication (8.14 for doctor initiative and 8.24 for patient engagement) and realism, closely matching real-world consultations. Objective comparisons revealed structural fidelity, with utterance lengths (34.0 characters for doctors, 43.5 for patients) near those of actual clinical dialogues. The dataset's diversity was confirmed through metrics like normalized entropy and semantic analysis, indicating varied and coherent interactions.

Contextually, this work matters because it addresses a critical gap in mental health resources, where comorbidity is common but poorly represented in existing AI training data. By simulating realistic diagnostic processes, PsyCoTalk can aid in developing tools for early screening and decision support, especially in settings with limited access to specialists. It emphasizes ethical use, with no real patient data involved, and aims to reduce biases through rigorous validation.

Limitations include the focus on prevalent disorders like depression and anxiety, excluding rarer conditions, and the primary use of Chinese language data, which may restrict cross-lingual applicability. However, the pipeline is extensible, allowing for future expansions to broader populations and languages, as demonstrated in a small-scale English experiment that showed comparable diversity.