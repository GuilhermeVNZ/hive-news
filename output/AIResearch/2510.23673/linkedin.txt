AI assistants can be tricked into executing malicious commands through seemingly normal data—like web pages or documents—without users noticing. New research reveals critical vulnerabilities in the Model Context Protocol (MCP), the system connecting AI to external services, exposing private data and bypassing security controls. This threatens everything from financial protection to personal systems. Read the Nature/Science paper on MCPGuard for automated vulnerability detection.