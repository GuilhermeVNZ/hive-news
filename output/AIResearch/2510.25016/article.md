Software development teams face a critical bottleneck: translating human needs into precise technical requirements. This process, called requirements engineering, often consumes significant time and introduces errors through miscommunication and information overload. Now researchers have developed a framework that uses artificial intelligence to assist human experts in creating better software specifications while maintaining human oversight.

The key finding is that AI can effectively support requirements engineering tasks when designed as a collaborative partner rather than a replacement for human expertise. The Human-AI Requirements Engineering Synergy Model (HARE-SM) integrates AI tools for tasks like requirement extraction, classification, and validation while ensuring human experts retain final decision-making authority.

The methodology involves a four-phase approach. First, researchers conducted preliminary studies analyzing existing AI applications in requirements engineering. Second, they designed and implemented a prototype called the Acceptance Criteria Assistant, which allows software engineers to input user stories and generate acceptance criteria using multiple AI models. The system displays outputs from different AI models side-by-side, enabling direct comparison and selection of the best criteria. All interactions are logged for analysis.

Results from the prototype implementation show that different AI models exhibit distinct characteristics in requirements generation. For example, Google's Flan-T5 model tends to generalize well but may omit edge cases, while LLaMA-3 provides more specific responses but can be verbose. The system architecture enforces human-in-the-loop principles by requiring every AI suggestion to be reviewed, corrected, or accepted by human engineers. The logging service captures all user decisions, edits, and preferences, creating an auditable trail of human-AI collaboration.

This research matters because software requirements form the foundation of successful software projects. Poor requirements lead to costly rework, missed deadlines, and failed projects. By combining AI efficiency with human judgment, development teams can create more accurate specifications faster while reducing errors. The framework addresses real-world concerns about AI automation by maintaining transparency, enabling bias mitigation, and preserving human accountability.

The approach has limitations that require further investigation. The researchers note that Phases III and IV of their roadmap—involving model fine-tuning, validation, and empirical evaluation—remain planned rather than completed. Future work needs to demonstrate how the system performs in real-world software development environments and whether the human-AI collaboration scales effectively across different project types and industries. The framework also needs validation through stakeholder workshops and controlled studies measuring productivity gains and usability improvements.