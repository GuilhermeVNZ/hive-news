Meta is ramping up efforts to enhance online safety for teenagers, with a focus on its Instagram platform. The company has launched a School Partnership Program for all U.S. middle and high schools, designed to give educators direct tools to report issues like bullying and harmful content. This initiative follows a year-long pilot that received positive feedback from participating institutions.

Developed in collaboration with the International Society for Technology in Education and the Association for Supervision and Curriculum Development, the program allows schools to flag content that may violate community standards. Meta promises a prioritized review, aiming to address reports within 48 hours, which could speed up responses to critical safety incidents.

Schools that join the program gain access to prioritized reporting, educational resources, and a profile banner indicating their official partnership with Instagram. A principal involved in the pilot noted that the program provided an 'inside track' for faster resolution of online safety concerns, highlighting its potential impact on student well-being.

In addition to the partnership program, Meta has rolled out a free online safety curriculum created with Childhelp, targeting middle schoolers. The curriculum covers topics like identifying signs of online exploitation and includes interactive elements to engage young users. Educators and parents expect it to reach over 550,000 students this year, with a goal of one million.

To make the content more relatable, Meta partnered with LifeSmarts to develop a peer-led version of the curriculum. High school students will now teach safety lessons to their younger peers, addressing the preference for age-appropriate discussions among middle schoolers.

These updates build on earlier features like Teen Accounts, which introduced restrictions on live streaming and direct messaging. The move comes amid increasing scrutiny of social media's impact on youth, with regulators and parents calling for stronger safeguards.

Industry analysts suggest that such measures could set a precedent for other tech platforms, as online safety becomes a central issue in digital governance. Meta has stated it will continue to develop new protections, with further announcements expected in the coming months.