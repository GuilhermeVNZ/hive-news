In a significant advancement for artificial intelligence in cybersecurity, Anthropic has revealed that its Claude Sonnet 4.5 model now matches or exceeds the performance of its flagship Opus 4.1 model in critical security tasks. The development comes as AI capabilities transition from theoretical potential to practical utility in defending against increasingly sophisticated cyber threats.

The research, detailed in Anthropic's latest findings, shows Claude Sonnet 4.5 achieving state-of-the-art results in multiple cybersecurity benchmarks. On the Cybench evaluation—derived from Capture-the-Flag competition challenges—Sonnet 4.5 achieved a 76.5% success rate when given 10 attempts per task, doubling the performance of Sonnet 3.7 from just six months earlier. This rapid improvement underscores the accelerating pace of AI development in security applications.

Perhaps more impressively, the model demonstrated real-world practicality by solving complex security challenges that would typically take skilled human analysts hours to complete. In one documented case, Claude analyzed network traffic, extracted malware, and decrypted it in just 38 minutes—a task estimated to require at least an hour for human experts.

The CyberGym benchmark revealed even more striking capabilities. When given 30 attempts per task, Claude Sonnet 4.5 reproduced known vulnerabilities in 66.7% of programs and discovered previously unknown vulnerabilities in over 33% of projects tested. This represents a substantial leap from Sonnet 4's approximately 2% discovery rate for new vulnerabilities.

Anthropic's approach has been deliberately defensive-focused. The company states it avoided enhancements that clearly favor offensive work, such as advanced exploitation or malware writing, instead concentrating on capabilities that benefit security teams protecting businesses, governments, and critical open-source software.

Early adopters are already seeing tangible benefits. HackerOne reported that Claude Sonnet 4.5 reduced average vulnerability intake time by 44% while improving accuracy by 25% for their security agents. Meanwhile, CrowdStrike noted the model's strong promise for red teaming—generating creative attack scenarios that help security teams better understand and prepare for real threats.

The timing is critical. Anthropic's Safeguards team has documented increasing misuse of AI by threat actors, including cases where cybercriminals used Claude to build large-scale data extortion schemes that previously would have required entire teams. The company has also detected and countered AI-assisted espionage operations targeting critical telecommunications infrastructure.

As AI capabilities continue to evolve rapidly, Anthropic's research suggests we've reached an inflection point where defensive applications must keep pace with offensive ones. The company is now calling for broader industry adoption of AI in security operations centers, SIEM analysis, and secure network engineering to ensure defenders maintain the advantage in an increasingly automated threat landscape.