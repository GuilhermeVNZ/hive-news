When faced with puzzling events, from everyday mysteries to scientific anomalies, we instinctively seek explanations. A new study reveals why some explanations feel more satisfying than others, offering insights into how our minds navigate a world filled with conflicting information. This research matters because it helps explain why people sometimes embrace conspiracy theories or reject scientific evidence—decisions that shape public health, politics, and social trust.

Researchers discovered that people evaluate explanations based on three core values: how well an explanation accounts for specific facts (descriptiveness), how well it connects different pieces of information (co-explanation), and how simple or unified it is (theoretical values like parsimony). These values act like mental scales, balancing detail against coherence and complexity.

The team used a Bayesian framework—a mathematical approach to probability—to model how people weigh these values when choosing between explanations. They presented participants with scenarios where explanations varied in descriptiveness (e.g., fitting all data points), co-explanation (e.g., linking symptoms to a common cause), and simplicity (e.g., using fewer assumptions). By analyzing choices, they quantified how much each value influences decisions.

The data showed that people consistently prefer explanations that strike a balance: neither overly complex nor too simplistic. For instance, explanations with high co-explanation but low descriptiveness were often rejected, as they overgeneralize. The paper notes that imbalances—such as overvaluing co-explanation—can lead to real-world issues, like belief in conspiracy theories, where hidden connections are emphasized at the expense of simplicity.

This research matters because it clarifies why certain explanations gain traction in society, from anti-vaccine movements to pseudoscientific claims. By understanding these mental biases, educators and communicators can design better messages that appeal to our innate explanatory preferences, potentially countering misinformation.

However, the study has limitations: it primarily focuses on controlled scenarios and may not capture all cultural or contextual factors that influence explanation preferences. The paper also notes that the framework assumes people have access to all relevant information, which is often not the case in real-life decisions.