xAI has officially unveiled Grok Code Fast 1, a specialized AI model designed to revolutionize agentic coding with its exceptional speed and affordability. The model addresses a critical pain point in current AI-assisted development: the sluggish performance of reasoning loops and tool calls that can disrupt workflow efficiency.

Built from the ground up with a novel architecture, Grok Code Fast 1 was trained on a programming-rich corpus and refined using real-world datasets from pull requests and coding tasks. The development process involved close collaboration with launch partners to optimize the model for practical use in agentic platforms.

The model demonstrates proficiency with essential developer tools like grep, terminal commands, and file editing, making it seamlessly integrable into popular IDEs. It supports multiple programming languages including TypeScript, Python, Java, Rust, C, and Go, handling tasks from project initialization to bug fixes with minimal oversight.

Performance metrics show Grok Code Fast 1 achieving a 70.8 score on the SWE-Bench-Verified subset using xAI's internal testing framework. However, the company emphasizes that real-world usability assessments by experienced developers were equally crucial in shaping the model's development, focusing on user satisfaction and practical application.

xAI has implemented advanced inference optimizations and prompt caching techniques that achieve over 90% cache hit rates with partner platforms. These innovations contribute to the model's remarkable responsiveness, allowing it to execute dozens of tool calls in the time it takes to read a single thinking trace.

The model is available through the xAI API at competitive pricing: $0.20 per million input tokens, $1.50 per million output tokens, and $0.02 per million cached input tokens. For a limited time, free access is offered through launch partners GitHub Copilot, Cursor, Cline, Roo Code, Kilo Code, opencode, and Windsurf.

xAI has already begun development on an enhanced variant supporting multimodal inputs, parallel tool calling, and extended context length. The company encourages developer feedback and promises rapid iteration cycles with improvements delivered in days rather than weeks.